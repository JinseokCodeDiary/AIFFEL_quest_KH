{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('outliers_data_test.csv', encoding='cp949')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''\n",
    "df = pd.read_csv('outliers_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"1: \\uc77c\\uce58 - \\ubd88\\uc548\\n2: \\uc77c\\uce58 - \\ubd88\\uc548\\n3: \\uc77c\\uce58 - \\uacb0\\uc758\\n4: \\uc77c\\uce58 - \\ubd84\\ub178\\n5: \\uc77c\\uce58 - \\uae30\\uc068\\n6: \\uc77c\\uce58 - \\uc9dc\\uc99d\\n7: \\uc77c\\uce58 - \\ud638\\uae30\\uc2ec\\n8: \\uc77c\\uce58 - \\uc5fc\\ub824\\n9: \\uc77c\\uce58 - \\uc131\\uae09\\ud568\\n10: \\uc77c\\uce58 - \\uae34\\uc7a5\\n11: \\uc77c\\uce58 - \\uae30\\uc068\\n12: \\uc77c\\uce58 - \\uae30\\uc068\\n13: \\ubd88\\uc77c\\uce58 - \\uc815\\ubcf4\\uc801\\n14: \\uc77c\\uce58 - \\uae30\\uc068\\n15: \\uc77c\\uce58 - \\uac71\\uc815\\n16: \\uc77c\\uce58 - \\uc2e4\\ub9dd\\n17: \\uc77c\\uce58 - \\uacb0\\uc758\\n18: \\uc77c\\uce58 - \\uae30\\uc068\\n19: \\uc77c\\uce58 - \\uc548\\uc2ec\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 789,\n",
      "        \"candidates_token_count\": 168,\n",
      "        \"total_token_count\": 957\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "감정 분석이 완료되었습니다. 결과가 'updated_emotion_data.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "def create_prompt(df, start_index, chunk_size=100):\n",
    "    prompt = \"다음 텍스트와 감정 쌍을 분석하고, 각 텍스트가 해당 감정과 일치하는지 확인해주세요. 일치하지 않는 경우 적절한 감정을 제안해주세요.\\n\\n\"\n",
    "    for i in range(start_index, min(start_index + chunk_size, len(df))):\n",
    "        prompt += f\"{i+1}. 텍스트: {df.loc[i, 'text']}\\n   감정: {df.loc[i, 'emotion']}\\n\\n\"\n",
    "        \n",
    "    prompt += \"보기의 감정으로만 답변해주세요.:\\n\"\n",
    "    prompt += \"emotions = ['당황', '분노', '불안', '슬픔', '중립', '행복'] \\n\"\n",
    "\n",
    "    prompt += \"각 항목에 대해 다음 형식으로 답변해주세요:\\n\"\n",
    "    prompt += \"항목 번호: [일치 여부] (일치/불일치) - [제안된 감정(불일치 경우에만)]\\n\"\n",
    "    return prompt\n",
    "\n",
    "def process_gemini_response(response_text, df, start_index):\n",
    "    lines = response_text.split('\\n')\n",
    "    for line in lines:\n",
    "        match = re.match(r'(\\d+): (\\w+) - (\\w+)', line)\n",
    "        if match:\n",
    "            item_num, match_status, suggested_emotion = match.groups()\n",
    "            idx = start_index + int(item_num) - 1\n",
    "            if idx < len(df) and match_status == '불일치':\n",
    "                df.loc[idx, 'emotion'] = suggested_emotion\n",
    "\n",
    "def analyze_emotions(df, api_key):\n",
    "    genai.configure(api_key=api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "    for start_index in range(0, len(df), 20):\n",
    "        prompt = create_prompt(df, start_index)\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        print(response)\n",
    "        \n",
    "        if response.text:\n",
    "            process_gemini_response(response.text, df, start_index)\n",
    "        else:\n",
    "            print(f\"Warning: Empty response for prompt starting at index {start_index}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# 메인 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 감정 분석 실행\n",
    "    updated_df = analyze_emotions(df, api_key)\n",
    "\n",
    "    # 결과 저장\n",
    "    updated_df.to_csv('updated_emotion_data2.csv', index=False)\n",
    "    print(\"감정 분석이 완료되었습니다. 결과가 'updated_emotion_data.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gemini_response(response_text, df, start_index):\n",
    "    lines = response_text.split('\\n')\n",
    "    print(lines)\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        match = re.match(r'(\\d+): \\[(\\w+)\\]( - \\[(\\w+)\\])?', line)\n",
    "        print(match)\n",
    "        if match:\n",
    "            print(\"match\",match)\n",
    "            item_num, match_status, _, suggested_emotion = match.groups()\n",
    "            idx = start_index + int(item_num) - 1\n",
    "            if idx < len(df) and match_status == '불일치' and suggested_emotion:\n",
    "                df.loc[idx, 'emotion'] = suggested_emotion\n",
    "\n",
    "def process_gemini_response(response_text, df, start_index):\n",
    "    lines = response_text.split('\\n')\n",
    "    for line in lines:\n",
    "        match = re.match(r'(\\d+): (\\w+) - (\\w+)', line)\n",
    "        if match:\n",
    "            item_num, match_status, suggested_emotion = match.groups()\n",
    "            idx = start_index + int(item_num) - 1\n",
    "            if idx < len(df) and match_status == '불일치':\n",
    "                df.loc[idx, 'emotion'] = suggested_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1: 불일치 - 두려움\\n2: 불일치 - 불안\\n3: 불일치 - 결의\\n4: 불일치 - 분노\\n5: 불일치 - 기쁨\\n6: 불일치 - 짜증\\n7: 불일치 - 호기심\\n8: 불일치 - 염려\\n9: 불일치 - 성급함\\n10: 불일치 - 긴장\\n11: 불일치 - 기쁨\\n12: 불일치 - 기쁨\\n13: 불일치 - 정보적\\n14: 불일치 - 기쁨\\n15: 불일치 - 걱정\\n16: 불일치 - 실망\\n17: 불일치 - 결의\\n18: 불일치 - 기쁨\\n19: 불일치 - 안심'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
