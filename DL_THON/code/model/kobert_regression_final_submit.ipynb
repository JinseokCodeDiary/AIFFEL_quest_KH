{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성 세기 예측 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torch.distributed as dist\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import nltk\n",
    "# from nltk.corpus import wordnet\n",
    "from tf_keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from tf_keras.models import Model\n",
    "from tf_keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 필요한 라이브러리 설치\n",
    "# !pip install konlpy\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/m2021/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 로드 완료\n",
      "CSV 파일 로드 중...\n",
      "데이터 로드 완료. 샘플 수: 14606\n",
      "데이터 샘플:\n",
      "                     wav_id                        발화문     상황    1번 감정  \\\n",
      "0  5e258fd1305bcf3ad153a6a4           어, 청소 니가 대신 해 줘!  anger  Neutral   \n",
      "1  5e258fe2305bcf3ad153a6a5         둘 다 청소 하기 싫어. 귀찮아.  anger  Neutral   \n",
      "2  5e258ff5305bcf3ad153a6a6             둘 다 하기 싫어서 화내.  anger    Angry   \n",
      "3  5e25902f305bcf3ad153a6a9                그럼 방세는 어떡해.  anger  Sadness   \n",
      "4  5e27f90b5807b852d9e0157b  권태긴줄 알았는데 다른 사람이 생겼나보더라고.    sad  Sadness   \n",
      "\n",
      "   1번 감정세기    2번 감정  2번 감정세기    3번 감정  3번 감정세기    4번 감정  4번 감정세기    5번 감정  \\\n",
      "0        0    Angry        1  Neutral        0  Neutral        0    Angry   \n",
      "1        0    Angry        1  Neutral        0  Neutral        0    Angry   \n",
      "2        1    Angry        1  Neutral        0    Angry        1    Angry   \n",
      "3        1  Sadness        1  Sadness        1  Sadness        1  Sadness   \n",
      "4        1  Sadness        1  Sadness        1  Sadness        2  Sadness   \n",
      "\n",
      "   5번 감정세기  나이    성별  \n",
      "0        1  27  male  \n",
      "1        1  27  male  \n",
      "2        1  27  male  \n",
      "3        1  27  male  \n",
      "4        1  32  male  \n"
     ]
    }
   ],
   "source": [
    "# NLTK WordNet 다운로드\n",
    "nltk.download('wordnet')\n",
    "print(\"라이브러리 로드 완료\")\n",
    "\n",
    "# 데이터셋 로드\n",
    "file_name = 'year4.csv'  # 감정 세기 데이터셋\n",
    "\n",
    "# CSV 파일 로드\n",
    "print(\"CSV 파일 로드 중...\")\n",
    "df = pd.read_csv(file_name, encoding='cp949')\n",
    "print(f\"데이터 로드 완료. 샘플 수: {len(df)}\")\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "print(\"데이터 샘플:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>그냥 걷고 있어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>내가 애정 표현을 잘 못해서 자주 싸우긴 했어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오늘 헤어졌어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>룸메이트와 너무 자주 싸우게 돼.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>그러고 싶은데 보증금 때문에 그럴 수가 없어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>이 회사가 이번 시즌 마지막 회사였어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>부모님한테 아직 말 안했는데 말하기가 두려워.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>아니. 입맛도 없어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>응. 혼 났지.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>그럴 시간도 없다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>부모님도 다 슬퍼하셔.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>그래, 고마워.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>해봤는데, 전화를 안 받네.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>맨날 그래 얘는.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>어. 크게 다치진 않았는데.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>일주일에 다섯번은 먹는다니까?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>응. 그래봐야지. 해피도 오래 살긴 했어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>다들 지쳤어. 나도 지쳤구, 이제.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>어제 밤 새서 작성한 기획안 다시 해야되네.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>모르겠어. 좀 최대한 추스려볼게.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>청소 좀 하고 살자.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>응. 그 동안 괜찮았는데.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>응. 인제 병원에서 퇴원하는 길이야.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>이제 두 달 지났어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>어제 지진 있었잖아. 다행히 다치진 않았어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>옆에서 친구가 넘어져서 발목 다쳤어.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       발화문  Neutral  Happiness  Sadness  \\\n",
       "0                         어, 청소 니가 대신 해 줘!        0          0        0   \n",
       "1                       둘 다 청소 하기 싫어. 귀찮아.        0          0        0   \n",
       "2                           둘 다 하기 싫어서 화내.        0          0        0   \n",
       "3                              그럼 방세는 어떡해.        0          0        5   \n",
       "4                권태긴줄 알았는데 다른 사람이 생겼나보더라고.        0          0        6   \n",
       "5                                그냥 걷고 있어.        0          0        2   \n",
       "6             어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.        0          0        0   \n",
       "7            처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.        0          1        0   \n",
       "8               내가 애정 표현을 잘 못해서 자주 싸우긴 했어.        0          0        5   \n",
       "9                                 오늘 헤어졌어.        0          0        4   \n",
       "10                      룸메이트와 너무 자주 싸우게 돼.        0          0        4   \n",
       "11               그러고 싶은데 보증금 때문에 그럴 수가 없어.        0          0        4   \n",
       "12                   이 회사가 이번 시즌 마지막 회사였어.        0          0        3   \n",
       "13               부모님한테 아직 말 안했는데 말하기가 두려워.        0          0        4   \n",
       "14                             아니. 입맛도 없어.        0          0        5   \n",
       "15                                응. 혼 났지.        0          0        2   \n",
       "16                              그럴 시간도 없다.        0          0        5   \n",
       "17                            부모님도 다 슬퍼하셔.        0          0        4   \n",
       "18                                그래, 고마워.        0          0        0   \n",
       "19                         해봤는데, 전화를 안 받네.        0          0        2   \n",
       "20                               맨날 그래 얘는.        0          0        0   \n",
       "21                         어. 크게 다치진 않았는데.        0          0        1   \n",
       "22                        일주일에 다섯번은 먹는다니까?        0          0        0   \n",
       "23  그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.        0          0        7   \n",
       "24            다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.        0          0        7   \n",
       "25                 응. 그래봐야지. 해피도 오래 살긴 했어.        0          0        7   \n",
       "26       그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.        0          0        7   \n",
       "27  지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.        0          0        5   \n",
       "28                     다들 지쳤어. 나도 지쳤구, 이제.        0          0        5   \n",
       "29                어제 밤 새서 작성한 기획안 다시 해야되네.        0          0        7   \n",
       "30           그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.        0          0        6   \n",
       "31      응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.        0          0        9   \n",
       "32                      모르겠어. 좀 최대한 추스려볼게.        0          0        6   \n",
       "33        노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.        0          0        6   \n",
       "34                             청소 좀 하고 살자.        0          0        0   \n",
       "35                          응. 그 동안 괜찮았는데.        0          0        3   \n",
       "36                    응. 인제 병원에서 퇴원하는 길이야.        0          1        1   \n",
       "37                             이제 두 달 지났어.        0          0        6   \n",
       "38                어제 지진 있었잖아. 다행히 다치진 않았어.        0          0        0   \n",
       "39                    옆에서 친구가 넘어져서 발목 다쳤어.        0          0        2   \n",
       "\n",
       "    Angry  Disgust  Surprise  Fear  나이      성별  \n",
       "0       2        0         0     0  27    male  \n",
       "1       2        0         0     0  27    male  \n",
       "2       4        0         0     0  27    male  \n",
       "3       0        0         0     0  27    male  \n",
       "4       0        0         0     0  32    male  \n",
       "5       0        0         0     0  32    male  \n",
       "6       2        5         0     0  32    male  \n",
       "7       0        0         0     0  28    male  \n",
       "8       0        0         0     0  28    male  \n",
       "9       0        0         0     0  28    male  \n",
       "10      0        0         0     0  28    male  \n",
       "11      0        0         0     0  28    male  \n",
       "12      0        0         0     0  28    male  \n",
       "13      0        0         0     1  28    male  \n",
       "14      0        0         0     0  28    male  \n",
       "15      1        0         0     0  28    male  \n",
       "16      0        0         0     0  28    male  \n",
       "17      0        0         0     0  28    male  \n",
       "18      0        0         0     0  28    male  \n",
       "19      0        0         0     0  28    male  \n",
       "20      4        0         0     0  28    male  \n",
       "21      0        0         0     0  28    male  \n",
       "22      2        0         2     0  28    male  \n",
       "23      0        0         0     0  28    male  \n",
       "24      0        0         0     0  28    male  \n",
       "25      0        0         0     0  28    male  \n",
       "26      0        0         0     0  28    male  \n",
       "27      0        0         0     0  28    male  \n",
       "28      1        0         0     0  28    male  \n",
       "29      0        0         0     0  28    male  \n",
       "30      0        0         0     0  28    male  \n",
       "31      0        0         0     0  28    male  \n",
       "32      0        0         0     0  28    male  \n",
       "33      0        0         0     0  28    male  \n",
       "34      6        0         0     0  28    male  \n",
       "35      0        0         0     0  37    male  \n",
       "36      0        0         0     0  37    male  \n",
       "37      0        0         0     0  40  female  \n",
       "38      0        0         1     0  37    male  \n",
       "39      0        0         0     0  37    male  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define emotion columns\n",
    "emotion_labels = ['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']\n",
    "\n",
    "# Initialize a list to store processed data\n",
    "final_data = []\n",
    "\n",
    "# Process each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    # Initialize emotion scores with zeros\n",
    "    emotions = {emotion: 0 for emotion in emotion_labels}\n",
    "    \n",
    "    # Sum the scores for each emotion\n",
    "    for i in range(1, 6):\n",
    "        emotion = row[f'{i}번 감정']\n",
    "        score = row[f'{i}번 감정세기']\n",
    "        if emotion in emotions:\n",
    "            emotions[emotion] += score\n",
    "\n",
    "    # Append the processed data\n",
    "    final_data.append({\n",
    "        '발화문': row['발화문'],\n",
    "        **emotions,\n",
    "        '나이': row['나이'],\n",
    "        '성별': row['성별']\n",
    "    })\n",
    "\n",
    "# Create the final DataFrame\n",
    "final_df = pd.DataFrame(final_data)\n",
    "\n",
    "# Convert emotion scores to integers\n",
    "final_df[emotion_labels] = final_df[emotion_labels].astype(int)\n",
    "\n",
    "# Display the final DataFrame\n",
    "final_df.head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 및 데이터셋 분배\n",
    "\n",
    "# Normalize emotion scores between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "final_df[['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']] = scaler.fit_transform(\n",
    "    final_df[['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']])\n",
    "\n",
    "# # Prepare features and targets\n",
    "# X = final_df['발화문']  # Features are the utterances\n",
    "# y = final_df.drop(columns=['발화문'])  # Targets include emotion scores, age, and gender\n",
    "\n",
    "# # Encode gender (if not already numeric)\n",
    "# y['성별'] = y['성별'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Display the size of each set\n",
    "# print(f\"Training set size: {len(X_train)}\")\n",
    "# print(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "# # Display a sample from the training data\n",
    "# print(\"\\nTraining data sample:\")\n",
    "# print(X_train.head())\n",
    "# print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_df.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Emotion  Count\n",
      "0    Neutral    123\n",
      "1  Happiness    370\n",
      "2    Sadness   8172\n",
      "3      Angry   3861\n",
      "4    Disgust   1016\n",
      "5   Surprise    113\n",
      "6       Fear    951\n"
     ]
    }
   ],
   "source": [
    "# Assuming final_df is your DataFrame with emotion columns\n",
    "emotion_columns = ['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']\n",
    "\n",
    "# Initialize a dictionary to count the occurrences\n",
    "dominant_emotion_count = {emotion: 0 for emotion in emotion_columns}\n",
    "\n",
    "# Iterate over each row and find the dominant emotion\n",
    "for _, row in final_df.iterrows():\n",
    "    # Get the emotion with the maximum score for the current row\n",
    "    dominant_emotion = row[emotion_columns].idxmax()\n",
    "    \n",
    "    # Increment the count for the dominant emotion\n",
    "    dominant_emotion_count[dominant_emotion] += 1\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better visualization\n",
    "dominant_emotion_df = pd.DataFrame(list(dominant_emotion_count.items()), columns=['Emotion', 'Count'])\n",
    "\n",
    "# Display the result\n",
    "print(dominant_emotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34102382168479234"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean for each emotion column\n",
    "non_zero_means = final_df[['Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']].apply(lambda col: col[col != 0].mean())\n",
    "emotion_mean = non_zero_means.mean()\n",
    "emotion_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불균형 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일부 데이터 언더 샘플링 후 증강 (실패한 시도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_edited = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>그냥 걷고 있어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>내가 애정 표현을 잘 못해서 자주 싸우긴 했어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오늘 헤어졌어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>룸메이트와 너무 자주 싸우게 돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>그러고 싶은데 보증금 때문에 그럴 수가 없어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>이 회사가 이번 시즌 마지막 회사였어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>부모님한테 아직 말 안했는데 말하기가 두려워.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>아니. 입맛도 없어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>응. 혼 났지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>그럴 시간도 없다.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>부모님도 다 슬퍼하셔.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>그래, 고마워.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>해봤는데, 전화를 안 받네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>맨날 그래 얘는.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>어. 크게 다치진 않았는데.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>일주일에 다섯번은 먹는다니까?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>응. 그래봐야지. 해피도 오래 살긴 했어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>다들 지쳤어. 나도 지쳤구, 이제.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>어제 밤 새서 작성한 기획안 다시 해야되네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>모르겠어. 좀 최대한 추스려볼게.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>청소 좀 하고 살자.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>응. 그 동안 괜찮았는데.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>응. 인제 병원에서 퇴원하는 길이야.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>이제 두 달 지났어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>어제 지진 있었잖아. 다행히 다치진 않았어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>옆에서 친구가 넘어져서 발목 다쳤어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       발화문  Neutral  Happiness  Sadness  \\\n",
       "0                         어, 청소 니가 대신 해 줘!      0.0   0.000000      0.0   \n",
       "1                       둘 다 청소 하기 싫어. 귀찮아.      0.0   0.000000      0.0   \n",
       "2                           둘 다 하기 싫어서 화내.      0.0   0.000000      0.0   \n",
       "3                              그럼 방세는 어떡해.      0.0   0.000000      0.5   \n",
       "4                권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0   0.000000      0.6   \n",
       "5                                그냥 걷고 있어.      0.0   0.000000      0.2   \n",
       "6             어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.      0.0   0.000000      0.0   \n",
       "7            처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.      0.0   0.111111      0.0   \n",
       "8               내가 애정 표현을 잘 못해서 자주 싸우긴 했어.      0.0   0.000000      0.5   \n",
       "9                                 오늘 헤어졌어.      0.0   0.000000      0.4   \n",
       "10                      룸메이트와 너무 자주 싸우게 돼.      0.0   0.000000      0.4   \n",
       "11               그러고 싶은데 보증금 때문에 그럴 수가 없어.      0.0   0.000000      0.4   \n",
       "12                   이 회사가 이번 시즌 마지막 회사였어.      0.0   0.000000      0.3   \n",
       "13               부모님한테 아직 말 안했는데 말하기가 두려워.      0.0   0.000000      0.4   \n",
       "14                             아니. 입맛도 없어.      0.0   0.000000      0.5   \n",
       "15                                응. 혼 났지.      0.0   0.000000      0.2   \n",
       "16                              그럴 시간도 없다.      0.0   0.000000      0.5   \n",
       "17                            부모님도 다 슬퍼하셔.      0.0   0.000000      0.4   \n",
       "18                                그래, 고마워.      0.0   0.000000      0.0   \n",
       "19                         해봤는데, 전화를 안 받네.      0.0   0.000000      0.2   \n",
       "20                               맨날 그래 얘는.      0.0   0.000000      0.0   \n",
       "21                         어. 크게 다치진 않았는데.      0.0   0.000000      0.1   \n",
       "22                        일주일에 다섯번은 먹는다니까?      0.0   0.000000      0.0   \n",
       "23  그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.      0.0   0.000000      0.7   \n",
       "24            다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.      0.0   0.000000      0.7   \n",
       "25                 응. 그래봐야지. 해피도 오래 살긴 했어.      0.0   0.000000      0.7   \n",
       "26       그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.      0.0   0.000000      0.7   \n",
       "27  지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.      0.0   0.000000      0.5   \n",
       "28                     다들 지쳤어. 나도 지쳤구, 이제.      0.0   0.000000      0.5   \n",
       "29                어제 밤 새서 작성한 기획안 다시 해야되네.      0.0   0.000000      0.7   \n",
       "30           그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.      0.0   0.000000      0.6   \n",
       "31      응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.      0.0   0.000000      0.9   \n",
       "32                      모르겠어. 좀 최대한 추스려볼게.      0.0   0.000000      0.6   \n",
       "33        노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.      0.0   0.000000      0.6   \n",
       "34                             청소 좀 하고 살자.      0.0   0.000000      0.0   \n",
       "35                          응. 그 동안 괜찮았는데.      0.0   0.000000      0.3   \n",
       "36                    응. 인제 병원에서 퇴원하는 길이야.      0.0   0.111111      0.1   \n",
       "37                             이제 두 달 지났어.      0.0   0.000000      0.6   \n",
       "38                어제 지진 있었잖아. 다행히 다치진 않았어.      0.0   0.000000      0.0   \n",
       "39                    옆에서 친구가 넘어져서 발목 다쳤어.      0.0   0.000000      0.2   \n",
       "\n",
       "    Angry  Disgust  Surprise  Fear  나이  성별  \n",
       "0     0.2      0.0  0.000000   0.0  27   0  \n",
       "1     0.2      0.0  0.000000   0.0  27   0  \n",
       "2     0.4      0.0  0.000000   0.0  27   0  \n",
       "3     0.0      0.0  0.000000   0.0  27   0  \n",
       "4     0.0      0.0  0.000000   0.0  32   0  \n",
       "5     0.0      0.0  0.000000   0.0  32   0  \n",
       "6     0.2      0.5  0.000000   0.0  32   0  \n",
       "7     0.0      0.0  0.000000   0.0  28   0  \n",
       "8     0.0      0.0  0.000000   0.0  28   0  \n",
       "9     0.0      0.0  0.000000   0.0  28   0  \n",
       "10    0.0      0.0  0.000000   0.0  28   0  \n",
       "11    0.0      0.0  0.000000   0.0  28   0  \n",
       "12    0.0      0.0  0.000000   0.0  28   0  \n",
       "13    0.0      0.0  0.000000   0.1  28   0  \n",
       "14    0.0      0.0  0.000000   0.0  28   0  \n",
       "15    0.1      0.0  0.000000   0.0  28   0  \n",
       "16    0.0      0.0  0.000000   0.0  28   0  \n",
       "17    0.0      0.0  0.000000   0.0  28   0  \n",
       "18    0.0      0.0  0.000000   0.0  28   0  \n",
       "19    0.0      0.0  0.000000   0.0  28   0  \n",
       "20    0.4      0.0  0.000000   0.0  28   0  \n",
       "21    0.0      0.0  0.000000   0.0  28   0  \n",
       "22    0.2      0.0  0.222222   0.0  28   0  \n",
       "23    0.0      0.0  0.000000   0.0  28   0  \n",
       "24    0.0      0.0  0.000000   0.0  28   0  \n",
       "25    0.0      0.0  0.000000   0.0  28   0  \n",
       "26    0.0      0.0  0.000000   0.0  28   0  \n",
       "27    0.0      0.0  0.000000   0.0  28   0  \n",
       "28    0.1      0.0  0.000000   0.0  28   0  \n",
       "29    0.0      0.0  0.000000   0.0  28   0  \n",
       "30    0.0      0.0  0.000000   0.0  28   0  \n",
       "31    0.0      0.0  0.000000   0.0  28   0  \n",
       "32    0.0      0.0  0.000000   0.0  28   0  \n",
       "33    0.0      0.0  0.000000   0.0  28   0  \n",
       "34    0.6      0.0  0.000000   0.0  28   0  \n",
       "35    0.0      0.0  0.000000   0.0  37   0  \n",
       "36    0.0      0.0  0.000000   0.0  37   0  \n",
       "37    0.0      0.0  0.000000   0.0  40   1  \n",
       "38    0.0      0.0  0.111111   0.0  37   0  \n",
       "39    0.0      0.0  0.000000   0.0  37   0  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_edited['성별'] = original_edited['성별'].map({'male': 0, 'female': 1})\n",
    "original_edited.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_final_df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 감정이 가장 높은 행의 개수:\n",
      "Highest_Emotion\n",
      "Sadness      8172\n",
      "Angry        3861\n",
      "Disgust      1016\n",
      "Fear          951\n",
      "Happiness     370\n",
      "Neutral       123\n",
      "Surprise      113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 행에서 가장 높은 감정 컬럼 확인\n",
    "final_df['Highest_Emotion'] = final_df[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "# 각 감정이 가장 높은 행의 수 계산\n",
    "emotion_counts = final_df['Highest_Emotion'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 감정이 가장 높은 행의 개수:\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실패한 시도 (언더샘플링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 감정이 가장 높은 행의 개수:\n",
      "Highest_Emotion\n",
      "Sadness      8172\n",
      "Angry        3861\n",
      "Disgust      1016\n",
      "Fear          951\n",
      "Happiness     370\n",
      "Neutral       123\n",
      "Surprise      113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 행에서 가장 높은 감정 컬럼 확인\n",
    "final_df['Highest_Emotion'] = final_df[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "# 각 감정이 가장 높은 행의 수 계산\n",
    "emotion_counts = final_df['Highest_Emotion'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 감정이 가장 높은 행의 개수:\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = first_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_unused 데이터프레임:\n",
      "                                     발화문  Neutral  Happiness  Sadness  Angry  \\\n",
      "0  할 수 있으면은 당연히 좋지. 근데 이직도 힘드니까. 잘 모르겠어.      0.0        0.0      0.7    0.0   \n",
      "1                          나 결국 헤어지게 됐어.      0.0        0.0      0.7    0.0   \n",
      "2                      밥맛이 없어. 나중에 먹어야지.      0.0        0.0      0.6    0.0   \n",
      "3                        해피가 결국 세상을 떠났어.      0.0        0.0      0.7    0.0   \n",
      "4                                권태기인가봐.      0.0        0.0      0.6    0.0   \n",
      "\n",
      "   Disgust  Surprise  Fear  나이  성별 Highest_Emotion  \n",
      "0      0.0       0.0   0.0  24   0         Sadness  \n",
      "1      0.0       0.0   0.0  46   1         Sadness  \n",
      "2      0.0       0.0   0.0  46   1         Sadness  \n",
      "3      0.0       0.0   0.0  40   1         Sadness  \n",
      "4      0.0       0.0   0.0  27   1         Sadness  \n",
      "\n",
      "final_df 데이터프레임 (업데이트됨):\n",
      "                                       발화문  Neutral  Happiness  Sadness  \\\n",
      "0      아니. 조금 예전부터 시름시름 아프더니 결국 세상을 떠나버렸네.      0.0   0.000000      0.7   \n",
      "1                          아직도 있어. 진짜 더럽다.      0.0   0.000000      0.0   \n",
      "2                               그러겠지. 고마워.      0.0   0.111111      0.1   \n",
      "3            우리 아빠 어제 또 다치셨어. 정말 이게 말이 되니?      0.0   0.000000      0.0   \n",
      "4  그래. 너가 대신 일을 해줄 수 없지만 위로 받을 수 있어서 다행이다.      0.0   0.222222      0.4   \n",
      "\n",
      "   Angry  Disgust  Surprise  Fear  나이  성별 Highest_Emotion  \n",
      "0    0.0      0.0       0.0   0.0  27   0         Sadness  \n",
      "1    0.0      0.7       0.0   0.0  27   1         Disgust  \n",
      "2    0.0      0.0       0.0   0.0  45   0       Happiness  \n",
      "3    0.6      0.0       0.0   0.0  41   1           Angry  \n",
      "4    0.0      0.0       0.0   0.0  31   0         Sadness  \n"
     ]
    }
   ],
   "source": [
    "random_seed = 42\n",
    "df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "# Sadness 이외의 감정 컬럼 값이 모두 0인 행의 인덱스 추출\n",
    "emotion_columns = ['Neutral', 'Happiness', 'Angry', 'Disgust', 'Surprise', 'Fear']\n",
    "zero_emotion_indices = df[(df[emotion_columns] == 0).all(axis=1)].index\n",
    "\n",
    "# 4311개의 인덱스 무작위 선택\n",
    "selected_indices = zero_emotion_indices.to_series().sample(n=4311, random_state=random_seed).values\n",
    "\n",
    "\n",
    "# final_df에서 temp_unused와 동일한 행 삭제\n",
    "final_df = df.drop(index=selected_indices).reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"temp_unused 데이터프레임:\")\n",
    "print(temp_unused.head())\n",
    "print(\"\\nfinal_df 데이터프레임 (업데이트됨):\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 감정이 가장 높은 행의 개수:\n",
      "Highest_Emotion\n",
      "Angry        5272\n",
      "Neutral      1721\n",
      "Fear         1404\n",
      "Disgust      1147\n",
      "Happiness     609\n",
      "Surprise      142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 행에서 가장 높은 감정 컬럼 확인\n",
    "final_df['Highest_Emotion'] = final_df[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "# 각 감정이 가장 높은 행의 수 계산\n",
    "emotion_counts = final_df['Highest_Emotion'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 감정이 가장 높은 행의 개수:\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 감정이 가장 높은 행의 개수:\n",
      "Highest_Emotion\n",
      "Neutral      6032\n",
      "Angry        5272\n",
      "Fear         1404\n",
      "Disgust      1147\n",
      "Happiness     609\n",
      "Surprise      142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_df = first_final_df\n",
    "\n",
    "# 각 행에서 가장 높은 감정 컬럼 확인\n",
    "final_df['Highest_Emotion'] = final_df[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "# 각 감정이 가장 높은 행의 수 계산\n",
    "emotion_counts = final_df['Highest_Emotion'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 감정이 가장 높은 행의 개수:\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한글 패키지 사용하기 (실패한 시도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/m2021/konlpy_data',\n",
       " '/usr/share/konlpy_data',\n",
       " '/usr/local/share/konlpy_data',\n",
       " '/usr/lib/konlpy_data',\n",
       " '/usr/local/lib/konlpy_data',\n",
       " '/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/konlpy/data']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "konlpy.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.io.FileNotFoundException: open-korean-text-2.1.0.jar (No such file or directory)\n",
      "\tat java.base/java.io.FileInputStream.open0(Native Method)\n",
      "\tat java.base/java.io.FileInputStream.open(FileInputStream.java:213)\n",
      "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:152)\n",
      "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:106)\n",
      "\tat jdk.jartool/sun.tools.jar.Main.run(Main.java:394)\n",
      "\tat jdk.jartool/sun.tools.jar.Main.main(Main.java:1708)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/konlpy/data')\n",
    "os.getcwd()\n",
    "\n",
    "!jar xvf open-korean-text-2.1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/konlpy/data/org/openkoreantext/processor/util\") as f:\n",
    "#     data = f.read()\n",
    "\n",
    "# print(data[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 부분 증강 (실패한 시도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "      <th>Highest_Emotion</th>\n",
       "      <th>증강된 발화문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>아, 요즘 룸메랑 너무 자주 싸우게 돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>아, 요즘 룸메랑 너무 자주 싸우게 돼.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602</th>\n",
       "      <td>아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14603</th>\n",
       "      <td>뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>그게 확실한 방법이겠지?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>그게 확실한 방법이겠지?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14606 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     발화문  Neutral  Happiness  \\\n",
       "0                                       어, 청소 니가 대신 해 줘!      0.0        0.0   \n",
       "1                                     둘 다 청소 하기 싫어. 귀찮아.      0.0        0.0   \n",
       "2                                         둘 다 하기 싫어서 화내.      0.0        0.0   \n",
       "3                                            그럼 방세는 어떡해.      0.0        0.0   \n",
       "4                              권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0   \n",
       "...                                                  ...      ...        ...   \n",
       "14601                             아, 요즘 룸메랑 너무 자주 싸우게 돼.      0.0        0.0   \n",
       "14602                  아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.      0.0        0.0   \n",
       "14603  뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...      0.0        0.0   \n",
       "14604            어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.      0.0        0.0   \n",
       "14605                                      그게 확실한 방법이겠지?      0.0        0.0   \n",
       "\n",
       "       Sadness  Angry  Disgust  Surprise  Fear  나이  성별 Highest_Emotion  \\\n",
       "0          0.0    0.2      0.0       0.0   0.0  27   0           Angry   \n",
       "1          0.0    0.2      0.0       0.0   0.0  27   0           Angry   \n",
       "2          0.0    0.4      0.0       0.0   0.0  27   0           Angry   \n",
       "3          0.5    0.0      0.0       0.0   0.0  27   0         Neutral   \n",
       "4          0.6    0.0      0.0       0.0   0.0  32   0         Neutral   \n",
       "...        ...    ...      ...       ...   ...  ..  ..             ...   \n",
       "14601      0.0    0.4      0.2       0.0   0.0  35   0           Angry   \n",
       "14602      0.0    0.4      0.2       0.0   0.0  35   0           Angry   \n",
       "14603      0.1    0.4      0.2       0.0   0.0  35   0           Angry   \n",
       "14604      0.1    0.1      0.0       0.0   0.0  35   0           Angry   \n",
       "14605      0.1    0.1      0.1       0.0   0.0  35   0           Angry   \n",
       "\n",
       "                                                 증강된 발화문  \n",
       "0                                       어, 청소 니가 대신 해 줘!  \n",
       "1                                     둘 다 청소 하기 싫어. 귀찮아.  \n",
       "2                                         둘 다 하기 싫어서 화내.  \n",
       "3                                            그럼 방세는 어떡해.  \n",
       "4                              권태긴줄 알았는데 다른 사람이 생겼나보더라고.  \n",
       "...                                                  ...  \n",
       "14601                             아, 요즘 룸메랑 너무 자주 싸우게 돼.  \n",
       "14602                  아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.  \n",
       "14603  뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...  \n",
       "14604            어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.  \n",
       "14605                                      그게 확실한 방법이겠지?  \n",
       "\n",
       "[14606 rows x 12 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness가 0이 아닌 행들 (sadness_data):\n",
      "                          발화문  Neutral  Happiness  Sadness  Angry  Disgust  \\\n",
      "0                 그럼 방세는 어떡해.      0.0        0.0      0.5    0.0      0.0   \n",
      "1   권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0      0.6    0.0      0.0   \n",
      "2                   그냥 걷고 있어.      0.0        0.0      0.2    0.0      0.0   \n",
      "3  내가 애정 표현을 잘 못해서 자주 싸우긴 했어.      0.0        0.0      0.5    0.0      0.0   \n",
      "4                    오늘 헤어졌어.      0.0        0.0      0.4    0.0      0.0   \n",
      "\n",
      "   Surprise  Fear  나이  성별 Highest_Emotion                     증강된 발화문  \n",
      "0       0.0   0.0  27   0         Neutral                 그럼 방세는 어떡해.  \n",
      "1       0.0   0.0  32   0         Neutral   권태긴줄 알았는데 다른 사람이 생겼나보더라고.  \n",
      "2       0.0   0.0  32   0         Neutral                   그냥 걷고 있어.  \n",
      "3       0.0   0.0  28   0         Neutral  내가 애정 표현을 잘 못해서 자주 싸우긴 했어.  \n",
      "4       0.0   0.0  28   0         Neutral                    오늘 헤어졌어.  \n",
      "\n",
      "나머지 행들 (augment_df):\n",
      "                             발화문  Neutral  Happiness  Sadness  Angry  Disgust  \\\n",
      "0               어, 청소 니가 대신 해 줘!      0.0   0.000000      0.0    0.2      0.0   \n",
      "1             둘 다 청소 하기 싫어. 귀찮아.      0.0   0.000000      0.0    0.2      0.0   \n",
      "2                 둘 다 하기 싫어서 화내.      0.0   0.000000      0.0    0.4      0.0   \n",
      "3   어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.      0.0   0.000000      0.0    0.2      0.5   \n",
      "4  처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.      0.0   0.111111      0.0    0.0      0.0   \n",
      "\n",
      "   Surprise  Fear  나이  성별 Highest_Emotion                        증강된 발화문  \n",
      "0       0.0   0.0  27   0           Angry               어, 청소 니가 대신 해 줘!  \n",
      "1       0.0   0.0  27   0           Angry             둘 다 청소 하기 싫어. 귀찮아.  \n",
      "2       0.0   0.0  27   0           Angry                 둘 다 하기 싫어서 화내.  \n",
      "3       0.0   0.0  32   0         Disgust   어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.  \n",
      "4       0.0   0.0  28   0       Happiness  처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.  \n"
     ]
    }
   ],
   "source": [
    "# Sadness 컬럼이 0이 아닌 행들을 추출하여 sadness_data에 저장\n",
    "sadness_data = final_df[final_df['Sadness'] != 0].reset_index(drop=True)\n",
    "\n",
    "# 나머지 행들을 추출하여 augment_df에 저장\n",
    "augment_df = final_df[final_df['Sadness'] == 0].reset_index(drop=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Sadness가 0이 아닌 행들 (sadness_data):\")\n",
    "print(sadness_data.head())\n",
    "print(\"\\n나머지 행들 (augment_df):\")\n",
    "print(augment_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 동의어 치환을 위한 사전 예시\n",
    "synonym_dict = {\n",
    "}\n",
    "\n",
    "# # 동의어 치환 함수\n",
    "# def replace_synonyms_korean(sentence, synonym_dict, probability=0.3):\n",
    "#     # 형태소 분석\n",
    "#     words = okt.pos(sentence, norm=True, stem=True)\n",
    "#     new_words = []\n",
    "    \n",
    "#     for word, pos in words:\n",
    "#         if pos in ['Noun', 'Verb', 'Adjective'] and random.random() < probability:\n",
    "#             # 동의어 치환\n",
    "#             if word in synonym_dict:\n",
    "#                 new_word = random.choice(synonym_dict[word])\n",
    "#                 new_words.append(new_word)\n",
    "#             else:\n",
    "#                 new_words.append(word)\n",
    "#         else:\n",
    "#             new_words.append(word)\n",
    "    \n",
    "#     return ' '.join(new_words)\n",
    "\n",
    "# # '발화문' 컬럼에 데이터 증강 적용\n",
    "# augment_df['증강된 발화문'] = augment_df['발화문'].apply(lambda x: replace_synonyms_korean(x, synonym_dict))\n",
    "\n",
    "# # 결과의 처음 몇 줄을 확인\n",
    "# augment_df[['발화문', '증강된 발화문']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Emotion  Count\n",
      "0    Neutral    123\n",
      "1  Happiness    370\n",
      "2    Sadness   8172\n",
      "3      Angry   3861\n",
      "4    Disgust   1016\n",
      "5   Surprise    113\n",
      "6       Fear    951\n"
     ]
    }
   ],
   "source": [
    "dominant_emotion_df = pd.DataFrame(list(dominant_emotion_count.items()), columns=['Emotion', 'Count'])\n",
    "# Display the result\n",
    "print(dominant_emotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         발화문  Neutral  Happiness  Sadness  Angry  Disgust  \\\n",
      "0           어, 청소 니가 대신 해 줘!      0.0        0.0      0.0    0.2      0.0   \n",
      "1         둘 다 청소 하기 싫어. 귀찮아.      0.0        0.0      0.0    0.2      0.0   \n",
      "2             둘 다 하기 싫어서 화내.      0.0        0.0      0.0    0.4      0.0   \n",
      "3                그럼 방세는 어떡해.      0.0        0.0      0.5    0.0      0.0   \n",
      "4  권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0      0.6    0.0      0.0   \n",
      "\n",
      "   Surprise  Fear  나이  성별 Highest_Emotion                    증강된 발화문  \n",
      "0       0.0   0.0  27   0           Angry           어, 청소 니가 대신 해 줘!  \n",
      "1       0.0   0.0  27   0           Angry         둘 다 청소 하기 싫어. 귀찮아.  \n",
      "2       0.0   0.0  27   0           Angry             둘 다 하기 싫어서 화내.  \n",
      "3       0.0   0.0  27   0         Neutral                그럼 방세는 어떡해.  \n",
      "4       0.0   0.0  32   0         Neutral  권태긴줄 알았는데 다른 사람이 생겼나보더라고.  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불균형 해결을 위해 다른 자료 통합 가능성 탐색 (기타 증강 기법 적용하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCEL 파일 로드 중...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_chunked_dialogue.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[247], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# EXCEL 파일 로드\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXCEL 파일 로드 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_two\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m데이터 로드 완료. 샘플 수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 데이터 샘플 출력\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_chunked_dialogue.xlsx'"
     ]
    }
   ],
   "source": [
    "file_two = 'training_chunked_dialogue.xlsx'\n",
    "file_three = 'val_chunked_dialogue.xlsx'\n",
    "\n",
    "# EXCEL 파일 로드\n",
    "print(\"EXCEL 파일 로드 중...\")\n",
    "df = pd.read_excel(file_two)\n",
    "print(f\"데이터 로드 완료. 샘플 수: {len(df)}\")\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "print(\"데이터 샘플:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "감정_소분류 집합: {'억울한', '환멸을 느끼는', '희생된', '불안', '편안한', '느긋', '외로운', '눈물이 나는', '신뢰하는', '분노', '배신당한', '스트레스 받는', '버려진', '좌절한', '짜증내는', '슬픔', '방어적인', '자신하는', '후회되는', '안달하는', '낙담한', '마비된', '신이 난', '우울한', '괴로워하는', '흥분', '회의적인', '상처', '실망한', '안도', '비통한', '충격 받은', '혼란스러운', '부끄러운', '당황', '질투하는', '혐오스러운', '남의 시선을 의식하는', '감사하는', '염세적인', '죄책감의', '걱정스러운', '노여워하는', '만족스러운', '툴툴대는', '가난한, 불우한', '두려운', '구역질 나는', '취약한', '고립된', '당혹스러운', '한심한', '초조한', '성가신', '조심스러운', '기쁨', '악의적인', '열등감'}\n",
      "감정_대분류 집합: {'슬픔', '불안', '상처', '분노', '당황', '기쁨'}\n",
      "\n",
      "감정_대분류와 감정_소분류 딕셔너리:\n",
      "슬픔: ['슬픔', '환멸을 느끼는', '우울한', '눈물이 나는', '실망한', '비통한', '낙담한', '후회되는', '마비된', '염세적인']\n",
      "불안: ['걱정스러운', '불안', '회의적인', '두려운', '취약한', '스트레스 받는', '당혹스러운', '혼란스러운', '초조한', '조심스러운']\n",
      "상처: ['억울한', '희생된', '괴로워하는', '가난한, 불우한', '상처', '충격 받은', '고립된', '배신당한', '질투하는', '버려진']\n",
      "분노: ['노여워하는', '방어적인', '툴툴대는', '구역질 나는', '분노', '안달하는', '성가신', '악의적인', '좌절한', '짜증내는']\n",
      "당황: ['외로운', '열등감', '고립된', '혼란스러운', '부끄러운', '당황', '한심한', '혐오스러운', '남의 시선을 의식하는', '죄책감의']\n",
      "기쁨: ['만족스러운', '흥분', '편안한', '느긋', '자신하는', '신뢰하는', '안도', '감사하는', '기쁨', '신이 난']\n"
     ]
    }
   ],
   "source": [
    "# Create sets for 감정_소분류 and 감정_대분류\n",
    "sub_emotions_set = set(df['감정_소분류'].dropna().unique())\n",
    "big_emotions_set = set(df['감정_대분류'].dropna().unique())\n",
    "\n",
    "print(\"\\n감정_소분류 집합:\", sub_emotions_set)\n",
    "print(\"감정_대분류 집합:\", big_emotions_set)\n",
    "\n",
    "# Initialize an empty dictionary to store results\n",
    "emotion_dict = {bigE: set() for bigE in big_emotions_set}\n",
    "\n",
    "# Populate the dictionary\n",
    "for bigE in big_emotions_set:\n",
    "    for subE in sub_emotions_set:\n",
    "        # Check if the current row has the given subE and bigE\n",
    "        matching_rows = df[(df['감정_소분류'] == subE) & (df['감정_대분류'] == bigE)]\n",
    "        if not matching_rows.empty:\n",
    "            emotion_dict[bigE].add(subE)\n",
    "\n",
    "# Convert sets to lists for more flexible usage later\n",
    "emotion_dict = {key: list(value) for key, value in emotion_dict.items()}\n",
    "\n",
    "# Display the resulting dictionary\n",
    "print(\"\\n감정_대분류와 감정_소분류 딕셔너리:\")\n",
    "for bigE, subE_list in emotion_dict.items():\n",
    "    print(f\"{bigE}: {subE_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>신체질환</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>감정_소분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>시스템문장1</th>\n",
       "      <th>사람문장2</th>\n",
       "      <th>시스템문장2</th>\n",
       "      <th>사람문장3</th>\n",
       "      <th>시스템문장3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "      <td>그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.</td>\n",
       "      <td>혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "      <td>최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.</td>\n",
       "      <td>월급이 줄어든 만큼 소비를 줄일 계획이군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "      <td>잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...</td>\n",
       "      <td>스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "      <td>직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.</td>\n",
       "      <td>직장 사람들과 이야기를 해 보겠다고 결심하셨군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "      <td>상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!</td>\n",
       "      <td>항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>51626</td>\n",
       "      <td>노년</td>\n",
       "      <td>남성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>분노</td>\n",
       "      <td>성가신</td>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "      <td>경제적인 문제 때문에 막막하시군요. 마음이 편치 않으시겠어요.</td>\n",
       "      <td>아무것도 할 수 없는 내가 무가치하게 느껴지고 실망스러워.</td>\n",
       "      <td>지금 할 수 있는 가장 합리적인 행동은 무엇인가요?</td>\n",
       "      <td>노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.</td>\n",
       "      <td>좋은 결과 얻으시길 바랄게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>51627</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>불안</td>\n",
       "      <td>초조한</td>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "      <td>건강에 대한 어려움 때문에 기분이 좋지 않으시군요. 속상하시겠어요.</td>\n",
       "      <td>마음 같아서는 다 할 수 있는 일인데 이젠 몸이 안 따라와 주니 화만 나.</td>\n",
       "      <td>어떻게 하면 지금의 기분을 나아지게 할 수 있을까요?</td>\n",
       "      <td>남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.</td>\n",
       "      <td>남편과 함께하는 좋은 외출 시간 되시길 바랄게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>51628</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>상처</td>\n",
       "      <td>희생된</td>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "      <td>노후 준비에 대한 어려움 때문에 걱정이 많으시겠어요.</td>\n",
       "      <td>주변 사람들은 다 노후 준비도 잘해두었던데 난 어떻게 해야 할지 모르겠어. 막막하기...</td>\n",
       "      <td>지금의 상황에서 할 수 있는 가장 좋은 행동이 무엇일까요?</td>\n",
       "      <td>남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.</td>\n",
       "      <td>좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>51629</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>불안</td>\n",
       "      <td>걱정스러운</td>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "      <td>가족과의 문제 때문에 속상하시겠어요.</td>\n",
       "      <td>이제 할 수 있는 일도 없고 이렇게 힘들게 사는 게 불만스럽기만 해.</td>\n",
       "      <td>지금의 감정을 나아지게 할 수 있는 어떤 방법이 있을까요?</td>\n",
       "      <td>함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.</td>\n",
       "      <td>지인분들과 좋은 시간 보내셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>51630</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>만성질환 무</td>\n",
       "      <td>상처</td>\n",
       "      <td>배신당한</td>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "      <td>대인관계에 대한 어려움 때문에 걱정되시고 속상하시겠어요.</td>\n",
       "      <td>사람들을 만나는 것이 어려워. 자꾸 사람들을 의심하게만 되고 말이야.</td>\n",
       "      <td>어떻게 하면 지금의 상황에 변화를 만들어낼 수 있을까요?</td>\n",
       "      <td>사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...</td>\n",
       "      <td>원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  연령  성별     상황키워드    신체질환 감정_대분류 감정_소분류  \\\n",
       "0               1  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "1               2  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "2               3  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "3               4  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "4               5  청년  여성  진로,취업,직장    해당없음     분노  노여워하는   \n",
       "...           ...  ..  ..       ...     ...    ...    ...   \n",
       "51625       51626  노년  남성        재정  만성질환 무     분노    성가신   \n",
       "51626       51627  노년  여성        재정  만성질환 무     불안    초조한   \n",
       "51627       51628  노년  여성        재정  만성질환 무     상처    희생된   \n",
       "51628       51629  노년  여성      대인관계  만성질환 무     불안  걱정스러운   \n",
       "51629       51630  노년  여성      대인관계  만성질환 무     상처   배신당한   \n",
       "\n",
       "                                                   사람문장1  \\\n",
       "0                              일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1         이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2      회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3      직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4                  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "...                                                  ...   \n",
       "51625     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.   \n",
       "51626        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.   \n",
       "51627   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.   \n",
       "51628  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.   \n",
       "51629  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.   \n",
       "\n",
       "                                                  시스템문장1  \\\n",
       "0                            많이 힘드시겠어요. 주위에 의논할 상대가 있나요?   \n",
       "1               급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?   \n",
       "2      회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...   \n",
       "3      관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...   \n",
       "4      무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...   \n",
       "...                                                  ...   \n",
       "51625                 경제적인 문제 때문에 막막하시군요. 마음이 편치 않으시겠어요.   \n",
       "51626              건강에 대한 어려움 때문에 기분이 좋지 않으시군요. 속상하시겠어요.   \n",
       "51627                      노후 준비에 대한 어려움 때문에 걱정이 많으시겠어요.   \n",
       "51628                               가족과의 문제 때문에 속상하시겠어요.   \n",
       "51629                    대인관계에 대한 어려움 때문에 걱정되시고 속상하시겠어요.   \n",
       "\n",
       "                                                   사람문장2  \\\n",
       "0                    그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.   \n",
       "1       최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.   \n",
       "2      잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...   \n",
       "3                  직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.   \n",
       "4                    상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!   \n",
       "...                                                  ...   \n",
       "51625                   아무것도 할 수 없는 내가 무가치하게 느껴지고 실망스러워.   \n",
       "51626          마음 같아서는 다 할 수 있는 일인데 이젠 몸이 안 따라와 주니 화만 나.   \n",
       "51627  주변 사람들은 다 노후 준비도 잘해두었던데 난 어떻게 해야 할지 모르겠어. 막막하기...   \n",
       "51628             이제 할 수 있는 일도 없고 이렇게 힘들게 사는 게 불만스럽기만 해.   \n",
       "51629             사람들을 만나는 것이 어려워. 자꾸 사람들을 의심하게만 되고 말이야.   \n",
       "\n",
       "                                                  시스템문장2  \\\n",
       "0         혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.    \n",
       "1                               월급이 줄어든 만큼 소비를 줄일 계획이군요.   \n",
       "2              스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.   \n",
       "3                            직장 사람들과 이야기를 해 보겠다고 결심하셨군요.   \n",
       "4      항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...   \n",
       "...                                                  ...   \n",
       "51625                       지금 할 수 있는 가장 합리적인 행동은 무엇인가요?   \n",
       "51626                      어떻게 하면 지금의 기분을 나아지게 할 수 있을까요?   \n",
       "51627                   지금의 상황에서 할 수 있는 가장 좋은 행동이 무엇일까요?   \n",
       "51628                   지금의 감정을 나아지게 할 수 있는 어떤 방법이 있을까요?   \n",
       "51629                    어떻게 하면 지금의 상황에 변화를 만들어낼 수 있을까요?   \n",
       "\n",
       "                                                   사람문장3  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "51625                 노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.   \n",
       "51626            남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.   \n",
       "51627      남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.   \n",
       "51628            함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.   \n",
       "51629  사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...   \n",
       "\n",
       "                                   시스템문장3  \n",
       "0                                     NaN  \n",
       "1                                     NaN  \n",
       "2                                     NaN  \n",
       "3                                     NaN  \n",
       "4                                     NaN  \n",
       "...                                   ...  \n",
       "51625                    좋은 결과 얻으시길 바랄게요.  \n",
       "51626         남편과 함께하는 좋은 외출 시간 되시길 바랄게요.  \n",
       "51627     좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.  \n",
       "51628             지인분들과 좋은 시간 보내셨으면 좋겠어요.  \n",
       "51629  원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.  \n",
       "\n",
       "[51630 rows x 13 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  나이  성별     상황키워드  신체질환 감정_대분류 감정_소분류  \\\n",
      "0           1  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
      "1           2  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
      "2           3  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
      "3           4  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
      "4           5  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
      "\n",
      "                                                 발화문  \\\n",
      "0                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
      "1     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
      "2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
      "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
      "4              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
      "\n",
      "                                              시스템문장1  \\\n",
      "0                        많이 힘드시겠어요. 주위에 의논할 상대가 있나요?   \n",
      "1           급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?   \n",
      "2  회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...   \n",
      "3  관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...   \n",
      "4  무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...   \n",
      "\n",
      "                                               사람문장2  \\\n",
      "0                그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.   \n",
      "1   최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.   \n",
      "2  잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...   \n",
      "3              직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.   \n",
      "4                상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!   \n",
      "\n",
      "                                              시스템문장2 사람문장3 시스템문장3  Neutral  \\\n",
      "0     혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.    NaN    NaN      0.0   \n",
      "1                           월급이 줄어든 만큼 소비를 줄일 계획이군요.   NaN    NaN      0.0   \n",
      "2          스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.   NaN    NaN      0.0   \n",
      "3                        직장 사람들과 이야기를 해 보겠다고 결심하셨군요.   NaN    NaN      0.0   \n",
      "4  항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...   NaN    NaN      0.0   \n",
      "\n",
      "   Happiness  Sadness     Angry  Disgust  Surprise  Fear  \n",
      "0        0.0      0.0  0.341024      0.0       0.0   0.0  \n",
      "1        0.0      0.0  0.341024      0.0       0.0   0.0  \n",
      "2        0.0      0.0  0.341024      0.0       0.0   0.0  \n",
      "3        0.0      0.0  0.341024      0.0       0.0   0.0  \n",
      "4        0.0      0.0  0.341024      0.0       0.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "# Rename '사람문장1' to '발화문'\n",
    "df.rename(columns={'사람문장1': '발화문'}, inplace=True)\n",
    "df.rename(columns={'연령': '나이'}, inplace=True)\n",
    "\n",
    "# Add new emotion columns with default value 0\n",
    "for col in emotion_columns:\n",
    "    df[col] = 0.0\n",
    "\n",
    "# Define lists for specific emotions\n",
    "list_disgust = ['한심한', '혐오스러운', '구역질 나는']\n",
    "list_surprise = ['당황', '충격 받은']\n",
    "list_sadness = ['고립된', '외로운', '슬픔', '염세적인', '실망한', '우울한', '환멸을 느끼는', '후회되는', \n",
    "                '낙담한', '눈물이 나는', '비통한', '마비된', '상처', '억울한', '버려진', '괴로워하는', \n",
    "                '질투하는', '희생된', '배신당한']\n",
    "list_angry = ['노여워하는', '짜증내는', '분노', '좌절한', '성가신', '안달하는', '툴툴대는', \n",
    "              '악의적인', '방어적인']\n",
    "list_fear = ['부끄러운', '죄책감의', '혼란스러운', '남의 시선을 의식하는', '열등감', '불안', '두려운', \n",
    "             '걱정스러운', '혼란스러운', '스트레스 받는', '회의적인', '초조한', '조심스러운', '취약한', \n",
    "             '당혹스러운']\n",
    "\n",
    "# Update 'Happiness' where '감정_대분류' is '기쁨'\n",
    "df.loc[df['감정_대분류'] == '기쁨', 'Happiness'] = emotion_mean\n",
    "df.loc[df['감정_소분류'].isin(list_surprise), 'Surprise'] = emotion_mean\n",
    "df.loc[df['감정_소분류'].isin(list_disgust), 'Disgust'] = emotion_mean\n",
    "df.loc[df['감정_소분류'].isin(list_fear), 'Fear'] = emotion_mean\n",
    "df.loc[df['감정_소분류'].isin(list_sadness), 'Sadness'] = emotion_mean\n",
    "df.loc[df['감정_소분류'].isin(list_angry), 'Angry'] = emotion_mean\n",
    "\n",
    "\n",
    "# Fill missing values with 0 (already initialized with 0.0)\n",
    "# df[emotion_columns] = df[emotion_columns].fillna(0.0)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "      <th>Highest_Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>아, 요즘 룸메랑 너무 자주 싸우게 돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602</th>\n",
       "      <td>아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14603</th>\n",
       "      <td>뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>그게 확실한 방법이겠지?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14606 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     발화문  Neutral  Happiness  \\\n",
       "0                                       어, 청소 니가 대신 해 줘!      0.0        0.0   \n",
       "1                                     둘 다 청소 하기 싫어. 귀찮아.      0.0        0.0   \n",
       "2                                         둘 다 하기 싫어서 화내.      0.0        0.0   \n",
       "3                                            그럼 방세는 어떡해.      0.0        0.0   \n",
       "4                              권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0   \n",
       "...                                                  ...      ...        ...   \n",
       "14601                             아, 요즘 룸메랑 너무 자주 싸우게 돼.      0.0        0.0   \n",
       "14602                  아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.      0.0        0.0   \n",
       "14603  뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...      0.0        0.0   \n",
       "14604            어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.      0.0        0.0   \n",
       "14605                                      그게 확실한 방법이겠지?      0.0        0.0   \n",
       "\n",
       "       Sadness  Angry  Disgust  Surprise  Fear  나이  성별 Highest_Emotion  \n",
       "0          0.0    0.2      0.0       0.0   0.0  27   0           Angry  \n",
       "1          0.0    0.2      0.0       0.0   0.0  27   0           Angry  \n",
       "2          0.0    0.4      0.0       0.0   0.0  27   0           Angry  \n",
       "3          0.5    0.0      0.0       0.0   0.0  27   0         Sadness  \n",
       "4          0.6    0.0      0.0       0.0   0.0  32   0         Sadness  \n",
       "...        ...    ...      ...       ...   ...  ..  ..             ...  \n",
       "14601      0.0    0.4      0.2       0.0   0.0  35   0           Angry  \n",
       "14602      0.0    0.4      0.2       0.0   0.0  35   0           Angry  \n",
       "14603      0.1    0.4      0.2       0.0   0.0  35   0           Angry  \n",
       "14604      0.1    0.1      0.0       0.0   0.0  35   0         Sadness  \n",
       "14605      0.1    0.1      0.1       0.0   0.0  35   0         Sadness  \n",
       "\n",
       "[14606 rows x 11 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_chunked_dial = df[['발화문', 'Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear', '나이', '성별']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = final_df.drop(columns=['Highest_Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>노년</td>\n",
       "      <td>남성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     발화문  Neutral  Happiness  \\\n",
       "0                              일은 왜 해도 해도 끝이 없을까? 화가 난다.      0.0        0.0   \n",
       "1         이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.      0.0        0.0   \n",
       "2      회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...      0.0        0.0   \n",
       "3      직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...      0.0        0.0   \n",
       "4                  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.      0.0        0.0   \n",
       "...                                                  ...      ...        ...   \n",
       "51625     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.      0.0        0.0   \n",
       "51626        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.      0.0        0.0   \n",
       "51627   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.      0.0        0.0   \n",
       "51628  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.      0.0        0.0   \n",
       "51629  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.      0.0        0.0   \n",
       "\n",
       "        Sadness     Angry  Disgust  Surprise      Fear  나이  성별  \n",
       "0      0.000000  0.341024      0.0       0.0  0.000000  청년  여성  \n",
       "1      0.000000  0.341024      0.0       0.0  0.000000  청년  여성  \n",
       "2      0.000000  0.341024      0.0       0.0  0.000000  청년  여성  \n",
       "3      0.000000  0.341024      0.0       0.0  0.000000  청년  여성  \n",
       "4      0.000000  0.341024      0.0       0.0  0.000000  청년  여성  \n",
       "...         ...       ...      ...       ...       ...  ..  ..  \n",
       "51625  0.000000  0.341024      0.0       0.0  0.000000  노년  남성  \n",
       "51626  0.000000  0.000000      0.0       0.0  0.341024  노년  여성  \n",
       "51627  0.341024  0.000000      0.0       0.0  0.000000  노년  여성  \n",
       "51628  0.000000  0.000000      0.0       0.0  0.341024  노년  여성  \n",
       "51629  0.341024  0.000000      0.0       0.0  0.000000  노년  여성  \n",
       "\n",
       "[51630 rows x 10 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_chunked_dial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['청년', '중년', '노년', '청소년'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_groups = df['나이'].unique()\n",
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/4226038590.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_chunked_dial['성별'] = from_chunked_dial['성별'].map({'남성': 0, '여성': 1})\n",
      "/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/4226038590.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from_chunked_dial['나이'] = from_chunked_dial['나이'].map({'청소년': teen, '청년' : adult, '중년' : midyear, '노년': senior})\n"
     ]
    }
   ],
   "source": [
    "def mean_age(a, b):\n",
    "    age = (a + b) / 2\n",
    "    return int(round(age))\n",
    "\n",
    "teen = mean_age(13, 18)\n",
    "adult = mean_age(19, 29)\n",
    "midyear = mean_age(30, 49)\n",
    "senior = mean_age(50, 80)\n",
    "\n",
    "\n",
    "from_chunked_dial['성별'] = from_chunked_dial['성별'].map({'남성': 0, '여성': 1})\n",
    "from_chunked_dial['나이'] = from_chunked_dial['나이'].map({'청소년': teen, '청년' : adult, '중년' : midyear, '노년': senior})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     발화문  Neutral  Happiness  \\\n",
       "0                              일은 왜 해도 해도 끝이 없을까? 화가 난다.      0.0        0.0   \n",
       "1         이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.      0.0        0.0   \n",
       "2      회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...      0.0        0.0   \n",
       "3      직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...      0.0        0.0   \n",
       "4                  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.      0.0        0.0   \n",
       "...                                                  ...      ...        ...   \n",
       "51625     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.      0.0        0.0   \n",
       "51626        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.      0.0        0.0   \n",
       "51627   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.      0.0        0.0   \n",
       "51628  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.      0.0        0.0   \n",
       "51629  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.      0.0        0.0   \n",
       "\n",
       "        Sadness     Angry  Disgust  Surprise      Fear  나이  성별  \n",
       "0      0.000000  0.341024      0.0       0.0  0.000000  24   1  \n",
       "1      0.000000  0.341024      0.0       0.0  0.000000  24   1  \n",
       "2      0.000000  0.341024      0.0       0.0  0.000000  24   1  \n",
       "3      0.000000  0.341024      0.0       0.0  0.000000  24   1  \n",
       "4      0.000000  0.341024      0.0       0.0  0.000000  24   1  \n",
       "...         ...       ...      ...       ...       ...  ..  ..  \n",
       "51625  0.000000  0.341024      0.0       0.0  0.000000  65   0  \n",
       "51626  0.000000  0.000000      0.0       0.0  0.341024  65   1  \n",
       "51627  0.341024  0.000000      0.0       0.0  0.000000  65   1  \n",
       "51628  0.000000  0.000000      0.0       0.0  0.341024  65   1  \n",
       "51629  0.341024  0.000000      0.0       0.0  0.000000  65   1  \n",
       "\n",
       "[51630 rows x 10 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_chunked_dial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Happiness 컬럼에서 0이 아닌 것 중 3491개 임의 추출\n",
    "happiness_non_zero = from_chunked_dial[from_chunked_dial['Happiness'] != 0]\n",
    "happiness_sample = happiness_non_zero.sample(n=3491, random_state=42)\n",
    "\n",
    "disgust_non_zero = from_chunked_dial[from_chunked_dial['Disgust'] != 0]\n",
    "\n",
    "surprise_non_zero = from_chunked_dial[from_chunked_dial['Surprise'] != 0]\n",
    "\n",
    "# Fear 컬럼에서 0이 아닌 것 중 2910개 임의 추출\n",
    "fear_non_zero = from_chunked_dial[from_chunked_dial['Fear'] != 0]\n",
    "fear_sample = fear_non_zero.sample(n=2910, random_state=42)\n",
    "\n",
    "\n",
    "selected = pd.concat([happiness_sample, disgust_non_zero, surprise_non_zero, fear_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_edited = original_edited.drop(columns=['Highest_Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>아, 요즘 룸메랑 너무 자주 싸우게 돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602</th>\n",
       "      <td>아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14603</th>\n",
       "      <td>뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14605</th>\n",
       "      <td>그게 확실한 방법이겠지?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14606 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     발화문  Neutral  Happiness  \\\n",
       "0                                       어, 청소 니가 대신 해 줘!      0.0        0.0   \n",
       "1                                     둘 다 청소 하기 싫어. 귀찮아.      0.0        0.0   \n",
       "2                                         둘 다 하기 싫어서 화내.      0.0        0.0   \n",
       "3                                            그럼 방세는 어떡해.      0.0        0.0   \n",
       "4                              권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0   \n",
       "...                                                  ...      ...        ...   \n",
       "14601                             아, 요즘 룸메랑 너무 자주 싸우게 돼.      0.0        0.0   \n",
       "14602                  아, 룸메가 방을 너무 지저분하게 써. 음식물도 막 버리고.      0.0        0.0   \n",
       "14603  뭐 화를 낸 것까진 아니지만, 한 달 전 쯤에 좀 확실하게 얘기를 해뒀거든. 근데 ...      0.0        0.0   \n",
       "14604            어. 고등학교 동창인데, 같은 동네 오게 돼서 같이 룸메로 살게 됐지.      0.0        0.0   \n",
       "14605                                      그게 확실한 방법이겠지?      0.0        0.0   \n",
       "\n",
       "       Sadness  Angry  Disgust  Surprise  Fear  나이  성별  \n",
       "0          0.0    0.2      0.0       0.0   0.0  27   0  \n",
       "1          0.0    0.2      0.0       0.0   0.0  27   0  \n",
       "2          0.0    0.4      0.0       0.0   0.0  27   0  \n",
       "3          0.5    0.0      0.0       0.0   0.0  27   0  \n",
       "4          0.6    0.0      0.0       0.0   0.0  32   0  \n",
       "...        ...    ...      ...       ...   ...  ..  ..  \n",
       "14601      0.0    0.4      0.2       0.0   0.0  35   0  \n",
       "14602      0.0    0.4      0.2       0.0   0.0  35   0  \n",
       "14603      0.1    0.4      0.2       0.0   0.0  35   0  \n",
       "14604      0.1    0.1      0.0       0.0   0.0  35   0  \n",
       "14605      0.1    0.1      0.1       0.0   0.0  35   0  \n",
       "\n",
       "[14606 rows x 10 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = selected[['발화문', 'Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear', '나이', '성별']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25404</th>\n",
       "      <td>새로운 아르바이트를 하는데 내가 일도 잘 못 하는 것 같고 민폐인 것 같아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25405</th>\n",
       "      <td>엄마 아빠와 나의 의견이 달라서 혼란스러워.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25406</th>\n",
       "      <td>친구들끼리 술자리에 모이면 항상 싸움이 나서 스트레스받아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25407</th>\n",
       "      <td>학교에서 나를 괴롭히는 친구들이 나에게 부탁을 할 때마다 거절하지 못하겠어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25408</th>\n",
       "      <td>회사 부장님이 사적인 것에 대해 뭐라 하셔서 스트레스받아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25409 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              발화문  Neutral  Happiness  \\\n",
       "0                                어, 청소 니가 대신 해 줘!      0.0        0.0   \n",
       "1                              둘 다 청소 하기 싫어. 귀찮아.      0.0        0.0   \n",
       "2                                  둘 다 하기 싫어서 화내.      0.0        0.0   \n",
       "3                                     그럼 방세는 어떡해.      0.0        0.0   \n",
       "4                       권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0        0.0   \n",
       "...                                           ...      ...        ...   \n",
       "25404  새로운 아르바이트를 하는데 내가 일도 잘 못 하는 것 같고 민폐인 것 같아.      0.0        0.0   \n",
       "25405                    엄마 아빠와 나의 의견이 달라서 혼란스러워.      0.0        0.0   \n",
       "25406            친구들끼리 술자리에 모이면 항상 싸움이 나서 스트레스받아.      0.0        0.0   \n",
       "25407  학교에서 나를 괴롭히는 친구들이 나에게 부탁을 할 때마다 거절하지 못하겠어.      0.0        0.0   \n",
       "25408            회사 부장님이 사적인 것에 대해 뭐라 하셔서 스트레스받아.      0.0        0.0   \n",
       "\n",
       "       Sadness  Angry  Disgust  Surprise      Fear  나이  성별  \n",
       "0          0.0    0.2      0.0       0.0  0.000000  27   0  \n",
       "1          0.0    0.2      0.0       0.0  0.000000  27   0  \n",
       "2          0.0    0.4      0.0       0.0  0.000000  27   0  \n",
       "3          0.5    0.0      0.0       0.0  0.000000  27   0  \n",
       "4          0.6    0.0      0.0       0.0  0.000000  32   0  \n",
       "...        ...    ...      ...       ...       ...  ..  ..  \n",
       "25404      0.0    0.0      0.0       0.0  0.341024  24   0  \n",
       "25405      0.0    0.0      0.0       0.0  0.341024  16   1  \n",
       "25406      0.0    0.0      0.0       0.0  0.341024  65   0  \n",
       "25407      0.0    0.0      0.0       0.0  0.341024  16   0  \n",
       "25408      0.0    0.0      0.0       0.0  0.341024  24   1  \n",
       "\n",
       "[25409 rows x 10 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_training = pd.concat([original_edited, selected], ignore_index=True)\n",
    "for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화문</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권태긴줄 알았는데 다른 사람이 생겼나보더라고.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>그냥 걷고 있어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>내가 애정 표현을 잘 못해서 자주 싸우긴 했어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오늘 헤어졌어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>룸메이트와 너무 자주 싸우게 돼.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>그러고 싶은데 보증금 때문에 그럴 수가 없어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>이 회사가 이번 시즌 마지막 회사였어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>부모님한테 아직 말 안했는데 말하기가 두려워.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>아니. 입맛도 없어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>응. 혼 났지.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>그럴 시간도 없다.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>부모님도 다 슬퍼하셔.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>그래, 고마워.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>해봤는데, 전화를 안 받네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>맨날 그래 얘는.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>어. 크게 다치진 않았는데.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>일주일에 다섯번은 먹는다니까?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>응. 그래봐야지. 해피도 오래 살긴 했어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>다들 지쳤어. 나도 지쳤구, 이제.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>어제 밤 새서 작성한 기획안 다시 해야되네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>모르겠어. 좀 최대한 추스려볼게.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>청소 좀 하고 살자.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>응. 그 동안 괜찮았는데.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>응. 인제 병원에서 퇴원하는 길이야.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>이제 두 달 지났어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>어제 지진 있었잖아. 다행히 다치진 않았어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>옆에서 친구가 넘어져서 발목 다쳤어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>아니 룸메이트 하기 전에는 그냥 학교에서만 알던 사이?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>또 술 먹고 그랬지 뭐. 지금 병원에 계셔.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>했는데 소용 없어. 다 포기했어, 지금은.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>응. 걷고 있어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>아휴. 이제 내년 거 준비해야지 뭐.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>너무 죄송해서 말도 못하겠어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>응. 다리 조금 다쳤는데 좀 쉬면 괜찮아질 것 같아.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>다른 여자가 생겼나봐.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>대학교 때 동아리 선배였었어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>우리는 싸울 일이 전혀 없었어.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       발화문  Neutral  Happiness  Sadness  \\\n",
       "0                         어, 청소 니가 대신 해 줘!      0.0   0.000000      0.0   \n",
       "1                       둘 다 청소 하기 싫어. 귀찮아.      0.0   0.000000      0.0   \n",
       "2                           둘 다 하기 싫어서 화내.      0.0   0.000000      0.0   \n",
       "3                              그럼 방세는 어떡해.      0.0   0.000000      0.5   \n",
       "4                권태긴줄 알았는데 다른 사람이 생겼나보더라고.      0.0   0.000000      0.6   \n",
       "5                                그냥 걷고 있어.      0.0   0.000000      0.2   \n",
       "6             어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.      0.0   0.000000      0.0   \n",
       "7            처음 학원에서 만났다가 서로 좋아해서 사귀게 되었지.      0.0   0.111111      0.0   \n",
       "8               내가 애정 표현을 잘 못해서 자주 싸우긴 했어.      0.0   0.000000      0.5   \n",
       "9                                 오늘 헤어졌어.      0.0   0.000000      0.4   \n",
       "10                      룸메이트와 너무 자주 싸우게 돼.      0.0   0.000000      0.4   \n",
       "11               그러고 싶은데 보증금 때문에 그럴 수가 없어.      0.0   0.000000      0.4   \n",
       "12                   이 회사가 이번 시즌 마지막 회사였어.      0.0   0.000000      0.3   \n",
       "13               부모님한테 아직 말 안했는데 말하기가 두려워.      0.0   0.000000      0.4   \n",
       "14                             아니. 입맛도 없어.      0.0   0.000000      0.5   \n",
       "15                                응. 혼 났지.      0.0   0.000000      0.2   \n",
       "16                              그럴 시간도 없다.      0.0   0.000000      0.5   \n",
       "17                            부모님도 다 슬퍼하셔.      0.0   0.000000      0.4   \n",
       "18                                그래, 고마워.      0.0   0.000000      0.0   \n",
       "19                         해봤는데, 전화를 안 받네.      0.0   0.000000      0.2   \n",
       "20                               맨날 그래 얘는.      0.0   0.000000      0.0   \n",
       "21                         어. 크게 다치진 않았는데.      0.0   0.000000      0.1   \n",
       "22                        일주일에 다섯번은 먹는다니까?      0.0   0.000000      0.0   \n",
       "23  그저께 아파해서 병원을 갔는데 괜찮아지나 싶더니 결국엔 이렇게 됐네.      0.0   0.000000      0.7   \n",
       "24            다들 마음이 안좋지. 집에 들어가기도 싫네, 나는.      0.0   0.000000      0.7   \n",
       "25                 응. 그래봐야지. 해피도 오래 살긴 했어.      0.0   0.000000      0.7   \n",
       "26       그렇지. 뭐 생명까지는 괜찮은데. 우리 마음에 지장이 있네.      0.0   0.000000      0.7   \n",
       "27  지난 번에도 드시고 다친 적 있었거든, 얼굴? 이번에 또 그런 거야.      0.0   0.000000      0.5   \n",
       "28                     다들 지쳤어. 나도 지쳤구, 이제.      0.0   0.000000      0.5   \n",
       "29                어제 밤 새서 작성한 기획안 다시 해야되네.      0.0   0.000000      0.7   \n",
       "30           그렇지. 아픈데도 했더니, 참, 근데 맞는 말이라서.      0.0   0.000000      0.6   \n",
       "31      응. 마음 좀 추스려야지. 근데 내가 잘하는게 없는 거 같네.      0.0   0.000000      0.9   \n",
       "32                      모르겠어. 좀 최대한 추스려볼게.      0.0   0.000000      0.6   \n",
       "33        노력하면 괜찮아지겠지. 근데 내가 실력이 부족한 건 맞아.      0.0   0.000000      0.6   \n",
       "34                             청소 좀 하고 살자.      0.0   0.000000      0.0   \n",
       "35                          응. 그 동안 괜찮았는데.      0.0   0.000000      0.3   \n",
       "36                    응. 인제 병원에서 퇴원하는 길이야.      0.0   0.111111      0.1   \n",
       "37                             이제 두 달 지났어.      0.0   0.000000      0.6   \n",
       "38                어제 지진 있었잖아. 다행히 다치진 않았어.      0.0   0.000000      0.0   \n",
       "39                    옆에서 친구가 넘어져서 발목 다쳤어.      0.0   0.000000      0.2   \n",
       "40          아니 룸메이트 하기 전에는 그냥 학교에서만 알던 사이?      0.0   0.000000      0.0   \n",
       "41                또 술 먹고 그랬지 뭐. 지금 병원에 계셔.      0.0   0.000000      0.3   \n",
       "42                 했는데 소용 없어. 다 포기했어, 지금은.      0.0   0.000000      0.5   \n",
       "43                               응. 걷고 있어.      0.0   0.000000      0.4   \n",
       "44                    아휴. 이제 내년 거 준비해야지 뭐.      0.0   0.000000      0.6   \n",
       "45                        너무 죄송해서 말도 못하겠어.      0.0   0.000000      0.6   \n",
       "46           응. 다리 조금 다쳤는데 좀 쉬면 괜찮아질 것 같아.      0.0   0.000000      0.2   \n",
       "47                            다른 여자가 생겼나봐.      0.0   0.000000      0.9   \n",
       "48                        대학교 때 동아리 선배였었어.      0.0   0.000000      0.8   \n",
       "49                       우리는 싸울 일이 전혀 없었어.      0.0   0.000000      0.2   \n",
       "\n",
       "    Angry  Disgust  Surprise  Fear  나이  성별  \n",
       "0     0.2      0.0  0.000000   0.0  27   0  \n",
       "1     0.2      0.0  0.000000   0.0  27   0  \n",
       "2     0.4      0.0  0.000000   0.0  27   0  \n",
       "3     0.0      0.0  0.000000   0.0  27   0  \n",
       "4     0.0      0.0  0.000000   0.0  32   0  \n",
       "5     0.0      0.0  0.000000   0.0  32   0  \n",
       "6     0.2      0.5  0.000000   0.0  32   0  \n",
       "7     0.0      0.0  0.000000   0.0  28   0  \n",
       "8     0.0      0.0  0.000000   0.0  28   0  \n",
       "9     0.0      0.0  0.000000   0.0  28   0  \n",
       "10    0.0      0.0  0.000000   0.0  28   0  \n",
       "11    0.0      0.0  0.000000   0.0  28   0  \n",
       "12    0.0      0.0  0.000000   0.0  28   0  \n",
       "13    0.0      0.0  0.000000   0.1  28   0  \n",
       "14    0.0      0.0  0.000000   0.0  28   0  \n",
       "15    0.1      0.0  0.000000   0.0  28   0  \n",
       "16    0.0      0.0  0.000000   0.0  28   0  \n",
       "17    0.0      0.0  0.000000   0.0  28   0  \n",
       "18    0.0      0.0  0.000000   0.0  28   0  \n",
       "19    0.0      0.0  0.000000   0.0  28   0  \n",
       "20    0.4      0.0  0.000000   0.0  28   0  \n",
       "21    0.0      0.0  0.000000   0.0  28   0  \n",
       "22    0.2      0.0  0.222222   0.0  28   0  \n",
       "23    0.0      0.0  0.000000   0.0  28   0  \n",
       "24    0.0      0.0  0.000000   0.0  28   0  \n",
       "25    0.0      0.0  0.000000   0.0  28   0  \n",
       "26    0.0      0.0  0.000000   0.0  28   0  \n",
       "27    0.0      0.0  0.000000   0.0  28   0  \n",
       "28    0.1      0.0  0.000000   0.0  28   0  \n",
       "29    0.0      0.0  0.000000   0.0  28   0  \n",
       "30    0.0      0.0  0.000000   0.0  28   0  \n",
       "31    0.0      0.0  0.000000   0.0  28   0  \n",
       "32    0.0      0.0  0.000000   0.0  28   0  \n",
       "33    0.0      0.0  0.000000   0.0  28   0  \n",
       "34    0.6      0.0  0.000000   0.0  28   0  \n",
       "35    0.0      0.0  0.000000   0.0  37   0  \n",
       "36    0.0      0.0  0.000000   0.0  37   0  \n",
       "37    0.0      0.0  0.000000   0.0  40   1  \n",
       "38    0.0      0.0  0.111111   0.0  37   0  \n",
       "39    0.0      0.0  0.000000   0.0  37   0  \n",
       "40    0.0      0.0  0.000000   0.0  28   1  \n",
       "41    0.0      0.0  0.000000   0.0  28   1  \n",
       "42    0.1      0.0  0.000000   0.0  28   1  \n",
       "43    0.0      0.0  0.000000   0.0  28   1  \n",
       "44    0.0      0.0  0.000000   0.0  28   1  \n",
       "45    0.0      0.0  0.000000   0.0  28   1  \n",
       "46    0.0      0.0  0.000000   0.0  28   1  \n",
       "47    0.0      0.0  0.000000   0.0  40   1  \n",
       "48    0.0      0.0  0.000000   0.0  40   1  \n",
       "49    0.1      0.0  0.000000   0.0  40   1  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_training.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련세트 테스트 세트 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 20327\n",
      "Testing set size: 5082\n",
      "\n",
      "Training data sample:\n",
      "24259                            나는 젊은 시절에 몇번의 사업실패를 겪었다네.\n",
      "23403    회사에서 젊은 신입들이 가지고 있는 공과 사의 단호함을 보면 내심 부러우면서도 불안해져.\n",
      "8714                                         장례를 해야될 것 같애.\n",
      "4417               유기견 다큐멘터리 봤는데 사람들, 책임감 없는 사람들 진짜 너무하더라.\n",
      "542                                    지금 혼자서 밖에 걸어다니고 있지.\n",
      "Name: 발화문, dtype: object\n",
      "       Neutral  Happiness  Sadness  Angry  Disgust  Surprise      Fear  나이  성별\n",
      "24259      0.0        0.0      0.0    0.0      0.0       0.0  0.341024  65   0\n",
      "23403      0.0        0.0      0.0    0.0      0.0       0.0  0.341024  40   0\n",
      "8714       0.0        0.0      0.5    0.0      0.0       0.0  0.000000  29   0\n",
      "4417       0.0        0.0      0.0    0.2      0.3       0.0  0.000000  24   1\n",
      "542        0.0        0.0      0.4    0.0      0.0       0.0  0.000000  31   0\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and targets\n",
    "X = for_training['발화문']  # Features are the utterances\n",
    "y = for_training.drop(columns=['발화문'])  # Targets include emotion scores, age, and gender\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of each set\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "# Display a sample from the training data\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 및 모델 로드 (이전 코드와 동일)\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name) # 토크나이저 초기화\n",
    "max_len = 128\n",
    "bert_model = TFBertModel.from_pretrained(model_name)\n",
    "\n",
    "# 데이터 인코딩 함수\n",
    "def encode_data(dataframe, tokenizer, max_len=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in dataframe:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf',\n",
    "        )\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "    return tf.concat(input_ids, axis=0), tf.concat(attention_masks, axis=0)\n",
    "\n",
    "# 연결지어주기\n",
    "# 데이터 인코딩\n",
    "train_input_ids, train_attention_mask = encode_data(X_train, tokenizer)\n",
    "val_input_ids, val_attention_mask = encode_data(X_test, tokenizer)\n",
    "\n",
    "# 레이블 준비\n",
    "train_emotions = y_train[['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']].values\n",
    "train_gender = y_train['성별'].values\n",
    "train_labels = y_train['나이'].values\n",
    "\n",
    "val_emotions = y_test[['Neutral', 'Happiness', 'Sadness', 'Angry', 'Disgust', 'Surprise', 'Fear']].values\n",
    "val_gender = y_test['성별'].values\n",
    "val_labels = y_test['나이'].values\n",
    "\n",
    "# # Tokenize text data\n",
    "# def tokenize_and_encode(texts):\n",
    "#     return tokenizer(\n",
    "#         texts.tolist(),\n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#         max_length=128,\n",
    "#         return_tensors=\"tf\"\n",
    "#     )\n",
    "\n",
    "# # encodings = tokenizer(\n",
    "# #     texts.to_list(),\n",
    "# #     padding='max_length',\n",
    "# #     truncation=True,\n",
    "# #     max_length=128,\n",
    "# #     return_tensors='tf'\n",
    "# # )\n",
    "\n",
    "# # Encode train and test data\n",
    "# train_encodings = tokenize_and_encode(X_train)\n",
    "# test_encodings = tokenize_and_encode(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24259                            나는 젊은 시절에 몇번의 사업실패를 겪었다네.\n",
       "23403    회사에서 젊은 신입들이 가지고 있는 공과 사의 단호함을 보면 내심 부러우면서도 불안해져.\n",
       "8714                                         장례를 해야될 것 같애.\n",
       "4417               유기견 다큐멘터리 봤는데 사람들, 책임감 없는 사람들 진짜 너무하더라.\n",
       "542                                    지금 혼자서 밖에 걸어다니고 있지.\n",
       "                               ...                        \n",
       "21575               친구가 다른 친구의 남자친구와 몰래 만나고 있었어. 너무 충격적이야.\n",
       "5390                                     해피가 어젯밤에 세상을 떠났어.\n",
       "860                                       룸메와 너무 자주 싸우게 돼.\n",
       "15795                      이번 승진으로 개인 사무실을 갖게 되어 무척 만족스러워.\n",
       "23654        형이랑 장난치다가 실수로 형의 눈에 상처를 냈어. 피가 너무 많이 나서 당황했어.\n",
       "Name: 발화문, Length: 20327, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 변환\n",
    "train_emotions = tf.convert_to_tensor(train_emotions, dtype=tf.float32)\n",
    "train_gender = tf.convert_to_tensor(train_gender, dtype=tf.float32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)\n",
    "\n",
    "val_emotions = tf.convert_to_tensor(val_emotions, dtype=tf.float32)\n",
    "val_gender = tf.convert_to_tensor(val_gender, dtype=tf.float32)\n",
    "val_labels = tf.convert_to_tensor(val_labels, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/3903446937.py\", line 35, in train_step  *\n        emotion_loss = self.compiled_loss(y['emotion_regression'], y_pred['emotion_regression'], regularization_losses=self.losses)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 252, in __call__  *\n        self.build(y_pred)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 193, in build  *\n        self._losses = self._conform_to_outputs(y_pred, self._losses)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 63, in _conform_to_outputs  *\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 819, in map_to_output_names  *\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['emotion_regression', 'gender_classification', 'age_regression']). Valid mode output names: ['output_1']. Received struct is: {'emotion_regression': 'mean_squared_error', 'gender_classification': 'binary_crossentropy', 'age_regression': 'mean_squared_error'}.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 65\u001b[0m\n\u001b[1;32m     50\u001b[0m custom_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m),\n\u001b[1;32m     52\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     }\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     83\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileh2y6jh2l.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file71ltr_hc.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     12\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 13\u001b[0m     emotion_loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     gender_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_loss, (ag__\u001b[38;5;241m.\u001b[39mld(y)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_classification\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_classification\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mdict\u001b[39m(regularization_losses\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlosses), fscope)\n\u001b[1;32m     15\u001b[0m     age_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_loss, (ag__\u001b[38;5;241m.\u001b[39mld(y)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_regression\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_regression\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mdict\u001b[39m(regularization_losses\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlosses), fscope)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filerxyt9751.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_built\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     43\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten, (ag__\u001b[38;5;241m.\u001b[39mld(y_true),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filerxyt9751.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body\u001b[39m():\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filehwyxetek.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__build\u001b[0;34m(self, y_pred)\u001b[0m\n\u001b[1;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28msuper\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(LossesContainer), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\u001b[38;5;241m.\u001b[39mbuild, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_maybe_broadcast_to_outputs, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conform_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_losses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_get_loss_object, ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_losses,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiurieaf4.py:26\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___conform_to_outputs\u001b[0;34m(self, outputs, struct)\u001b[0m\n\u001b[1;32m     24\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     25\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 26\u001b[0m struct \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap_to_output_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstruct\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m struct \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(map_missing_dict_keys), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(struct)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileqqb7vz3y.py:100\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__map_to_output_names\u001b[0;34m(y_pred, output_names, struct)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     99\u001b[0m new_struct \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_struct\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mand_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_are_flat_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstruct\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstruct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileqqb7vz3y.py:63\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__map_to_output_names.<locals>.if_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body\u001b[39m():\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstruct\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_1\u001b[39m():\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (do_return, retval_)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileqqb7vz3y.py:59\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__map_to_output_names.<locals>.if_body_2.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body\u001b[39m():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;167;01mValueError\u001b[39;00m), (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound unexpected losses or metrics that do not correspond to any Model output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(struct)\u001b[38;5;241m.\u001b[39mkeys,\u001b[38;5;250m \u001b[39m(),\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;250m \u001b[39mfscope)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Valid mode output names: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(output_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Received struct is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(struct)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/3903446937.py\", line 35, in train_step  *\n        emotion_loss = self.compiled_loss(y['emotion_regression'], y_pred['emotion_regression'], regularization_losses=self.losses)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 252, in __call__  *\n        self.build(y_pred)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 193, in build  *\n        self._losses = self._conform_to_outputs(y_pred, self._losses)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 63, in _conform_to_outputs  *\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/compile_utils.py\", line 819, in map_to_output_names  *\n        raise ValueError(\n\n    ValueError: Found unexpected losses or metrics that do not correspond to any Model output: dict_keys(['emotion_regression', 'gender_classification', 'age_regression']). Valid mode output names: ['output_1']. Received struct is: {'emotion_regression': 'mean_squared_error', 'gender_classification': 'binary_crossentropy', 'age_regression': 'mean_squared_error'}.\n"
     ]
    }
   ],
   "source": [
    "# class CustomBERTModel(tf.keras.Model):\n",
    "#     def __init__(self, bert_model):\n",
    "#         super(CustomBERTModel, self).__init__()\n",
    "#         self.bert = bert_model\n",
    "#         self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "#         self.emotion_dense = tf.keras.layers.Dense(7, activation='linear', name='emotion_regression')\n",
    "#         self.gender_dense = tf.keras.layers.Dense(1, activation='sigmoid', name='gender_classification')\n",
    "#         self.age_dense = tf.keras.layers.Dense(1, activation='linear', name='age_regression')\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         input_ids, attention_mask, emotions, gender = inputs\n",
    "        \n",
    "#         bert_output = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
    "#         pooled_output = bert_output.pooler_output\n",
    "        \n",
    "#         x = self.dropout(pooled_output, training=training)\n",
    "#         gender = tf.expand_dims(gender, axis=-1)\n",
    "#         combined_input = tf.concat([x, emotions, gender], axis=1)\n",
    "        \n",
    "#         emotion_output = self.emotion_dense(combined_input)\n",
    "#         gender_output = self.gender_dense(combined_input)\n",
    "#         age_output = self.age_dense(combined_input)\n",
    "        \n",
    "#         return {\n",
    "#             'emotion_regression': emotion_output,\n",
    "#             'gender_classification': gender_output,\n",
    "#             'age_regression': age_output\n",
    "#         }\n",
    "\n",
    "#     def train_step(self, data):\n",
    "#         x, y = data\n",
    "        \n",
    "#         with tf.GradientTape() as tape:\n",
    "#             y_pred = self(x, training=True)\n",
    "#             emotion_loss = self.compiled_loss(y['emotion_regression'], y_pred['emotion_regression'], regularization_losses=self.losses)\n",
    "#             gender_loss = self.compiled_loss(y['gender_classification'], y_pred['gender_classification'], regularization_losses=self.losses)\n",
    "#             age_loss = self.compiled_loss(y['age_regression'], y_pred['age_regression'], regularization_losses=self.losses)\n",
    "#             total_loss = emotion_loss + gender_loss + age_loss\n",
    "\n",
    "#         trainable_vars = self.trainable_variables\n",
    "#         gradients = tape.gradient(total_loss, trainable_vars)\n",
    "        \n",
    "#         self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "#         return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# # 모델 컴파일\n",
    "# custom_model = CustomBERTModel(bert_model)\n",
    "# custom_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=3e-5),\n",
    "#     loss={\n",
    "#         'emotion_regression': 'mean_squared_error',\n",
    "#         'gender_classification': 'binary_crossentropy',\n",
    "#         'age_regression': 'mean_squared_error'\n",
    "#     },\n",
    "#     metrics={\n",
    "#         'emotion_regression': 'mae',\n",
    "#         'gender_classification': 'accuracy',\n",
    "#         'age_regression': 'mae'\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 모델 훈련\n",
    "# history = custom_model.fit(\n",
    "#     x=[train_input_ids, train_attention_mask, train_emotions, train_gender],\n",
    "#     y={\n",
    "#         'emotion_regression': train_emotions,\n",
    "#         'gender_classification': train_gender,\n",
    "#         'age_regression': train_labels\n",
    "#     },\n",
    "#     validation_data=(\n",
    "#         [val_input_ids, val_attention_mask, val_emotions, val_gender],\n",
    "#         {\n",
    "#             'emotion_regression': val_emotions,\n",
    "#             'gender_classification': val_gender,\n",
    "#             'age_regression': val_labels\n",
    "#         }\n",
    "#     ),\n",
    "#     epochs=10,\n",
    "#     batch_size=16,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: Exception encountered when calling layer 'tf_bert_model_23' (type TFBertModel).\n\nin user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n        return func(self, **unpacked_inputs)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1209, in call  *\n        outputs = self.bert(\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1005, in error_handler  *\n        del filtered_tb\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n        inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n\n    TypeError: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n    \n    in user code:\n    \n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 887, in call  *\n            embedding_output = self.embeddings(\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1000, in error_handler  *\n            filtered_tb = _process_traceback_frames(e.__traceback__)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 162, in error_handler  **\n            raise ag__.converted_call(ag__.ld(new_e).with_traceback, (ag__.ld(e).__traceback__,), None, fscope_1) from None\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 34, in error_handler\n            retval__1 = ag__.converted_call(ag__.ld(fn), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call  **\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n            inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n    \n        TypeError: Exception encountered when calling layer 'embeddings' (type TFBertEmbeddings).\n        \n        in user code:\n        \n            File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 182, in call  *\n                inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n        \n            TypeError: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64\n        \n        \n        Call arguments received by layer 'embeddings' (type TFBertEmbeddings):\n          • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 128), dtype=int32)\n          • inputs_embeds=None\n          • past_key_values_length=0\n          • training=False\n    \n    \n    Call arguments received by layer 'bert' (type TFBertMainLayer):\n      • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n      • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=True\n      • output_attentions=False\n      • output_hidden_states=False\n      • return_dict=True\n      • training=False\n\n\nCall arguments received by layer 'tf_bert_model_23' (type TFBertModel):\n  • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:540\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[270], line 13\u001b[0m, in \u001b[0;36mCustomBERTModel.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     11\u001b[0m input_ids, attention_mask, emotions, gender \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 13\u001b[0m bert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m bert_output\u001b[38;5;241m.\u001b[39mpooler_output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filek2n22r2t.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filerloun0v8.py:31\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m     30\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:44\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_traceback_filtering_enabled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_process_traceback_frames), (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(filtered_tb),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filen05eag34.py:242\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m name_scope \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_scope\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_in_functional_construction_mode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filen05eag34.py:187\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.else_body_11\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(autocast_variable)\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m--> 187\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_8\u001b[39m():\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py:162\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(arguments_context), if_body_5, else_body_5, get_state_6, set_state_6, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments_context\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(new_e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope_1)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filek2n22r2t.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6pkwerbo.py:127\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    126\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(token_type_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_6, else_body_6, get_state_6, set_state_6, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(shape_list), (ag__\u001b[38;5;241m.\u001b[39mld(attention_mask),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:44\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_tb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_traceback_filtering_enabled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:40\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(_process_traceback_frames), (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(filtered_tb),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file6d5181ro.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__error_handler.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filen05eag34.py:242\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m name_scope \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_scope\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_in_functional_construction_mode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_11\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs[\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filen05eag34.py:187\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.else_body_11\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(autocast_variable)\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m--> 187\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_8\u001b[39m():\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py:162\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(arguments_context), if_body_5, else_body_5, get_state_6, set_state_6, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_e\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments_context\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(new_e)\u001b[38;5;241m.\u001b[39mwith_traceback, (ag__\u001b[38;5;241m.\u001b[39mld(e)\u001b[38;5;241m.\u001b[39m__traceback__,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py:34\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__inject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(fn), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(args)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(kwargs)), fscope_1)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py:46\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs_embeds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(shape_list), (ag__\u001b[38;5;241m.\u001b[39mld(inputs_embeds),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(check_embeddings_within_bounds), (ag__\u001b[38;5;241m.\u001b[39mld(input_ids), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 41\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'tf_bert_model_23' (type TFBertModel).\n\nin user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n        return func(self, **unpacked_inputs)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1209, in call  *\n        outputs = self.bert(\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1005, in error_handler  *\n        del filtered_tb\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n        inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n\n    TypeError: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n    \n    in user code:\n    \n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 887, in call  *\n            embedding_output = self.embeddings(\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1000, in error_handler  *\n            filtered_tb = _process_traceback_frames(e.__traceback__)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 162, in error_handler  **\n            raise ag__.converted_call(ag__.ld(new_e).with_traceback, (ag__.ld(e).__traceback__,), None, fscope_1) from None\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 34, in error_handler\n            retval__1 = ag__.converted_call(ag__.ld(fn), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call  **\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n            inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n    \n        TypeError: Exception encountered when calling layer 'embeddings' (type TFBertEmbeddings).\n        \n        in user code:\n        \n            File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 182, in call  *\n                inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n        \n            TypeError: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64\n        \n        \n        Call arguments received by layer 'embeddings' (type TFBertEmbeddings):\n          • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 128), dtype=int32)\n          • inputs_embeds=None\n          • past_key_values_length=0\n          • training=False\n    \n    \n    Call arguments received by layer 'bert' (type TFBertMainLayer):\n      • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n      • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=True\n      • output_attentions=False\n      • output_hidden_states=False\n      • return_dict=True\n      • training=False\n\n\nCall arguments received by layer 'tf_bert_model_23' (type TFBertModel):\n  • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 49\u001b[0m\n\u001b[1;32m     34\u001b[0m custom_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m),\n\u001b[1;32m     36\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     }\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 모델 구조 확인 (선택사항)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m custom_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:542\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 542\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot build your model by calling `build` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif your layers do not support float type inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, in order to instantiate and build your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel, call your model on real tensor data (of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe correct dtype).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe actual error from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call` is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    549\u001b[0m             )\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbuild(input_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: Exception encountered when calling layer 'tf_bert_model_23' (type TFBertModel).\n\nin user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n        return func(self, **unpacked_inputs)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1209, in call  *\n        outputs = self.bert(\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1005, in error_handler  *\n        del filtered_tb\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 165, in error_handler\n        bound_signature = ag__.Undefined('bound_signature')\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call\n        ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n        inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n\n    TypeError: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n    \n    in user code:\n    \n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1182, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 887, in call  *\n            embedding_output = self.embeddings(\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1000, in error_handler  *\n            filtered_tb = _process_traceback_frames(e.__traceback__)\n        File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 1136, in __call__  *\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 162, in error_handler  **\n            raise ag__.converted_call(ag__.ld(new_e).with_traceback, (ag__.ld(e).__traceback__,), None, fscope_1) from None\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file9hlmxksf.py\", line 34, in error_handler\n            retval__1 = ag__.converted_call(ag__.ld(fn), tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope_1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 46, in tf__call  **\n            ag__.if_stmt(ag__.ld(input_ids) is not None, if_body_1, else_body_1, get_state_1, set_state_1, ('inputs_embeds',), 1)\n        File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_file3qvzmsgj.py\", line 41, in if_body_1\n            inputs_embeds = ag__.converted_call(ag__.ld(tf).gather, (), dict(params=ag__.ld(self).weight, indices=ag__.ld(input_ids)), fscope)\n    \n        TypeError: Exception encountered when calling layer 'embeddings' (type TFBertEmbeddings).\n        \n        in user code:\n        \n            File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 182, in call  *\n                inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n        \n            TypeError: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64\n        \n        \n        Call arguments received by layer 'embeddings' (type TFBertEmbeddings):\n          • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n          • position_ids=None\n          • token_type_ids=tf.Tensor(shape=(None, 128), dtype=int32)\n          • inputs_embeds=None\n          • past_key_values_length=0\n          • training=False\n    \n    \n    Call arguments received by layer 'bert' (type TFBertMainLayer):\n      • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n      • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=True\n      • output_attentions=False\n      • output_hidden_states=False\n      • return_dict=True\n      • training=False\n\n\nCall arguments received by layer 'tf_bert_model_23' (type TFBertModel):\n  • input_ids=tf.Tensor(shape=(None, 128), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(None, 128), dtype=float32)\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False."
     ]
    }
   ],
   "source": [
    "class CustomBERTModel(tf.keras.Model):\n",
    "    def __init__(self, bert_model):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.emotion_dense = tf.keras.layers.Dense(7, activation='linear', name='emotion_regression')\n",
    "        self.gender_dense = tf.keras.layers.Dense(1, activation='sigmoid', name='gender_classification')\n",
    "        self.age_dense = tf.keras.layers.Dense(1, activation='linear', name='age_regression')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask, emotions, gender = inputs\n",
    "        \n",
    "        bert_output = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        \n",
    "        x = self.dropout(pooled_output, training=training)\n",
    "        gender = tf.expand_dims(gender, axis=-1)\n",
    "        combined_input = tf.concat([x, emotions, gender], axis=1)\n",
    "        \n",
    "        emotion_output = self.emotion_dense(combined_input)\n",
    "        gender_output = self.gender_dense(combined_input)\n",
    "        age_output = self.age_dense(combined_input)\n",
    "        \n",
    "        return {\n",
    "            'emotion_regression': emotion_output,\n",
    "            'gender_classification': gender_output,\n",
    "            'age_regression': age_output\n",
    "        }\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "custom_model = CustomBERTModel(bert_model)\n",
    "\n",
    "# 모델 컴파일\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "    loss={\n",
    "        'emotion_regression': 'mean_squared_error',\n",
    "        'gender_classification': 'binary_crossentropy',\n",
    "        'age_regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_regression': 'mae',\n",
    "        'gender_classification': 'accuracy',\n",
    "        'age_regression': 'mae'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 모델 구조 확인 (선택사항)\n",
    "custom_model.build(input_shape=[(None, 128), (None, 128), (None, 7), (None,)])\n",
    "custom_model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "history = custom_model.fit(\n",
    "    x=[train_input_ids, train_attention_mask, train_emotions, train_gender],\n",
    "    y={\n",
    "        'emotion_regression': train_emotions,\n",
    "        'gender_classification': train_gender,\n",
    "        'age_regression': train_labels\n",
    "    },\n",
    "    validation_data=(\n",
    "        [val_input_ids, val_attention_mask, val_emotions, val_gender],\n",
    "        {\n",
    "            'emotion_regression': val_emotions,\n",
    "            'gender_classification': val_gender,\n",
    "            'age_regression': val_labels\n",
    "        }\n",
    "    ),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_bert_model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tf_bert_model_23 (TFBertMo  TFBaseModelOutputWithPo   92186880  \n",
      " del)                        olingAndCrossAttentions             \n",
      "                             (last_hidden_state=(Non             \n",
      "                             e, 128, 768),                       \n",
      "                              pooler_output=(None, 7             \n",
      "                             68),                                \n",
      "                              past_key_values=None,              \n",
      "                             hidden_states=None, att             \n",
      "                             entions=None, cross_att             \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " dropout_906 (Dropout)       multiple                  0         \n",
      "                                                                 \n",
      " emotion_regression (Dense)  multiple                  5439      \n",
      "                                                                 \n",
      " gender_classification (Den  multiple                  777       \n",
      " se)                                                             \n",
      "                                                                 \n",
      " age_regression (Dense)      multiple                  777       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92193873 (351.69 MB)\n",
      "Trainable params: 92193873 (351.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1149, in train_step  *\n        self._validate_target_and_loss(y, loss)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1102, in _validate_target_and_loss  *\n        if self.loss and y is None:\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/typing.py\", line 1912, in __instancecheck__\n        val = getattr_static(instance, attr)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py\", line 1854, in getattr_static\n        instance_result = _check_instance(obj, attr)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py\", line 1790, in _check_instance\n        instance_dict = object.__getattribute__(obj, \"__dict__\")\n\n    TypeError: this __dict__ descriptor does not support '_DictWrapper' objects\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m custom_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     82\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileh2y6jh2l.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filen49rgpmv.py:39\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompute_loss, (ag__\u001b[38;5;241m.\u001b[39mld(x), ag__\u001b[38;5;241m.\u001b[39mld(y), ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_target_and_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28mdict\u001b[39m(tape\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tape)), fscope)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_filenoup0w1g.py:42\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___validate_target_and_loss\u001b[0;34m(self, y, loss)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(loss) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body, else_body, get_state, set_state, (), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mand_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m, if_body_1, else_body_1, get_state_1, set_state_1, (), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/typing.py:1912\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1912\u001b[0m         val \u001b[38;5;241m=\u001b[39m getattr_static(instance, attr)\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1914\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py:1854\u001b[0m, in \u001b[0;36mgetattr_static\u001b[0;34m(obj, attr, default)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[0;32m-> 1854\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py:1790\u001b[0m, in \u001b[0;36m_check_instance\u001b[0;34m(obj, attr)\u001b[0m\n\u001b[1;32m   1788\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1790\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1149, in train_step  *\n        self._validate_target_and_loss(y, loss)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1102, in _validate_target_and_loss  *\n        if self.loss and y is None:\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/typing.py\", line 1912, in __instancecheck__\n        val = getattr_static(instance, attr)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py\", line 1854, in getattr_static\n        instance_result = _check_instance(obj, attr)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/inspect.py\", line 1790, in _check_instance\n        instance_dict = object.__getattribute__(obj, \"__dict__\")\n\n    TypeError: this __dict__ descriptor does not support '_DictWrapper' objects\n"
     ]
    }
   ],
   "source": [
    "class CustomBERTModel(tf.keras.Model):\n",
    "    def __init__(self, bert_model):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.emotion_dense = tf.keras.layers.Dense(7, activation='linear', name='emotion_regression')\n",
    "        self.gender_dense = tf.keras.layers.Dense(1, activation='sigmoid', name='gender_classification')\n",
    "        self.age_dense = tf.keras.layers.Dense(1, activation='linear', name='age_regression')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask, emotions, gender = inputs\n",
    "        \n",
    "        # 입력 데이터 타입 변환\n",
    "        input_ids = tf.cast(input_ids, tf.int32)\n",
    "        attention_mask = tf.cast(attention_mask, tf.int32)\n",
    "        \n",
    "        bert_output = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        \n",
    "        x = self.dropout(pooled_output, training=training)\n",
    "        gender = tf.expand_dims(gender, axis=-1)\n",
    "        combined_input = tf.concat([x, emotions, gender], axis=1)\n",
    "        \n",
    "        emotion_output = self.emotion_dense(combined_input)\n",
    "        gender_output = self.gender_dense(combined_input)\n",
    "        age_output = self.age_dense(combined_input)\n",
    "        \n",
    "        return {\n",
    "            'emotion_regression': emotion_output,\n",
    "            'gender_classification': gender_output,\n",
    "            'age_regression': age_output\n",
    "        }\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "custom_model = CustomBERTModel(bert_model)\n",
    "\n",
    "# 모델 컴파일\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=3e-5),\n",
    "    loss={\n",
    "        'emotion_regression': 'mean_squared_error',\n",
    "        'gender_classification': 'binary_crossentropy',\n",
    "        'age_regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_regression': 'mae',\n",
    "        'gender_classification': 'accuracy',\n",
    "        'age_regression': 'mae'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 모델 구조 확인\n",
    "# 실제 데이터의 배치 크기를 사용하여 모델을 구축\n",
    "batch_size = 16  # 또는 실제 사용하는 배치 크기\n",
    "custom_model.build(input_shape=[\n",
    "    (batch_size, 128),  # input_ids\n",
    "    (batch_size, 128),  # attention_mask\n",
    "    (batch_size, 7),    # emotions\n",
    "    (batch_size,)       # gender\n",
    "])\n",
    "custom_model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "history = custom_model.fit(\n",
    "    x=[train_input_ids, train_attention_mask, train_emotions, train_gender],\n",
    "    y={\n",
    "        'emotion_regression': train_emotions,\n",
    "        'gender_classification': train_gender,\n",
    "        'age_regression': train_labels\n",
    "    },\n",
    "    validation_data=(\n",
    "        [val_input_ids, val_attention_mask, val_emotions, val_gender],\n",
    "        {\n",
    "            'emotion_regression': val_emotions,\n",
    "            'gender_classification': val_gender,\n",
    "            'age_regression': val_labels\n",
    "        }\n",
    "    ),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/111251126.py\", line 39, in train_step  *\n        emotion_loss = self.compiled_loss['emotion_regression'](y['emotion_regression'], y_pred['emotion_regression'])\n\n    TypeError: 'LossesContainer' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[273], line 74\u001b[0m\n\u001b[1;32m     59\u001b[0m custom_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m),\n\u001b[1;32m     61\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     }\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileh2y6jh2l.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileiu96fp66.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[0;32m/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/__autograph_generated_fileckrrkfdj.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     12\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 13\u001b[0m     emotion_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, (ag__\u001b[38;5;241m.\u001b[39mld(y)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_regression\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_regression\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m     gender_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_classification\u001b[39m\u001b[38;5;124m'\u001b[39m], (ag__\u001b[38;5;241m.\u001b[39mld(y)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_classification\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_classification\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m     age_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_regression\u001b[39m\u001b[38;5;124m'\u001b[39m], (ag__\u001b[38;5;241m.\u001b[39mld(y)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_regression\u001b[39m\u001b[38;5;124m'\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(y_pred)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_regression\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"/var/folders/nc/35vy2ljn2pdfpcglx2fk1qn80000gn/T/ipykernel_66901/111251126.py\", line 39, in train_step  *\n        emotion_loss = self.compiled_loss['emotion_regression'](y['emotion_regression'], y_pred['emotion_regression'])\n\n    TypeError: 'LossesContainer' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "class CustomBERTModel(tf.keras.Model):\n",
    "    def __init__(self, bert_model):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.emotion_dense = tf.keras.layers.Dense(7, activation='linear', name='emotion_regression')\n",
    "        self.gender_dense = tf.keras.layers.Dense(1, activation='sigmoid', name='gender_classification')\n",
    "        self.age_dense = tf.keras.layers.Dense(1, activation='linear', name='age_regression')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask, emotions, gender = inputs\n",
    "        \n",
    "        # 입력 데이터 타입 변환\n",
    "        input_ids = tf.cast(input_ids, tf.int32)\n",
    "        attention_mask = tf.cast(attention_mask, tf.int32)\n",
    "        \n",
    "        bert_output = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        \n",
    "        x = self.dropout(pooled_output, training=training)\n",
    "        gender = tf.expand_dims(gender, axis=-1)\n",
    "        combined_input = tf.concat([x, emotions, gender], axis=1)\n",
    "        \n",
    "        emotion_output = self.emotion_dense(combined_input)\n",
    "        gender_output = self.gender_dense(combined_input)\n",
    "        age_output = self.age_dense(combined_input)\n",
    "        \n",
    "        return {\n",
    "            'emotion_regression': emotion_output,\n",
    "            'gender_classification': gender_output,\n",
    "            'age_regression': age_output\n",
    "        }\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            emotion_loss = self.compiled_loss['emotion_regression'](y['emotion_regression'], y_pred['emotion_regression'])\n",
    "            gender_loss = self.compiled_loss['gender_classification'](y['gender_classification'], y_pred['gender_classification'])\n",
    "            age_loss = self.compiled_loss['age_regression'](y['age_regression'], y_pred['age_regression'])\n",
    "            total_loss = emotion_loss + gender_loss + age_loss\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        self.compiled_metrics['emotion_regression'].update_state(y['emotion_regression'], y_pred['emotion_regression'])\n",
    "        self.compiled_metrics['gender_classification'].update_state(y['gender_classification'], y_pred['gender_classification'])\n",
    "        self.compiled_metrics['age_regression'].update_state(y['age_regression'], y_pred['age_regression'])\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "custom_model = CustomBERTModel(bert_model)\n",
    "\n",
    "# 모델 컴파일\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "    loss={\n",
    "        'emotion_regression': 'mean_squared_error',\n",
    "        'gender_classification': 'binary_crossentropy',\n",
    "        'age_regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_regression': 'mae',\n",
    "        'gender_classification': 'accuracy',\n",
    "        'age_regression': 'mae'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = custom_model.fit(\n",
    "    x=[train_input_ids, train_attention_mask, train_emotions, train_gender],\n",
    "    y={\n",
    "        'emotion_regression': train_emotions,\n",
    "        'gender_classification': train_gender,\n",
    "        'age_regression': train_labels\n",
    "    },\n",
    "    validation_data=(\n",
    "        [val_input_ids, val_attention_mask, val_emotions, val_gender],\n",
    "        {\n",
    "            'emotion_regression': val_emotions,\n",
    "            'gender_classification': val_gender,\n",
    "            'age_regression': val_labels\n",
    "        }\n",
    "    ),\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행 성공, 결과 확인 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  23/1271 [..............................] - ETA: 3:02:50 - loss: 1166.9954 - age_regression_loss: 1165.9387 - emotion_regression_loss: 0.3594 - gender_classification_loss: 0.6971 - age_regression_mae: 31.0564 - emotion_regression_mae: 0.4726 - gender_classification_accuracy: 0.5380"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[275], line 68\u001b[0m\n\u001b[1;32m     53\u001b[0m custom_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m),\n\u001b[1;32m     55\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     }\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_emotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender_classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage_regression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dlthonv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CustomBERTModel(tf.keras.Model):\n",
    "    def __init__(self, bert_model):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.emotion_dense = tf.keras.layers.Dense(7, activation='linear', name='emotion_regression')\n",
    "        self.gender_dense = tf.keras.layers.Dense(1, activation='sigmoid', name='gender_classification')\n",
    "        self.age_dense = tf.keras.layers.Dense(1, activation='linear', name='age_regression')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        input_ids, attention_mask, emotions, gender = inputs\n",
    "        \n",
    "        # 입력 데이터 타입 변환\n",
    "        input_ids = tf.cast(input_ids, tf.int32)\n",
    "        attention_mask = tf.cast(attention_mask, tf.int32)\n",
    "        \n",
    "        bert_output = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        \n",
    "        x = self.dropout(pooled_output, training=training)\n",
    "        gender = tf.expand_dims(gender, axis=-1)\n",
    "        combined_input = tf.concat([x, emotions, gender], axis=1)\n",
    "        \n",
    "        emotion_output = self.emotion_dense(combined_input)\n",
    "        gender_output = self.gender_dense(combined_input)\n",
    "        age_output = self.age_dense(combined_input)\n",
    "        \n",
    "        return {\n",
    "            'emotion_regression': emotion_output,\n",
    "            'gender_classification': gender_output,\n",
    "            'age_regression': age_output\n",
    "        }\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "custom_model = CustomBERTModel(bert_model)\n",
    "\n",
    "# 모델 컴파일\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=3e-5),\n",
    "    loss={\n",
    "        'emotion_regression': 'mean_squared_error',\n",
    "        'gender_classification': 'binary_crossentropy',\n",
    "        'age_regression': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'emotion_regression': 'mae',\n",
    "        'gender_classification': 'accuracy',\n",
    "        'age_regression': 'mae'\n",
    "    }\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = custom_model.fit(\n",
    "    x=[train_input_ids, train_attention_mask, train_emotions, train_gender],\n",
    "    y={\n",
    "        'emotion_regression': train_emotions,\n",
    "        'gender_classification': train_gender,\n",
    "        'age_regression': train_labels\n",
    "    },\n",
    "    validation_data=(\n",
    "        [val_input_ids, val_attention_mask, val_emotions, val_gender],\n",
    "        {\n",
    "            'emotion_regression': val_emotions,\n",
    "            'gender_classification': val_gender,\n",
    "            'age_regression': val_labels\n",
    "        }\n",
    "    ),\n",
    "    epochs=50,  # 최대 에폭 수 증가. Early Stopping이 적절한 시점에 훈련을 멈추도록\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 학습 곡선 그리기\n",
    "def plot_learning_curves(history):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "    # 손실 곡선\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Emotion Regression MAE\n",
    "    ax2.plot(history.history['emotion_regression_mae'], label='Training Emotion MAE')\n",
    "    ax2.plot(history.history['val_emotion_regression_mae'], label='Validation Emotion MAE')\n",
    "    ax2.set_title('Emotion Regression MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Gender Classification Accuracy\n",
    "    ax3.plot(history.history['gender_classification_accuracy'], label='Training Gender Accuracy')\n",
    "    ax3.plot(history.history['val_gender_classification_accuracy'], label='Validation Gender Accuracy')\n",
    "    ax3.set_title('Gender Classification Accuracy')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 학습 곡선 출력\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# 최적의 에폭 출력\n",
    "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "print(f\"Best epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원 확인\n",
    "# print(tf.shape(input_ids))  # 출력: (배치 크기, 입력 시퀀스 길이)\n",
    "# print(tf.shape(attention_mask))  # 출력: (배치 크기, 입력 시퀀스 길이)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 형태 확인\n",
    "print(\"Input IDs shape:\", train_input_ids.shape)  # 예시 출력: (배치 크기, 시퀀스 길이)\n",
    "print(\"Attention Mask shape:\", train_attention_mask.shape)  # 예시 출력: (배치 크기, 시퀀스 길이)\n",
    "print(\"Emotions shape:\", train_emotions.shape)  # 예시 출력: (배치 크기, 7)\n",
    "print(\"Gender shape:\", train_gender.shape)  # 예시 출력: (배치 크기, 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
