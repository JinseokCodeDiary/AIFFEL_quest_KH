{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install summa","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:09:05.269672Z","iopub.execute_input":"2024-08-14T04:09:05.270044Z","iopub.status.idle":"2024-08-14T04:09:22.662409Z","shell.execute_reply.started":"2024-08-14T04:09:05.270013Z","shell.execute_reply":"2024-08-14T04:09:22.661203Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting summa\n  Downloading summa-1.2.0.tar.gz (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m670.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy>=0.19 in /opt/conda/lib/python3.10/site-packages (from summa) (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy>=0.19->summa) (1.26.4)\nBuilding wheels for collected packages: summa\n  Building wheel for summa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54388 sha256=c031dd1a9eec684f035fa77583b7de647bab2731d6538dd498f5049f13d84cdf\n  Stored in directory: /root/.cache/pip/wheels/4a/ca/c5/4958614cfba88ed6ceb7cb5a849f9f89f9ac49971616bc919f\nSuccessfully built summa\nInstalling collected packages: summa\nSuccessfully installed summa-1.2.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from importlib.metadata import version\nimport nltk\nimport tensorflow\nimport pandas as pd\nimport summa\n\nprint(nltk.__version__)\nprint(tensorflow.__version__)\nprint(pd.__version__)\nprint(version('summa'))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:09:22.664544Z","iopub.execute_input":"2024-08-14T04:09:22.664865Z","iopub.status.idle":"2024-08-14T04:09:22.705754Z","shell.execute_reply.started":"2024-08-14T04:09:22.664836Z","shell.execute_reply":"2024-08-14T04:09:22.704737Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"3.2.4\n2.15.0\n2.2.2\n1.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom bs4 import BeautifulSoup \nfrom tensorflow.keras.preprocessing.text import Tokenizer \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport urllib.request\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:09:22.707123Z","iopub.execute_input":"2024-08-14T04:09:22.707758Z","iopub.status.idle":"2024-08-14T04:09:23.102725Z","shell.execute_reply.started":"2024-08-14T04:09:22.707724Z","shell.execute_reply":"2024-08-14T04:09:23.101728Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n=3\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib.request\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\ndata = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:01.697273Z","iopub.execute_input":"2024-08-14T07:40:01.697977Z","iopub.status.idle":"2024-08-14T07:40:02.855270Z","shell.execute_reply.started":"2024-08-14T07:40:01.697943Z","shell.execute_reply":"2024-08-14T07:40:02.854197Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:03.018294Z","iopub.execute_input":"2024-08-14T07:40:03.018690Z","iopub.status.idle":"2024-08-14T07:40:03.033782Z","shell.execute_reply.started":"2024-08-14T07:40:03.018661Z","shell.execute_reply":"2024-08-14T07:40:03.032708Z"},"trusted":true},"execution_count":175,"outputs":[{"execution_count":175,"output_type":"execute_result","data":{"text/plain":"                                               headlines  \\\n45951  Sridevi maintained her dignity in a demanding ...   \n23945  28% GST rate added the Excise, VAT & CST: Ex-F...   \n41170     Kim Jong-un attends first South Korean concert   \n61775  Amazon focused on customers, not competitors: ...   \n78800  No more permissions for casinos in Goa: CM Par...   \n22747  Received 60% return on sale of stake in Flipka...   \n70089   Govt planning to link Driving Licence to Aadhaar   \n8607   Bollywood celebs pay tribute to Mumbai terror ...   \n97237  AIIMS doctors wear helmets to work over Maha d...   \n78642  Grand Alliance will choose new Bihar Chief Min...   \n\n                                                    text  \n45951  Filmmaker Subhash Ghai, while condoling the de...  \n23945  Former Finance Minister P Chidambaram has said...  \n41170  North Korean leader Kim Jong-un on Sunday beca...  \n61775  CEO of Amazon Worldwide Consumer, Jeffrey Wilk...  \n78800  Goa Chief Minister Manohar Parrikar has clarif...  \n22747  Japan's SoftBank Group on Monday reported its ...  \n70089  Union Information Technology Minister Ravi Sha...  \n8607   Bollywood celebrities took to social media and...  \n97237  Around 1,200 junior doctors turned up wearing ...  \n78642  During a press conference after Bihar Chief Mi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headlines</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45951</th>\n      <td>Sridevi maintained her dignity in a demanding ...</td>\n      <td>Filmmaker Subhash Ghai, while condoling the de...</td>\n    </tr>\n    <tr>\n      <th>23945</th>\n      <td>28% GST rate added the Excise, VAT &amp; CST: Ex-F...</td>\n      <td>Former Finance Minister P Chidambaram has said...</td>\n    </tr>\n    <tr>\n      <th>41170</th>\n      <td>Kim Jong-un attends first South Korean concert</td>\n      <td>North Korean leader Kim Jong-un on Sunday beca...</td>\n    </tr>\n    <tr>\n      <th>61775</th>\n      <td>Amazon focused on customers, not competitors: ...</td>\n      <td>CEO of Amazon Worldwide Consumer, Jeffrey Wilk...</td>\n    </tr>\n    <tr>\n      <th>78800</th>\n      <td>No more permissions for casinos in Goa: CM Par...</td>\n      <td>Goa Chief Minister Manohar Parrikar has clarif...</td>\n    </tr>\n    <tr>\n      <th>22747</th>\n      <td>Received 60% return on sale of stake in Flipka...</td>\n      <td>Japan's SoftBank Group on Monday reported its ...</td>\n    </tr>\n    <tr>\n      <th>70089</th>\n      <td>Govt planning to link Driving Licence to Aadhaar</td>\n      <td>Union Information Technology Minister Ravi Sha...</td>\n    </tr>\n    <tr>\n      <th>8607</th>\n      <td>Bollywood celebs pay tribute to Mumbai terror ...</td>\n      <td>Bollywood celebrities took to social media and...</td>\n    </tr>\n    <tr>\n      <th>97237</th>\n      <td>AIIMS doctors wear helmets to work over Maha d...</td>\n      <td>Around 1,200 junior doctors turned up wearing ...</td>\n    </tr>\n    <tr>\n      <th>78642</th>\n      <td>Grand Alliance will choose new Bihar Chief Min...</td>\n      <td>During a press conference after Bihar Chief Mi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 중복 확인\nprint('총 데이터 개수 :', len(data))\nprint('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\nprint('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:03.642448Z","iopub.execute_input":"2024-08-14T07:40:03.643076Z","iopub.status.idle":"2024-08-14T07:40:03.816015Z","shell.execute_reply.started":"2024-08-14T07:40:03.643043Z","shell.execute_reply":"2024-08-14T07:40:03.815001Z"},"trusted":true},"execution_count":176,"outputs":[{"name":"stdout","text":"총 데이터 개수 : 98401\ntext 열에서 중복을 배제한 유일한 샘플의 수 : 98360\nheadlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n","output_type":"stream"}]},{"cell_type":"code","source":"# 중복 제거\ndata.drop_duplicates(subset = ['text'], inplace=True)\nprint('전체 샘플수 :', (len(data)))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:04.184699Z","iopub.execute_input":"2024-08-14T07:40:04.185713Z","iopub.status.idle":"2024-08-14T07:40:04.236105Z","shell.execute_reply.started":"2024-08-14T07:40:04.185677Z","shell.execute_reply":"2024-08-14T07:40:04.235231Z"},"trusted":true},"execution_count":177,"outputs":[{"name":"stdout","text":"전체 샘플수 : 98360\n","output_type":"stream"}]},{"cell_type":"code","source":"print(data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:04.582789Z","iopub.execute_input":"2024-08-14T07:40:04.583735Z","iopub.status.idle":"2024-08-14T07:40:04.613139Z","shell.execute_reply.started":"2024-08-14T07:40:04.583689Z","shell.execute_reply":"2024-08-14T07:40:04.612031Z"},"trusted":true},"execution_count":178,"outputs":[{"name":"stdout","text":"headlines    0\ntext         0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n                           \"you're\": \"you are\", \"you've\": \"you have\"}\n\nprint(\"정규화 사전의 수: \", len(contractions))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:04.917946Z","iopub.execute_input":"2024-08-14T07:40:04.918754Z","iopub.status.idle":"2024-08-14T07:40:04.933842Z","shell.execute_reply.started":"2024-08-14T07:40:04.918722Z","shell.execute_reply":"2024-08-14T07:40:04.932834Z"},"trusted":true},"execution_count":179,"outputs":[{"name":"stdout","text":"정규화 사전의 수:  120\n","output_type":"stream"}]},{"cell_type":"code","source":"print('불용어 개수 :', len(stopwords.words('english') ))\nprint(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:05.297177Z","iopub.execute_input":"2024-08-14T07:40:05.297586Z","iopub.status.idle":"2024-08-14T07:40:05.303897Z","shell.execute_reply.started":"2024-08-14T07:40:05.297548Z","shell.execute_reply":"2024-08-14T07:40:05.303001Z"},"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"불용어 개수 : 179\n['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"# 데이터 전처리 함수\ndef preprocess_sentence(sentence, remove_stopwords=True):\n    sentence = sentence.lower() # 텍스트 소문자화\n    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n    \n    # 불용어 제거 (Text)\n    if remove_stopwords:\n        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n    # 불용어 미제거 (Summary)\n    else:\n        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n    return tokens\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:05.722874Z","iopub.execute_input":"2024-08-14T07:40:05.723775Z","iopub.status.idle":"2024-08-14T07:40:05.732905Z","shell.execute_reply.started":"2024-08-14T07:40:05.723742Z","shell.execute_reply":"2024-08-14T07:40:05.732005Z"},"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\ntemp_summary = 'Great way to start (or finish) the day!!!'\n\nprint(\"text: \", preprocess_sentence(temp_text))\nprint(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다.","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:05.994391Z","iopub.execute_input":"2024-08-14T07:40:05.994992Z","iopub.status.idle":"2024-08-14T07:40:06.006023Z","shell.execute_reply.started":"2024-08-14T07:40:05.994964Z","shell.execute_reply":"2024-08-14T07:40:06.005097Z"},"trusted":true},"execution_count":182,"outputs":[{"name":"stdout","text":"text:  everything bought great infact ordered twice third ordered wasfor mother father\nsummary: great way to start the day\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \nclean_text = []\n\n# for i in data.index:\n#     data.loc[i, 'text'] = preprocess_sentence(data.loc[i, 'text'])\n\nfor i in tqdm(data.index, desc=\"Preprocessing Summary\"):\n    clean_text.append(preprocess_sentence(data.loc[i, 'text']))\n\n# 전처리 후 출력\nprint(\"Text 전처리 후 결과: \", clean_text[:5])\nlen(clean_text)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:40:06.174376Z","iopub.execute_input":"2024-08-14T07:40:06.174712Z","iopub.status.idle":"2024-08-14T07:53:24.940738Z","shell.execute_reply.started":"2024-08-14T07:40:06.174687Z","shell.execute_reply":"2024-08-14T07:53:24.939741Z"},"trusted":true},"execution_count":183,"outputs":[{"name":"stderr","text":"Preprocessing Summary: 100%|██████████| 98360/98360 [13:18<00:00, 123.14it/s]","output_type":"stream"},{"name":"stdout","text":"Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"98360"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \nclean_summary = []\n\n# [[YOUR CODE]]\n# tqdm을 사용하여 진행 상황 표시\nfor i in tqdm(data.index, desc=\"Preprocessing headlines\"):\n    clean_summary.append(preprocess_sentence(data.loc[i, 'headlines'], False))\n\nprint(\"headlines 전처리 후 결과: \", clean_summary[:5])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:24.942477Z","iopub.execute_input":"2024-08-14T07:53:24.942774Z","iopub.status.idle":"2024-08-14T07:53:49.624214Z","shell.execute_reply.started":"2024-08-14T07:53:24.942747Z","shell.execute_reply":"2024-08-14T07:53:49.623226Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stderr","text":"Preprocessing headlines:   0%|          | 378/98360 [00:00<00:25, 3778.43it/s]/tmp/ipykernel_34/2884123602.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\nPreprocessing headlines: 100%|██████████| 98360/98360 [00:24<00:00, 3986.96it/s]","output_type":"stream"},{"name":"stdout","text":"headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"data['text'] = clean_text\ndata['headlines'] = clean_summary","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:49.625237Z","iopub.execute_input":"2024-08-14T07:53:49.625508Z","iopub.status.idle":"2024-08-14T07:53:49.659865Z","shell.execute_reply.started":"2024-08-14T07:53:49.625485Z","shell.execute_reply":"2024-08-14T07:53:49.658952Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:49.662304Z","iopub.execute_input":"2024-08-14T07:53:49.662599Z","iopub.status.idle":"2024-08-14T07:53:49.691674Z","shell.execute_reply.started":"2024-08-14T07:53:49.662568Z","shell.execute_reply":"2024-08-14T07:53:49.690754Z"},"trusted":true},"execution_count":186,"outputs":[{"execution_count":186,"output_type":"execute_result","data":{"text/plain":"headlines    0\ntext         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.dropna(axis=0, inplace=True)\nprint('전체 샘플수 :', (len(data)))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:49.692906Z","iopub.execute_input":"2024-08-14T07:53:49.693337Z","iopub.status.idle":"2024-08-14T07:53:49.733685Z","shell.execute_reply.started":"2024-08-14T07:53:49.693306Z","shell.execute_reply":"2024-08-14T07:53:49.732877Z"},"trusted":true},"execution_count":187,"outputs":[{"name":"stdout","text":"전체 샘플수 : 98360\n","output_type":"stream"}]},{"cell_type":"markdown","source":"필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례에요.\n\nText와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 볼게요.","metadata":{}},{"cell_type":"code","source":"# 길이 분포 출력\nimport matplotlib.pyplot as plt\n\ntext_len = [len(s.split()) for s in data['text']]\nprint(data['headlines'])\nsummary_len = [len(s.split()) for s in data['headlines']]\n\nprint('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\nprint('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\nprint('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\nprint('요약의 최소 길이 : {}'.format(np.min(summary_len)))\nprint('요약의 최대 길이 : {}'.format(np.max(summary_len)))\nprint('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n\nplt.subplot(1,2,1)\nplt.boxplot(text_len)\nplt.title('Text')\nplt.subplot(1,2,2)\nplt.boxplot(summary_len)\nplt.title('headlines')\nplt.tight_layout()\nplt.show()\n\nplt.title('text')\nplt.hist(text_len, bins = 40)\nplt.xlabel('length of samples')\nplt.ylabel('number of samples')\nplt.show()\n\nplt.title('Summary')\nplt.hist(summary_len, bins = 40)\nplt.xlabel('length of samples')\nplt.ylabel('number of samples')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:49.734679Z","iopub.execute_input":"2024-08-14T07:53:49.734944Z","iopub.status.idle":"2024-08-14T07:53:52.631962Z","shell.execute_reply.started":"2024-08-14T07:53:49.734921Z","shell.execute_reply":"2024-08-14T07:53:52.630970Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stdout","text":"0        upgrad learner switches to career in ml al wit...\n1        delhi techie wins free food from swiggy for on...\n2        new zealand end rohit sharma led india match w...\n3        aegon life iterm insurance plan helps customer...\n4        have known hirani for yrs what if metoo claims...\n                               ...                        \n98396    crpf jawan axed to death by maoists in chhatti...\n98397    first song from sonakshi sinha noor titled uff...\n98398                the matrix film to get reboot reports\n98399    snoop dogg aims gun at clown dressed as trump ...\n98400    madhesi morcha withdraws support to nepalese g...\nName: headlines, Length: 98360, dtype: object\n텍스트의 최소 길이 : 1\n텍스트의 최대 길이 : 60\n텍스트의 평균 길이 : 35.09968483123221\n요약의 최소 길이 : 1\n요약의 최대 길이 : 16\n요약의 평균 길이 : 9.299532330215534\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"text_max_len = 43\nheadline_max_len = 12\nprint('=3')\n\ndef below_threshold_len(max_len, nested_list):\n  cnt = 0\n  for s in nested_list:\n    if(len(s.split()) <= max_len):\n        cnt = cnt + 1\n  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\nprint('=3')\n\nbelow_threshold_len(text_max_len, data['text'])\nbelow_threshold_len(headline_max_len,  data['headlines'])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:52.633460Z","iopub.execute_input":"2024-08-14T07:53:52.633838Z","iopub.status.idle":"2024-08-14T07:53:53.034894Z","shell.execute_reply.started":"2024-08-14T07:53:52.633801Z","shell.execute_reply":"2024-08-14T07:53:53.033837Z"},"trusted":true},"execution_count":189,"outputs":[{"name":"stdout","text":"=3\n=3\n전체 샘플 중 길이가 43 이하인 샘플의 비율: 0.9871797478649857\n전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenized_len(text):\n    return len(text.split())\n\n# 토큰화된 길이 분포 확인\ntoken_lengths = data['text'].apply(tokenized_len)\nprint(\"토큰화된 텍스트 길이 통계:\")\nprint(token_lengths.describe())\n\n# 적절한 max_len 값 제안 (예: 95 퍼센타일)\nsuggested_max_len = int(token_lengths.quantile(0.99))\nprint(f\"\\n제안된 max_len 값: {suggested_max_len}\")\n\n# 새로운 max_len 값으로 필터링\nfiltered_data = data[data['text'].apply(lambda x: tokenized_len(x) <= suggested_max_len)]\nprint(f\"\\n필터링 후 남은 행 수: {len(filtered_data)}\")\n\n# below_threshold_len 함수를 사용한 분석\ndef below_threshold_len(max_len, nested_list):\n    cnt = sum(1 for s in nested_list if len(s.split()) <= max_len)\n    print(f'전체 샘플 중 길이가 {max_len} 이하인 샘플의 비율: {cnt / len(nested_list):.2f}')\n\nbelow_threshold_len(suggested_max_len, data['text'])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:53.036239Z","iopub.execute_input":"2024-08-14T07:53:53.036566Z","iopub.status.idle":"2024-08-14T07:53:53.923419Z","shell.execute_reply.started":"2024-08-14T07:53:53.036539Z","shell.execute_reply":"2024-08-14T07:53:53.922501Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stdout","text":"토큰화된 텍스트 길이 통계:\ncount    98360.000000\nmean        35.099685\nstd          3.799406\nmin          1.000000\n25%         33.000000\n50%         35.000000\n75%         38.000000\nmax         60.000000\nName: text, dtype: float64\n\n제안된 max_len 값: 44\n\n필터링 후 남은 행 수: 97708\n전체 샘플 중 길이가 44 이하인 샘플의 비율: 0.99\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenized_len(text):\n    return len(text.split())\n\nfiltered_data = data[data['text'].apply(lambda x: tokenized_len(x) <= text_max_len)]\n\n# 필터링 결과 확인\nprint(f\"원본 데이터 크기: {len(data)}\")\nprint(f\"필터링 후 데이터 크기: {len(filtered_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:53.924647Z","iopub.execute_input":"2024-08-14T07:53:53.924957Z","iopub.status.idle":"2024-08-14T07:53:54.230944Z","shell.execute_reply.started":"2024-08-14T07:53:53.924928Z","shell.execute_reply":"2024-08-14T07:53:54.229950Z"},"trusted":true},"execution_count":191,"outputs":[{"name":"stdout","text":"원본 데이터 크기: 98360\n필터링 후 데이터 크기: 97099\n","output_type":"stream"}]},{"cell_type":"code","source":"df = data[data['headlines'].apply(lambda x: tokenized_len(x) <= headline_max_len)]\n\n# 필터링 결과 확인\nprint(f\"원본 데이터 크기: {len(data)}\")\nprint(f\"필터링 후 데이터 크기: {len(filtered_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.234644Z","iopub.execute_input":"2024-08-14T07:53:54.234948Z","iopub.status.idle":"2024-08-14T07:53:54.366131Z","shell.execute_reply.started":"2024-08-14T07:53:54.234921Z","shell.execute_reply":"2024-08-14T07:53:54.365321Z"},"trusted":true},"execution_count":192,"outputs":[{"name":"stdout","text":"원본 데이터 크기: 98360\n필터링 후 데이터 크기: 97099\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.367276Z","iopub.execute_input":"2024-08-14T07:53:54.367655Z","iopub.status.idle":"2024-08-14T07:53:54.378569Z","shell.execute_reply.started":"2024-08-14T07:53:54.367618Z","shell.execute_reply":"2024-08-14T07:53:54.377664Z"},"trusted":true},"execution_count":193,"outputs":[{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"                                               headlines  \\\n0      upgrad learner switches to career in ml al wit...   \n1      delhi techie wins free food from swiggy for on...   \n2      new zealand end rohit sharma led india match w...   \n3      aegon life iterm insurance plan helps customer...   \n5      rahat fateh ali khan denies getting notice for...   \n...                                                  ...   \n98396  crpf jawan axed to death by maoists in chhatti...   \n98397  first song from sonakshi sinha noor titled uff...   \n98398              the matrix film to get reboot reports   \n98399  snoop dogg aims gun at clown dressed as trump ...   \n98400  madhesi morcha withdraws support to nepalese g...   \n\n                                                    text  \n0      saurav kant alumnus upgrad iiit pg program mac...  \n1      kunal shah credit card bill payment platform c...  \n2      new zealand defeated india wickets fourth odi ...  \n3      aegon life iterm insurance plan customers enjo...  \n5      pakistani singer rahat fateh ali khan denied r...  \n...                                                  ...  \n98396  crpf jawan tuesday axed death sharp edged weap...  \n98397  uff yeh first song sonakshi sinha starrer upco...  \n98398  according reports new version science fiction ...  \n98399  new music video shows rapper snoop dogg aiming...  \n98400  madhesi morcha alliance seven political partie...  \n\n[97183 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headlines</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>upgrad learner switches to career in ml al wit...</td>\n      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>delhi techie wins free food from swiggy for on...</td>\n      <td>kunal shah credit card bill payment platform c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>new zealand end rohit sharma led india match w...</td>\n      <td>new zealand defeated india wickets fourth odi ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aegon life iterm insurance plan helps customer...</td>\n      <td>aegon life iterm insurance plan customers enjo...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rahat fateh ali khan denies getting notice for...</td>\n      <td>pakistani singer rahat fateh ali khan denied r...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>98396</th>\n      <td>crpf jawan axed to death by maoists in chhatti...</td>\n      <td>crpf jawan tuesday axed death sharp edged weap...</td>\n    </tr>\n    <tr>\n      <th>98397</th>\n      <td>first song from sonakshi sinha noor titled uff...</td>\n      <td>uff yeh first song sonakshi sinha starrer upco...</td>\n    </tr>\n    <tr>\n      <th>98398</th>\n      <td>the matrix film to get reboot reports</td>\n      <td>according reports new version science fiction ...</td>\n    </tr>\n    <tr>\n      <th>98399</th>\n      <td>snoop dogg aims gun at clown dressed as trump ...</td>\n      <td>new music video shows rapper snoop dogg aiming...</td>\n    </tr>\n    <tr>\n      <th>98400</th>\n      <td>madhesi morcha withdraws support to nepalese g...</td>\n      <td>madhesi morcha alliance seven political partie...</td>\n    </tr>\n  </tbody>\n</table>\n<p>97183 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\ndf['decoder_input'] = df['headlines'].apply(lambda x : 'sostoken '+ x)\ndf['decoder_target'] = df['headlines'].apply(lambda x : x + ' eostoken')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.379730Z","iopub.execute_input":"2024-08-14T07:53:54.380029Z","iopub.status.idle":"2024-08-14T07:53:54.459659Z","shell.execute_reply.started":"2024-08-14T07:53:54.380003Z","shell.execute_reply":"2024-08-14T07:53:54.458615Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/32008424.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['decoder_input'] = df['headlines'].apply(lambda x : 'sostoken '+ x)\n/tmp/ipykernel_34/32008424.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['decoder_target'] = df['headlines'].apply(lambda x : x + ' eostoken')\n","output_type":"stream"},{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"                                           headlines  \\\n0  upgrad learner switches to career in ml al wit...   \n1  delhi techie wins free food from swiggy for on...   \n2  new zealand end rohit sharma led india match w...   \n3  aegon life iterm insurance plan helps customer...   \n5  rahat fateh ali khan denies getting notice for...   \n\n                                                text  \\\n0  saurav kant alumnus upgrad iiit pg program mac...   \n1  kunal shah credit card bill payment platform c...   \n2  new zealand defeated india wickets fourth odi ...   \n3  aegon life iterm insurance plan customers enjo...   \n5  pakistani singer rahat fateh ali khan denied r...   \n\n                                       decoder_input  \\\n0  sostoken upgrad learner switches to career in ...   \n1  sostoken delhi techie wins free food from swig...   \n2  sostoken new zealand end rohit sharma led indi...   \n3  sostoken aegon life iterm insurance plan helps...   \n5  sostoken rahat fateh ali khan denies getting n...   \n\n                                      decoder_target  \n0  upgrad learner switches to career in ml al wit...  \n1  delhi techie wins free food from swiggy for on...  \n2  new zealand end rohit sharma led india match w...  \n3  aegon life iterm insurance plan helps customer...  \n5  rahat fateh ali khan denies getting notice for...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headlines</th>\n      <th>text</th>\n      <th>decoder_input</th>\n      <th>decoder_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>upgrad learner switches to career in ml al wit...</td>\n      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n      <td>sostoken upgrad learner switches to career in ...</td>\n      <td>upgrad learner switches to career in ml al wit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>delhi techie wins free food from swiggy for on...</td>\n      <td>kunal shah credit card bill payment platform c...</td>\n      <td>sostoken delhi techie wins free food from swig...</td>\n      <td>delhi techie wins free food from swiggy for on...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>new zealand end rohit sharma led india match w...</td>\n      <td>new zealand defeated india wickets fourth odi ...</td>\n      <td>sostoken new zealand end rohit sharma led indi...</td>\n      <td>new zealand end rohit sharma led india match w...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aegon life iterm insurance plan helps customer...</td>\n      <td>aegon life iterm insurance plan customers enjo...</td>\n      <td>sostoken aegon life iterm insurance plan helps...</td>\n      <td>aegon life iterm insurance plan helps customer...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rahat fateh ali khan denies getting notice for...</td>\n      <td>pakistani singer rahat fateh ali khan denied r...</td>\n      <td>sostoken rahat fateh ali khan denies getting n...</td>\n      <td>rahat fateh ali khan denies getting notice for...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"encoder_input = np.array(df['text']) # 인코더의 입력\ndecoder_input = np.array(df['decoder_input']) # 디코더의 입력\ndecoder_target = np.array(df['decoder_target']) # 디코더의 레이블\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.460871Z","iopub.execute_input":"2024-08-14T07:53:54.461111Z","iopub.status.idle":"2024-08-14T07:53:54.477226Z","shell.execute_reply.started":"2024-08-14T07:53:54.461089Z","shell.execute_reply":"2024-08-14T07:53:54.476421Z"},"trusted":true},"execution_count":195,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"indices = np.arange(encoder_input.shape[0])\nnp.random.shuffle(indices)\nprint(indices)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.478124Z","iopub.execute_input":"2024-08-14T07:53:54.478378Z","iopub.status.idle":"2024-08-14T07:53:54.490818Z","shell.execute_reply.started":"2024-08-14T07:53:54.478356Z","shell.execute_reply":"2024-08-14T07:53:54.489867Z"},"trusted":true},"execution_count":196,"outputs":[{"name":"stdout","text":"[66037 22072 60470 ... 16613  8061 59395]\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_input = encoder_input[indices]\ndecoder_input = decoder_input[indices]\ndecoder_target = decoder_target[indices]\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.492075Z","iopub.execute_input":"2024-08-14T07:53:54.492617Z","iopub.status.idle":"2024-08-14T07:53:54.518972Z","shell.execute_reply.started":"2024-08-14T07:53:54.492591Z","shell.execute_reply":"2024-08-14T07:53:54.518025Z"},"trusted":true},"execution_count":197,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"n_of_val = int(len(encoder_input)*0.2)\nprint('테스트 데이터의 수 :', n_of_val)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.520260Z","iopub.execute_input":"2024-08-14T07:53:54.520665Z","iopub.status.idle":"2024-08-14T07:53:54.525635Z","shell.execute_reply.started":"2024-08-14T07:53:54.520631Z","shell.execute_reply":"2024-08-14T07:53:54.524694Z"},"trusted":true},"execution_count":198,"outputs":[{"name":"stdout","text":"테스트 데이터의 수 : 19436\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_input_train = encoder_input[:-n_of_val]\ndecoder_input_train = decoder_input[:-n_of_val]\ndecoder_target_train = decoder_target[:-n_of_val]\n\nencoder_input_test = encoder_input[-n_of_val:]\ndecoder_input_test = decoder_input[-n_of_val:]\ndecoder_target_test = decoder_target[-n_of_val:]\n\nprint('훈련 데이터의 개수 :', len(encoder_input_train))\nprint('훈련 레이블의 개수 :', len(decoder_input_train))\nprint('테스트 데이터의 개수 :', len(encoder_input_test))\nprint('테스트 레이블의 개수 :', len(decoder_input_test))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.526819Z","iopub.execute_input":"2024-08-14T07:53:54.527109Z","iopub.status.idle":"2024-08-14T07:53:54.536257Z","shell.execute_reply.started":"2024-08-14T07:53:54.527085Z","shell.execute_reply":"2024-08-14T07:53:54.535352Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"훈련 데이터의 개수 : 77747\n훈련 레이블의 개수 : 77747\n테스트 데이터의 개수 : 19436\n테스트 레이블의 개수 : 19436\n","output_type":"stream"}]},{"cell_type":"code","source":"src_tokenizer = Tokenizer() # 토크나이저 정의\nsrc_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:54.537373Z","iopub.execute_input":"2024-08-14T07:53:54.537640Z","iopub.status.idle":"2024-08-14T07:53:57.883210Z","shell.execute_reply.started":"2024-08-14T07:53:54.537617Z","shell.execute_reply":"2024-08-14T07:53:57.882232Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"src_tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:57.884492Z","iopub.execute_input":"2024-08-14T07:53:57.884797Z","iopub.status.idle":"2024-08-14T07:53:57.922456Z","shell.execute_reply.started":"2024-08-14T07:53:57.884771Z","shell.execute_reply":"2024-08-14T07:53:57.921367Z"},"trusted":true},"execution_count":201,"outputs":[{"execution_count":201,"output_type":"execute_result","data":{"text/plain":"{'said': 1,\n 'india': 2,\n 'year': 3,\n 'added': 4,\n 'us': 5,\n 'also': 6,\n 'first': 7,\n 'government': 8,\n 'police': 9,\n 'people': 10,\n 'two': 11,\n 'indian': 12,\n 'old': 13,\n 'minister': 14,\n 'film': 15,\n 'president': 16,\n 'one': 17,\n 'crore': 18,\n 'world': 19,\n 'court': 20,\n 'state': 21,\n 'reportedly': 22,\n 'years': 23,\n 'would': 24,\n 'new': 25,\n 'delhi': 26,\n 'former': 27,\n 'time': 28,\n 'last': 29,\n 'reports': 30,\n 'three': 31,\n 'company': 32,\n 'earlier': 33,\n 'based': 34,\n 'congress': 35,\n 'like': 36,\n 'man': 37,\n 'bjp': 38,\n 'country': 39,\n 'claimed': 40,\n 'team': 41,\n 'accused': 42,\n 'day': 43,\n 'chief': 44,\n 'trump': 45,\n 'singh': 46,\n 'pakistan': 47,\n 'modi': 48,\n 'million': 49,\n 'pm': 50,\n 'actor': 51,\n 'women': 52,\n 'according': 53,\n 'allegedly': 54,\n 'made': 55,\n 'pradesh': 56,\n 'monday': 57,\n 'party': 58,\n 'friday': 59,\n 'comes': 60,\n 'wednesday': 61,\n 'tuesday': 62,\n 'lakh': 63,\n 'woman': 64,\n 'called': 65,\n 'around': 66,\n 'video': 67,\n 'thursday': 68,\n 'asked': 69,\n 'mumbai': 70,\n 'billion': 71,\n 'tweeted': 72,\n 'took': 73,\n 'including': 74,\n 'khan': 75,\n 'test': 76,\n 'case': 77,\n 'cm': 78,\n 'found': 79,\n 'four': 80,\n 'revealed': 81,\n 'actress': 82,\n 'national': 83,\n 'officials': 84,\n 'leader': 85,\n 'saturday': 86,\n 'sunday': 87,\n 'could': 88,\n 'arrested': 89,\n 'five': 90,\n 'second': 91,\n 'announced': 92,\n 'high': 93,\n 'match': 94,\n 'wrote': 95,\n 'following': 96,\n 'group': 97,\n 'used': 98,\n 'since': 99,\n 'however': 100,\n 'captain': 101,\n 'startup': 102,\n 'users': 103,\n 'notably': 104,\n 'alleged': 105,\n 'china': 106,\n 'take': 107,\n 'media': 108,\n 'cricket': 109,\n 'killed': 110,\n 'bank': 111,\n 'part': 112,\n 'family': 113,\n 'due': 114,\n 'may': 115,\n 'narendra': 116,\n 'international': 117,\n 'led': 118,\n 'th': 119,\n 'make': 120,\n 'get': 121,\n 'ceo': 122,\n 'per': 123,\n 'days': 124,\n 'donald': 125,\n 'security': 126,\n 'adding': 127,\n 'six': 128,\n 'month': 129,\n 'gandhi': 130,\n 'set': 131,\n 'air': 132,\n 'twitter': 133,\n 'facebook': 134,\n 'home': 135,\n 'house': 136,\n 'south': 137,\n 'kapoor': 138,\n 'incident': 139,\n 'life': 140,\n 'data': 141,\n 'report': 142,\n 'series': 143,\n 'saying': 144,\n 'help': 145,\n 'number': 146,\n 'official': 147,\n 'picture': 148,\n 'using': 149,\n 'north': 150,\n 'work': 151,\n 'social': 152,\n 'another': 153,\n 'several': 154,\n 'prime': 155,\n 'girl': 156,\n 'uttar': 157,\n 'show': 158,\n 'supreme': 159,\n 'kumar': 160,\n 'back': 161,\n 'later': 162,\n 'wife': 163,\n 'car': 164,\n 'next': 165,\n 'released': 166,\n 'students': 167,\n 'post': 168,\n 'week': 169,\n 'among': 170,\n 'union': 171,\n 'board': 172,\n 'least': 173,\n 'seen': 174,\n 'hospital': 175,\n 'money': 176,\n 'google': 177,\n 'filed': 178,\n 'public': 179,\n 'death': 180,\n 'upcoming': 181,\n 'men': 182,\n 'australia': 183,\n 'elections': 184,\n 'city': 185,\n 'third': 186,\n 'rahul': 187,\n 'user': 188,\n 'months': 189,\n 'kohli': 190,\n 'talking': 191,\n 'nearly': 192,\n 'recently': 193,\n 'taken': 194,\n 'launched': 195,\n 'school': 196,\n 'without': 197,\n 'become': 198,\n 'record': 199,\n 'cup': 200,\n 'got': 201,\n 'uk': 202,\n 'children': 203,\n 'shared': 204,\n 'director': 205,\n 'technology': 206,\n 'worth': 207,\n 'centre': 208,\n 'even': 209,\n 'attack': 210,\n 'release': 211,\n 'son': 212,\n 'many': 213,\n 'named': 214,\n 'online': 215,\n 'times': 216,\n 'ever': 217,\n 'others': 218,\n 'run': 219,\n 'win': 220,\n 'away': 221,\n 'co': 222,\n 'came': 223,\n 'researchers': 224,\n 'deal': 225,\n 'held': 226,\n 'district': 227,\n 'ministry': 228,\n 'korea': 229,\n 'place': 230,\n 'use': 231,\n 'england': 232,\n 'father': 233,\n 'making': 234,\n 'hit': 235,\n 'sharma': 236,\n 'reported': 237,\n 'cannot': 238,\n 'final': 239,\n 'order': 240,\n 'body': 241,\n 'shah': 242,\n 'law': 243,\n 'given': 244,\n 'told': 245,\n 'died': 246,\n 'open': 247,\n 'system': 248,\n 'across': 249,\n 'founder': 250,\n 'long': 251,\n 'directed': 252,\n 'water': 253,\n 'working': 254,\n 'general': 255,\n 'received': 256,\n 'capital': 257,\n 'event': 258,\n 'members': 259,\n 'pay': 260,\n 'every': 261,\n 'started': 262,\n 'app': 263,\n 'american': 264,\n 'tax': 265,\n 'along': 266,\n 'apple': 267,\n 'daughter': 268,\n 'best': 269,\n 'army': 270,\n 'hours': 271,\n 'flight': 272,\n 'taking': 273,\n 'chinese': 274,\n 'come': 275,\n 'assembly': 276,\n 'runs': 277,\n 'karnataka': 278,\n 'person': 279,\n 'department': 280,\n 'united': 281,\n 'raised': 282,\n 'mother': 283,\n 'decision': 284,\n 'way': 285,\n 'firm': 286,\n 'go': 287,\n 'university': 288,\n 'left': 289,\n 'top': 290,\n 'lost': 291,\n 'want': 292,\n 'play': 293,\n 'today': 294,\n 'fire': 295,\n 'human': 296,\n 'highest': 297,\n 'space': 298,\n 'name': 299,\n 'kashmir': 300,\n 'services': 301,\n 'injured': 302,\n 'went': 303,\n 'largest': 304,\n 'never': 305,\n 'within': 306,\n 'service': 307,\n 'airport': 308,\n 'seven': 309,\n 'power': 310,\n 'odi': 311,\n 'star': 312,\n 'employees': 313,\n 'became': 314,\n 'cricketer': 315,\n 'end': 316,\n 'right': 317,\n 'australian': 318,\n 'player': 319,\n 'authorities': 320,\n 'total': 321,\n 'issued': 322,\n 'well': 323,\n 'league': 324,\n 'maharashtra': 325,\n 'action': 326,\n 'gold': 327,\n 'food': 328,\n 'states': 329,\n 'chairman': 330,\n 'sexual': 331,\n 'officer': 332,\n 'read': 333,\n 'kerala': 334,\n 'bengaluru': 335,\n 'good': 336,\n 'russia': 337,\n 'business': 338,\n 'information': 339,\n 'ram': 340,\n 'companies': 341,\n 'december': 342,\n 'central': 343,\n 'countries': 344,\n 'speaking': 345,\n 'playing': 346,\n 'meanwhile': 347,\n 'private': 348,\n 'known': 349,\n 'sent': 350,\n 'films': 351,\n 'round': 352,\n 'give': 353,\n 'meeting': 354,\n 'move': 355,\n 'posted': 356,\n 'eight': 357,\n 'near': 358,\n 'russian': 359,\n 'march': 360,\n 'support': 361,\n 'head': 362,\n 'currently': 363,\n 'free': 364,\n 'office': 365,\n 'role': 366,\n 'virat': 367,\n 'foreign': 368,\n 'amid': 369,\n 'share': 370,\n 'tweet': 371,\n 'cases': 372,\n 'gujarat': 373,\n 'list': 374,\n 'election': 375,\n 'face': 376,\n 'ball': 377,\n 'special': 378,\n 'visit': 379,\n 'slammed': 380,\n 'issue': 381,\n 'june': 382,\n 'ahead': 383,\n 'tamil': 384,\n 'going': 385,\n 'child': 386,\n 'love': 387,\n 'ban': 388,\n 'bihar': 389,\n 'claiming': 390,\n 'market': 391,\n 'april': 392,\n 'commission': 393,\n 'sabha': 394,\n 'scored': 395,\n 'war': 396,\n 'instagram': 397,\n 'scheduled': 398,\n 'un': 399,\n 'statement': 400,\n 'salman': 401,\n 'investigation': 402,\n 'uber': 403,\n 'played': 404,\n 'sri': 405,\n 'non': 406,\n 'passengers': 407,\n 'know': 408,\n 'need': 409,\n 'january': 410,\n 'registered': 411,\n 'ipl': 412,\n 'nuclear': 413,\n 'ago': 414,\n 'think': 415,\n 'senior': 416,\n 'military': 417,\n 'punjab': 418,\n 'anti': 419,\n 'husband': 420,\n 'much': 421,\n 'funding': 422,\n 'secretary': 423,\n 'health': 424,\n 'song': 425,\n 'class': 426,\n 'september': 427,\n 'real': 428,\n 'ex': 429,\n 'west': 430,\n 'august': 431,\n 'development': 432,\n 'yadav': 433,\n 'shot': 434,\n 'boy': 435,\n 'news': 436,\n 'platform': 437,\n 'passed': 438,\n 'defence': 439,\n 'major': 440,\n 'age': 441,\n 'global': 442,\n 'inside': 443,\n 'leaders': 444,\n 'wedding': 445,\n 'student': 446,\n 'feature': 447,\n 'put': 448,\n 'shows': 449,\n 'pakistani': 450,\n 'station': 451,\n 'singer': 452,\n 'rape': 453,\n 'train': 454,\n 'players': 455,\n 'late': 456,\n 'area': 457,\n 'dead': 458,\n 'finance': 459,\n 'complaint': 460,\n 'see': 461,\n 'launch': 462,\n 'giant': 463,\n 'trying': 464,\n 'ordered': 465,\n 'mp': 466,\n 'political': 467,\n 'recent': 468,\n 'allegations': 469,\n 'denied': 470,\n 'member': 471,\n 'couple': 472,\n 'cbi': 473,\n 'failed': 474,\n 'bollywood': 475,\n 'suicide': 476,\n 'force': 477,\n 'award': 478,\n 'project': 479,\n 'november': 480,\n 'female': 481,\n 'stop': 482,\n 'jail': 483,\n 'medical': 484,\n 'bill': 485,\n 'july': 486,\n 'despite': 487,\n 'still': 488,\n 'financial': 489,\n 'october': 490,\n 'lead': 491,\n 'wanted': 492,\n 'act': 493,\n 'side': 494,\n 'amazon': 495,\n 'towards': 496,\n 'phone': 497,\n 'agency': 498,\n 'fake': 499,\n 'expected': 500,\n 'getting': 501,\n 'decided': 502,\n 'game': 503,\n 'allowed': 504,\n 'different': 505,\n 'past': 506,\n 'control': 507,\n 'local': 508,\n 'dhoni': 509,\n 'white': 510,\n 'road': 511,\n 'campaign': 512,\n 'saudi': 513,\n 'victim': 514,\n 'rajasthan': 515,\n 'claims': 516,\n 'temple': 517,\n 'forces': 518,\n 'stated': 519,\n 'nadu': 520,\n 'founded': 521,\n 'together': 522,\n 'sachin': 523,\n 'change': 524,\n 'building': 525,\n 'history': 526,\n 'scientists': 527,\n 'married': 528,\n 'vice': 529,\n 'plans': 530,\n 'mark': 531,\n 'korean': 532,\n 'outside': 533,\n 'birthday': 534,\n 'earth': 535,\n 'look': 536,\n 'study': 537,\n 'british': 538,\n 'priyanka': 539,\n 'gst': 540,\n 'calling': 541,\n 'minutes': 542,\n 'workers': 543,\n 'games': 544,\n 'paid': 545,\n 'committee': 546,\n 'batsman': 547,\n 'rights': 548,\n 'account': 549,\n 'railway': 550,\n 'reacting': 551,\n 'winning': 552,\n 'jammu': 553,\n 'driver': 554,\n 'quarter': 555,\n 'refused': 556,\n 'debut': 557,\n 'madhya': 558,\n 'nation': 559,\n 'musk': 560,\n 'coach': 561,\n 'cost': 562,\n 'seeking': 563,\n 'till': 564,\n 'letter': 565,\n 'planning': 566,\n 'sharing': 567,\n 'football': 568,\n 'behind': 569,\n 'iran': 570,\n 'starrer': 571,\n 'live': 572,\n 'banned': 573,\n 'half': 574,\n 'night': 575,\n 'violence': 576,\n 'pictures': 577,\n 'mobile': 578,\n 'ali': 579,\n 'parents': 580,\n 'provide': 581,\n 'london': 582,\n 'great': 583,\n 'black': 584,\n 'always': 585,\n 'filmmaker': 586,\n 'developed': 587,\n 'nine': 588,\n 'africa': 589,\n 'fund': 590,\n 'fell': 591,\n 'call': 592,\n 'border': 593,\n 'instead': 594,\n 'haryana': 595,\n 'big': 596,\n 'nasa': 597,\n 'season': 598,\n 'murder': 599,\n 'single': 600,\n 'tesla': 601,\n 'met': 602,\n 'french': 603,\n 'affairs': 604,\n 'cash': 605,\n 'land': 606,\n 'leave': 607,\n 'protest': 608,\n 'career': 609,\n 'fourth': 610,\n 'matches': 611,\n 'self': 612,\n 'declared': 613,\n 'justice': 614,\n 'biggest': 615,\n 'muslim': 616,\n 'light': 617,\n 'previous': 618,\n 'gave': 619,\n 'parliament': 620,\n 'intelligence': 621,\n 'personal': 622,\n 'must': 623,\n 'lok': 624,\n 'harassment': 625,\n 'amount': 626,\n 'banks': 627,\n 'spokesperson': 628,\n 'turned': 629,\n 'innings': 630,\n 'confirmed': 631,\n 'investors': 632,\n 'club': 633,\n 'offered': 634,\n 'bachchan': 635,\n 'matter': 636,\n 'price': 637,\n 'industry': 638,\n 'start': 639,\n 'sale': 640,\n 'better': 641,\n 'loss': 642,\n 'flipkart': 643,\n 'opposition': 644,\n 'aadhaar': 645,\n 'already': 646,\n 'staff': 647,\n 'admitted': 648,\n 'current': 649,\n 'suspended': 650,\n 'probe': 651,\n 'charges': 652,\n 'brother': 653,\n 'model': 654,\n 'japan': 655,\n 'tournament': 656,\n 'aircraft': 657,\n 'created': 658,\n 'period': 659,\n 'driving': 660,\n 'farmers': 661,\n 'far': 662,\n 'bengal': 663,\n 'yet': 664,\n 'km': 665,\n 'able': 666,\n 'hyderabad': 667,\n 'vehicles': 668,\n 'owned': 669,\n 'written': 670,\n 'february': 671,\n 'shares': 672,\n 'nations': 673,\n 'missing': 674,\n 'stating': 675,\n 'tried': 676,\n 'say': 677,\n 'cut': 678,\n 'include': 679,\n 'indians': 680,\n 'appointed': 681,\n 'done': 682,\n 'increase': 683,\n 'champions': 684,\n 'return': 685,\n 'income': 686,\n 'girls': 687,\n 'caused': 688,\n 'wickets': 689,\n 'fight': 690,\n 'education': 691,\n 'level': 692,\n 'let': 693,\n 'issues': 694,\n 'chopra': 695,\n 'baby': 696,\n 'character': 697,\n 'allow': 698,\n 'create': 699,\n 'happy': 700,\n 'showed': 701,\n 'customers': 702,\n 'hotel': 703,\n 'job': 704,\n 'photo': 705,\n 'organisation': 706,\n 'proposed': 707,\n 'commerce': 708,\n 'village': 709,\n 'meet': 710,\n 'carrying': 711,\n 'accounts': 712,\n 'process': 713,\n 'rukh': 714,\n 'term': 715,\n 'lanka': 716,\n 'defeated': 717,\n 'demanded': 718,\n 'governor': 719,\n 'form': 720,\n 'stake': 721,\n 'plan': 722,\n 'full': 723,\n 'officers': 724,\n 'suggested': 725,\n 'reach': 726,\n 'investment': 727,\n 'gone': 728,\n 'council': 729,\n 'operations': 730,\n 'rbi': 731,\n 'bus': 732,\n 'keep': 733,\n 'treatment': 734,\n 'hindu': 735,\n 'forced': 736,\n 'sought': 737,\n 'tv': 738,\n 'passenger': 739,\n 'showing': 740,\n 'wearing': 741,\n 'date': 742,\n 'oil': 743,\n 'rao': 744,\n 'policy': 745,\n 'sold': 746,\n 'cars': 747,\n 'economic': 748,\n 'hand': 749,\n 'reliance': 750,\n 'response': 751,\n 'attacks': 752,\n 'ongoing': 753,\n 'vehicle': 754,\n 'illegal': 755,\n 'things': 756,\n 'products': 757,\n 'sanjay': 758,\n 'mla': 759,\n 'involved': 760,\n 'continue': 761,\n 'score': 762,\n 'caught': 763,\n 'features': 764,\n 'travel': 765,\n 'broke': 766,\n 'sex': 767,\n 'discovered': 768,\n 'related': 769,\n 'reached': 770,\n 'marriage': 771,\n 'region': 772,\n 'room': 773,\n 'various': 774,\n 'legal': 775,\n 'talks': 776,\n 'adityanath': 777,\n 'future': 778,\n 'bcci': 779,\n 'deepika': 780,\n 'committed': 781,\n 'zealand': 782,\n 'ranveer': 783,\n 'airline': 784,\n 'community': 785,\n 'lot': 786,\n 'afghanistan': 787,\n 'ensure': 788,\n 'corporation': 789,\n 'access': 790,\n 'title': 791,\n 'karan': 792,\n 'story': 793,\n 'hearing': 794,\n 'andhra': 795,\n 'terror': 796,\n 'compared': 797,\n 'less': 798,\n 'trade': 799,\n 'forward': 800,\n 'threatened': 801,\n 'doctors': 802,\n 'warned': 803,\n 'addressing': 804,\n 'personnel': 805,\n 'saw': 806,\n 'revenue': 807,\n 'york': 808,\n 'feel': 809,\n 'yogi': 810,\n 'friends': 811,\n 'notice': 812,\n 'fans': 813,\n 'giving': 814,\n 'born': 815,\n 'conducted': 816,\n 'signed': 817,\n 'electric': 818,\n 'red': 819,\n 'safety': 820,\n 'line': 821,\n 'friend': 822,\n 'research': 823,\n 'ended': 824,\n 'jaitley': 825,\n 'delivery': 826,\n 'spot': 827,\n 'schools': 828,\n 'birth': 829,\n 'viral': 830,\n 'seats': 831,\n 'deputy': 832,\n 'looking': 833,\n 'find': 834,\n 'offer': 835,\n 'vijay': 836,\n 'whose': 837,\n 'anil': 838,\n 'internet': 839,\n 'kg': 840,\n 'agreed': 841,\n 'judge': 842,\n 'asking': 843,\n 'tendulkar': 844,\n 'bangladesh': 845,\n 'increased': 846,\n 'almost': 847,\n 'helped': 848,\n 'points': 849,\n 'pacer': 850,\n 'al': 851,\n 'value': 852,\n 'hour': 853,\n 'close': 854,\n 'built': 855,\n 'protests': 856,\n 'soon': 857,\n 'weeks': 858,\n 'website': 859,\n 'corruption': 860,\n 'television': 861,\n 'stars': 862,\n 'someone': 863,\n 'victory': 864,\n 'parties': 865,\n 'suffered': 866,\n 'small': 867,\n 'opened': 868,\n 'annual': 869,\n 'killing': 870,\n 'english': 871,\n 'dismissed': 872,\n 'college': 873,\n 'rejected': 874,\n 'digital': 875,\n 'net': 876,\n 'strike': 877,\n 'aged': 878,\n 'citizens': 879,\n 'brand': 880,\n 'removed': 881,\n 'rohit': 882,\n 'administration': 883,\n 'approved': 884,\n 'germany': 885,\n 'really': 886,\n 'fine': 887,\n 'similar': 888,\n 'sena': 889,\n 'airlines': 890,\n 'wants': 891,\n 'kangana': 892,\n 'victims': 893,\n 'ceremony': 894,\n 'chennai': 895,\n 'traffic': 896,\n 'whatsapp': 897,\n 'growth': 898,\n 'arrest': 899,\n 'rate': 900,\n 'position': 901,\n 'german': 902,\n 'front': 903,\n 'management': 904,\n 'trophy': 905,\n 'worked': 906,\n 'included': 907,\n 'ambani': 908,\n 'festival': 909,\n 'aimed': 910,\n 'hai': 911,\n 'medal': 912,\n 'low': 913,\n 'emergency': 914,\n 'owner': 915,\n 'buy': 916,\n 'spinner': 917,\n 'actors': 918,\n 'akshay': 919,\n 'fast': 920,\n 'device': 921,\n 'interview': 922,\n 'accident': 923,\n 'injuries': 924,\n 'kolkata': 925,\n 'imposed': 926,\n 'employee': 927,\n 'claim': 928,\n 'early': 929,\n 'anyone': 930,\n 'kapil': 931,\n 'ground': 932,\n 'grand': 933,\n 'details': 934,\n 'asian': 935,\n 'search': 936,\n 'music': 937,\n 'available': 938,\n 'france': 939,\n 'shooting': 940,\n 'charge': 941,\n 'areas': 942,\n 'brought': 943,\n 'production': 944,\n 'jobs': 945,\n 'islamic': 946,\n 'kejriwal': 947,\n 'metro': 948,\n 'scheme': 949,\n 'association': 950,\n 'surfaced': 951,\n 'urged': 952,\n 'fashion': 953,\n 'something': 954,\n 'ms': 955,\n 'whether': 956,\n 'joined': 957,\n 'began': 958,\n 'elon': 959,\n 'prasad': 960,\n 'message': 961,\n 'seized': 962,\n 'fifa': 963,\n 'book': 964,\n 'leading': 965,\n 'tests': 966,\n 'crime': 967,\n 'followed': 968,\n 'funds': 969,\n 'site': 970,\n 'mission': 971,\n 'wrong': 972,\n 'goal': 973,\n 'rules': 974,\n 'militants': 975,\n 'amit': 976,\n 'cover': 977,\n 'payments': 978,\n 'training': 979,\n 'sanctions': 980,\n 'charged': 981,\n 'opening': 982,\n 'affected': 983,\n 'asia': 984,\n 'served': 985,\n 'image': 986,\n 'terrorists': 987,\n 'joint': 988,\n 'construction': 989,\n 'tennis': 990,\n 'bad': 991,\n 'journalist': 992,\n 'fraud': 993,\n 'energy': 994,\n 'bring': 995,\n 'cause': 996,\n 'plane': 997,\n 'aap': 998,\n 'cancer': 999,\n 'card': 1000,\n ...}"},"metadata":{}}]},{"cell_type":"code","source":"threshold = 10\ntotal_cnt = len(src_tokenizer.word_index) # 단어의 수\nrare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\ntotal_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\nrare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n\n# # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\nfor key, value in src_tokenizer.word_counts.items():\n    total_freq = total_freq + value\n\n    # 단어의 등장 빈도수가 threshold보다 작으면\n    if(value < threshold):\n        rare_cnt = rare_cnt + 1\n        rare_freq = rare_freq + value\n\nprint('단어 집합(vocabulary)의 크기 :', total_cnt)\nprint('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\nprint('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\nprint(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\nprint(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:57.923671Z","iopub.execute_input":"2024-08-14T07:53:57.923984Z","iopub.status.idle":"2024-08-14T07:53:57.975947Z","shell.execute_reply.started":"2024-08-14T07:53:57.923959Z","shell.execute_reply":"2024-08-14T07:53:57.975090Z"},"trusted":true},"execution_count":202,"outputs":[{"name":"stdout","text":"단어 집합(vocabulary)의 크기 : 69407\n등장 빈도가 9번 이하인 희귀 단어의 수: 51125\n단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 18282\n단어 집합에서 희귀 단어의 비율: 73.65971731957872\n전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.592919621342387\n","output_type":"stream"}]},{"cell_type":"code","source":"src_vocab = 15000\nsrc_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\nsrc_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:53:57.977049Z","iopub.execute_input":"2024-08-14T07:53:57.977328Z","iopub.status.idle":"2024-08-14T07:54:01.259622Z","shell.execute_reply.started":"2024-08-14T07:53:57.977304Z","shell.execute_reply":"2024-08-14T07:54:01.258588Z"},"trusted":true},"execution_count":203,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"# 텍스트 시퀀스를 정수 시퀀스로 변환\nencoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \nencoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n\n# 잘 진행되었는지 샘플 출력\nprint(encoder_input_train[:3])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:01.261099Z","iopub.execute_input":"2024-08-14T07:54:01.261519Z","iopub.status.idle":"2024-08-14T07:54:04.280718Z","shell.execute_reply.started":"2024-08-14T07:54:01.261481Z","shell.execute_reply":"2024-08-14T07:54:04.279779Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"[[50, 116, 48, 61, 1, 2, 605, 2902, 6781, 275, 1448, 2047, 8, 3436, 50, 48, 1, 3436, 14201, 1516, 10, 121, 2509, 2761, 7968, 8, 4], [6924, 57, 92, 7, 481, 122, 9807, 9808, 1401, 23, 9808, 1219, 330, 929, 1401, 490, 7969, 16, 1893, 2, 305, 12131, 24, 2172, 491, 7417, 32, 1, 9808], [67, 951, 215, 740, 31, 4129, 525, 9809, 3262, 932, 306, 1280, 795, 56, 13256, 86, 139, 1029, 151, 1083, 3892, 248, 525, 3913, 237, 662, 1335, 3657, 124, 414, 123, 30]]\n","output_type":"stream"}]},{"cell_type":"code","source":"tar_tokenizer = Tokenizer()\ntar_tokenizer.fit_on_texts(decoder_input_train)\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:04.281802Z","iopub.execute_input":"2024-08-14T07:54:04.282079Z","iopub.status.idle":"2024-08-14T07:54:05.797711Z","shell.execute_reply.started":"2024-08-14T07:54:04.282053Z","shell.execute_reply":"2024-08-14T07:54:05.796772Z"},"trusted":true},"execution_count":205,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"code","source":"threshold = 6\ntotal_cnt = len(tar_tokenizer.word_index) # 단어의 수\nrare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\ntotal_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\nrare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n\n# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\nfor key, value in tar_tokenizer.word_counts.items():\n    total_freq = total_freq + value\n\n    # 단어의 등장 빈도수가 threshold보다 작으면\n    if(value < threshold):\n        rare_cnt = rare_cnt + 1\n        rare_freq = rare_freq + value\n\nprint('단어 집합(vocabulary)의 크기 :', total_cnt)\nprint('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\nprint('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\nprint(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\nprint(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:05.798993Z","iopub.execute_input":"2024-08-14T07:54:05.799390Z","iopub.status.idle":"2024-08-14T07:54:05.824629Z","shell.execute_reply.started":"2024-08-14T07:54:05.799355Z","shell.execute_reply":"2024-08-14T07:54:05.823566Z"},"trusted":true},"execution_count":206,"outputs":[{"name":"stdout","text":"단어 집합(vocabulary)의 크기 : 30004\n등장 빈도가 5번 이하인 희귀 단어의 수: 19643\n단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10361\n단어 집합에서 희귀 단어의 비율: 65.46793760831889\n전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.71603643126222\n","output_type":"stream"}]},{"cell_type":"code","source":"tar_vocab = 10000\ntar_tokenizer = Tokenizer(num_words=tar_vocab) \ntar_tokenizer.fit_on_texts(decoder_input_train)\ntar_tokenizer.fit_on_texts(decoder_target_train)\n\n# 텍스트 시퀀스를 정수 시퀀스로 변환\ndecoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \ndecoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\ndecoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\ndecoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n\n# 잘 변환되었는지 확인\nprint('input')\nprint('input ',decoder_input_train[:5])\nprint('target')\nprint('decoder ',decoder_target_train[:5])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:05.826861Z","iopub.execute_input":"2024-08-14T07:54:05.827165Z","iopub.status.idle":"2024-08-14T07:54:11.905634Z","shell.execute_reply.started":"2024-08-14T07:54:05.827140Z","shell.execute_reply":"2024-08-14T07:54:11.904595Z"},"trusted":true},"execution_count":207,"outputs":[{"name":"stdout","text":"input\ninput  [[1, 643, 3, 2093, 6408, 400, 3, 13, 11, 2031], [1, 5376, 69, 7150, 5845, 3, 2264, 179, 11, 58], [1, 77, 688, 1486, 1012, 2223, 4, 336], [1, 1195, 200, 479, 209, 4, 6409, 1063], [1, 1428, 152, 5, 3290, 156, 5, 448, 66, 4, 1487]]\ntarget\ndecoder  [[643, 3, 2093, 6408, 400, 3, 13, 11, 2031, 2], [5376, 69, 7150, 5845, 3, 2264, 179, 11, 58, 2], [77, 688, 1486, 1012, 2223, 4, 336, 2], [1195, 200, 479, 209, 4, 6409, 1063, 2], [1428, 152, 5, 3290, 156, 5, 448, 66, 4, 1487, 2]]\n","output_type":"stream"}]},{"cell_type":"code","source":"drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\ndrop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n\nprint('삭제할 훈련 데이터의 개수 :', len(drop_train))\nprint('삭제할 테스트 데이터의 개수 :', len(drop_test))\n\nencoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\ndecoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\ndecoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n\nencoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\ndecoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\ndecoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n\nprint('훈련 데이터의 개수 :', len(encoder_input_train))\nprint('훈련 레이블의 개수 :', len(decoder_input_train))\nprint('테스트 데이터의 개수 :', len(encoder_input_test))\nprint('테스트 레이블의 개수 :', len(decoder_input_test))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:11.906820Z","iopub.execute_input":"2024-08-14T07:54:11.907131Z","iopub.status.idle":"2024-08-14T07:54:11.981385Z","shell.execute_reply.started":"2024-08-14T07:54:11.907103Z","shell.execute_reply":"2024-08-14T07:54:11.980283Z"},"trusted":true},"execution_count":208,"outputs":[{"name":"stdout","text":"삭제할 훈련 데이터의 개수 : 0\n삭제할 테스트 데이터의 개수 : 0\n훈련 데이터의 개수 : 77747\n훈련 레이블의 개수 : 77747\n테스트 데이터의 개수 : 19436\n테스트 레이블의 개수 : 19436\n","output_type":"stream"}]},{"cell_type":"code","source":"drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\ndrop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n\nprint('삭제할 훈련 데이터의 개수 :', len(drop_train))\nprint('삭제할 테스트 데이터의 개수 :', len(drop_test))\n\nencoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\ndecoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\ndecoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n\nencoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\ndecoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\ndecoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n\nprint('훈련 데이터의 개수 :', len(encoder_input_train))\nprint('훈련 레이블의 개수 :', len(decoder_input_train))\nprint('테스트 데이터의 개수 :', len(encoder_input_test))\nprint('테스트 레이블의 개수 :', len(decoder_input_test))\n\nencoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\nencoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\ndecoder_input_train = pad_sequences(decoder_input_train, maxlen=headline_max_len, padding='post')\ndecoder_target_train = pad_sequences(decoder_target_train, maxlen=headline_max_len, padding='post')\ndecoder_input_test = pad_sequences(decoder_input_test, maxlen=headline_max_len, padding='post')\ndecoder_target_test = pad_sequences(decoder_target_test, maxlen=headline_max_len, padding='post')\nprint('=3')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:11.982959Z","iopub.execute_input":"2024-08-14T07:54:11.983406Z","iopub.status.idle":"2024-08-14T07:54:13.514861Z","shell.execute_reply.started":"2024-08-14T07:54:11.983367Z","shell.execute_reply":"2024-08-14T07:54:13.513838Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stdout","text":"삭제할 훈련 데이터의 개수 : 0\n삭제할 테스트 데이터의 개수 : 0\n훈련 데이터의 개수 : 77747\n훈련 레이블의 개수 : 77747\n테스트 데이터의 개수 : 19436\n테스트 레이블의 개수 : 19436\n=3\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# 인코더 설계 시작\nembedding_dim = 128\nhidden_size = 256\n\n# 인코더\nencoder_inputs = Input(shape=(text_max_len,))\n\n# 인코더의 임베딩 층\nenc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n\n# 인코더의 LSTM 1\n# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\nencoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n\n# 인코더의 LSTM 2\n# [[YOUR CODE]]\nencoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n\n# 인코더의 LSTM 3\n# [[YOUR CODE]]\nencoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:39:27.580421Z","iopub.execute_input":"2024-08-14T05:39:27.580771Z","iopub.status.idle":"2024-08-14T05:39:27.723493Z","shell.execute_reply.started":"2024-08-14T05:39:27.580746Z","shell.execute_reply":"2024-08-14T05:39:27.722251Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# 인코더 설계 시작\nembedding_dim = 128\nhidden_size = 256\n\n# 인코더\nencoder_inputs = Input(shape=(text_max_len,))\n\n# 인코더의 임베딩 층\nenc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n\n# 인코더의 LSTM 1\n# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\nencoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n\n# 인코더의 LSTM 2\n# [[YOUR CODE]]\nencoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n\n# 인코더의 LSTM 3\n# [[YOUR CODE]]\nencoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,recurrent_dropout = 0.4)\nencoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n\n# 디코더 설계\ndecoder_inputs = Input(shape=(None,))\n\n# 디코더의 임베딩 층\ndec_emb_layer = Embedding(tar_vocab, embedding_dim)\ndec_emb = dec_emb_layer(decoder_inputs)\n\n# 디코더의 LSTM\n# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\ndecoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])\n\n# 디코더의 출력층\ndecoder_softmax_layer = Dense(tar_vocab, activation='softmax')\ndecoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n\n# 모델 정의\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\nmodel.summary()\n\nfrom tensorflow.keras.layers import AdditiveAttention\n\n# 어텐션 층(어텐션 함수)\nattn_layer = AdditiveAttention(name='attention_layer')\n\n# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\nattn_out = attn_layer([decoder_outputs, encoder_output3])\n\n\n# 어텐션의 결과와 디코더의 hidden state들을 연결\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n\n# 디코더의 출력층\ndecoder_softmax_layer = Dense(tar_vocab, activation='softmax')\ndecoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n\n# 모델 정의\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n\nhistory = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n          batch_size=256, callbacks=[es], epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:43:23.433984Z","iopub.execute_input":"2024-08-14T04:43:23.434307Z","iopub.status.idle":"2024-08-14T04:43:23.482731Z","shell.execute_reply.started":"2024-08-14T04:43:23.434280Z","shell.execute_reply":"2024-08-14T04:43:23.481858Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:43:24.857876Z","iopub.execute_input":"2024-08-14T04:43:24.859064Z","iopub.status.idle":"2024-08-14T04:43:24.906211Z","shell.execute_reply.started":"2024-08-14T04:43:24.859024Z","shell.execute_reply":"2024-08-14T04:43:24.905213Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,536,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,570,000\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│                     │ \u001b[38;5;34m10000\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,225,104\u001b[0m (27.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,225,104</span> (27.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,225,104\u001b[0m (27.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,225,104</span> (27.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import AdditiveAttention\n\n# 어텐션 층(어텐션 함수)\nattn_layer = AdditiveAttention(name='attention_layer')\n\n# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\nattn_out = attn_layer([decoder_outputs, encoder_output3])\n\n\n# 어텐션의 결과와 디코더의 hidden state들을 연결\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n\n# 디코더의 출력층\ndecoder_softmax_layer = Dense(tar_vocab, activation='softmax')\ndecoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n\n# 모델 정의\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:43:28.081265Z","iopub.execute_input":"2024-08-14T04:43:28.082564Z","iopub.status.idle":"2024-08-14T04:43:28.140580Z","shell.execute_reply.started":"2024-08-14T04:43:28.082527Z","shell.execute_reply":"2024-08-14T04:43:28.139615Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,536,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m5,130,000\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m10000\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,785,360\u001b[0m (37.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,785,360</span> (37.33 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,785,360\u001b[0m (37.33 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,785,360</span> (37.33 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n\nhistory = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n          batch_size=256, callbacks=[es], epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T01:27:14.565227Z","iopub.execute_input":"2024-08-14T01:27:14.566275Z","iopub.status.idle":"2024-08-14T03:10:21.634481Z","shell.execute_reply.started":"2024-08-14T01:27:14.566226Z","shell.execute_reply":"2024-08-14T03:10:21.633506Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 401ms/step - accuracy: 0.2360 - loss: 6.3303 - val_accuracy: 0.2965 - val_loss: 5.5926\nEpoch 2/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.2931 - loss: 5.6027 - val_accuracy: 0.2992 - val_loss: 5.4908\nEpoch 3/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.2942 - loss: 5.5209 - val_accuracy: 0.3040 - val_loss: 5.3776\nEpoch 4/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.2978 - loss: 5.3938 - val_accuracy: 0.3039 - val_loss: 5.2861\nEpoch 5/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.2994 - loss: 5.2717 - val_accuracy: 0.3089 - val_loss: 5.1355\nEpoch 6/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.3054 - loss: 5.1167 - val_accuracy: 0.3126 - val_loss: 5.0256\nEpoch 7/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 403ms/step - accuracy: 0.3093 - loss: 4.9933 - val_accuracy: 0.3164 - val_loss: 4.9271\nEpoch 8/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.3118 - loss: 4.9106 - val_accuracy: 0.3183 - val_loss: 4.8613\nEpoch 9/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.3141 - loss: 4.8243 - val_accuracy: 0.3207 - val_loss: 4.7891\nEpoch 10/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.3190 - loss: 4.7260 - val_accuracy: 0.3254 - val_loss: 4.7012\nEpoch 11/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.3231 - loss: 4.6354 - val_accuracy: 0.3300 - val_loss: 4.6257\nEpoch 12/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.3282 - loss: 4.5491 - val_accuracy: 0.3347 - val_loss: 4.5604\nEpoch 13/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.3330 - loss: 4.4686 - val_accuracy: 0.3387 - val_loss: 4.4972\nEpoch 14/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 403ms/step - accuracy: 0.3382 - loss: 4.3914 - val_accuracy: 0.3424 - val_loss: 4.4407\nEpoch 15/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 406ms/step - accuracy: 0.3426 - loss: 4.3151 - val_accuracy: 0.3453 - val_loss: 4.4021\nEpoch 16/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 403ms/step - accuracy: 0.3469 - loss: 4.2444 - val_accuracy: 0.3504 - val_loss: 4.3359\nEpoch 17/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.3519 - loss: 4.1719 - val_accuracy: 0.3552 - val_loss: 4.2788\nEpoch 18/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.3572 - loss: 4.0951 - val_accuracy: 0.3589 - val_loss: 4.2283\nEpoch 19/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.3618 - loss: 4.0350 - val_accuracy: 0.3612 - val_loss: 4.1928\nEpoch 20/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.3680 - loss: 3.9596 - val_accuracy: 0.3660 - val_loss: 4.1444\nEpoch 21/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.3716 - loss: 3.9006 - val_accuracy: 0.3694 - val_loss: 4.1014\nEpoch 22/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.3769 - loss: 3.8405 - val_accuracy: 0.3718 - val_loss: 4.0675\nEpoch 23/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.3824 - loss: 3.7729 - val_accuracy: 0.3737 - val_loss: 4.0406\nEpoch 24/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.3868 - loss: 3.7177 - val_accuracy: 0.3761 - val_loss: 4.0056\nEpoch 25/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.3903 - loss: 3.6651 - val_accuracy: 0.3802 - val_loss: 3.9717\nEpoch 26/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 406ms/step - accuracy: 0.3952 - loss: 3.6124 - val_accuracy: 0.3823 - val_loss: 3.9424\nEpoch 27/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 406ms/step - accuracy: 0.3985 - loss: 3.5672 - val_accuracy: 0.3848 - val_loss: 3.9195\nEpoch 28/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 406ms/step - accuracy: 0.4024 - loss: 3.5146 - val_accuracy: 0.3869 - val_loss: 3.8900\nEpoch 29/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 406ms/step - accuracy: 0.4071 - loss: 3.4652 - val_accuracy: 0.3881 - val_loss: 3.8710\nEpoch 30/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 405ms/step - accuracy: 0.4114 - loss: 3.4171 - val_accuracy: 0.3908 - val_loss: 3.8500\nEpoch 31/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.4138 - loss: 3.3775 - val_accuracy: 0.3922 - val_loss: 3.8315\nEpoch 32/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.4178 - loss: 3.3353 - val_accuracy: 0.3937 - val_loss: 3.8138\nEpoch 33/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 403ms/step - accuracy: 0.4214 - loss: 3.2966 - val_accuracy: 0.3955 - val_loss: 3.7981\nEpoch 34/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 404ms/step - accuracy: 0.4258 - loss: 3.2483 - val_accuracy: 0.3968 - val_loss: 3.7772\nEpoch 35/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 404ms/step - accuracy: 0.4291 - loss: 3.2104 - val_accuracy: 0.3972 - val_loss: 3.7688\nEpoch 36/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.4331 - loss: 3.1720 - val_accuracy: 0.3993 - val_loss: 3.7491\nEpoch 37/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.4367 - loss: 3.1322 - val_accuracy: 0.3988 - val_loss: 3.7436\nEpoch 38/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 400ms/step - accuracy: 0.4394 - loss: 3.0987 - val_accuracy: 0.4015 - val_loss: 3.7265\nEpoch 39/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.4440 - loss: 3.0534 - val_accuracy: 0.4038 - val_loss: 3.7145\nEpoch 40/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 399ms/step - accuracy: 0.4460 - loss: 3.0314 - val_accuracy: 0.4019 - val_loss: 3.7077\nEpoch 41/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 397ms/step - accuracy: 0.4497 - loss: 2.9901 - val_accuracy: 0.4050 - val_loss: 3.6942\nEpoch 42/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 398ms/step - accuracy: 0.4535 - loss: 2.9542 - val_accuracy: 0.4062 - val_loss: 3.6845\nEpoch 43/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 398ms/step - accuracy: 0.4570 - loss: 2.9224 - val_accuracy: 0.4056 - val_loss: 3.6804\nEpoch 44/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 398ms/step - accuracy: 0.4601 - loss: 2.8918 - val_accuracy: 0.4071 - val_loss: 3.6689\nEpoch 45/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 403ms/step - accuracy: 0.4641 - loss: 2.8572 - val_accuracy: 0.4055 - val_loss: 3.6719\nEpoch 46/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.4670 - loss: 2.8250 - val_accuracy: 0.4070 - val_loss: 3.6637\nEpoch 47/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.4694 - loss: 2.7980 - val_accuracy: 0.4081 - val_loss: 3.6596\nEpoch 48/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 400ms/step - accuracy: 0.4732 - loss: 2.7659 - val_accuracy: 0.4075 - val_loss: 3.6554\nEpoch 49/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 400ms/step - accuracy: 0.4773 - loss: 2.7301 - val_accuracy: 0.4076 - val_loss: 3.6505\nEpoch 50/50\n\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 401ms/step - accuracy: 0.4803 - loss: 2.7076 - val_accuracy: 0.4106 - val_loss: 3.6445\n","output_type":"stream"}]},{"cell_type":"code","source":"src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\ntar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\ntar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n\nprint('=3')\n\n# 인코더 설계\nencoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output3, state_h3, state_c3])\n\n# 이전 시점의 상태들을 저장하는 텐서\ndecoder_state_input_h = Input(shape=(hidden_size,))\ndecoder_state_input_c = Input(shape=(hidden_size,))\n\ndec_emb2 = dec_emb_layer(decoder_inputs)\n\n# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\n# 어텐션 함수\ndecoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\nattn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\ndecoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\n# 디코더의 출력층\ndecoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n\n# 최종 디코더 모델\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])\n\nprint('=3')\n\n\ndef decode_sequence(input_seq):\n    # 입력으로부터 인코더의 상태를 얻음\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n\n     # <SOS>에 해당하는 토큰 생성\n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = tar_word_to_index['sostoken']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = tar_index_to_word[sampled_token_index]\n\n        if (sampled_token!='eostoken'):\n            decoded_sentence += ' '+sampled_token\n\n        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headline_max_len-1)):\n            stop_condition = True\n\n        # 길이가 1인 타겟 시퀀스를 업데이트\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # 상태를 업데이트 합니다.\n        e_h, e_c = h, c\n\n    return decoded_sentence\nprint('=3')\n\n# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\ndef seq2text(input_seq):\n    temp=''\n    for i in input_seq:\n        if (i!=0):\n            temp = temp + src_index_to_word[i]+' '\n    return temp\n\n# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n# def seq2summary(input_seq):\n#     # [[YOUR CODE]]\n#     temp=''\n#     for i in input_seq:\n#         if (i!=0):\n#             temp = temp + src_index_to_word[i]+' '\n#     return temp\n# print('=3')\n\ndef seq2summary(input_seq):\n    result = []\n    for i in input_seq:\n        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n            result.append(tar_index_to_word[i])\n    return ' '.join(result)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T03:20:12.450012Z","iopub.execute_input":"2024-08-14T03:20:12.450381Z","iopub.status.idle":"2024-08-14T03:20:12.463899Z","shell.execute_reply.started":"2024-08-14T03:20:12.450351Z","shell.execute_reply":"2024-08-14T03:20:12.462974Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"모델 테스트","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"for i in range(0, 10):\n    print(\"원문 :\", seq2text(encoder_input_test[i]))\n    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T03:22:47.082573Z","iopub.execute_input":"2024-08-14T03:22:47.082981Z","iopub.status.idle":"2024-08-14T03:22:55.323613Z","shell.execute_reply.started":"2024-08-14T03:22:47.082949Z","shell.execute_reply":"2024-08-14T03:22:55.322407Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"원문 : writing poem daughter shweta bachchan nanda launched new fashion brand partnership friend monisha jaising amitabh bachchan wrote proud daughters found success like necklace jewels precious keep safe wrote shweta new fashion brand called \n실제 요약 : proud when daughters find success themselves big in poem\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n예측 요약 :  jay daughter dances to make song daughter\n\n\n원문 : dozens teen pregnancy prevention programs deemed ineffective us president donald trump administration lose million funding following surprise decision end five year grants three years us government officials said four programs studied showed lasting positive impacts critics urged government turn back clock progress \n실제 요약 : trump administration cuts short anti teen pregnancy grants\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n예측 요약 :  trump sues trump over blue wedding\n\n\n원문 : congress mp shashi tharoor filed criminal defamation case arnab goswami republic tv court trivandrum told chief judicial magistrate goswami deliberately image used language unfairly link wife sunanda pushkar death tharoor earlier filed civil defamation case goswami republic tv \n실제 요약 : tharoor files defamation case against republic tv\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n예측 요약 :  tharoor shares defamation case against him by him\n\n\n원문 : singer ed sheeran responding accusations performing live concert tweeted never thought would explain everything live show live loop station backing track sheeran accused using backing tracks seen playing guitar sound heard concert \n실제 요약 : sheeran reacts to accusations of not singing live in concert\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n예측 요약 :  my day is my my time sheeran on pregnancy\n\n\n원문 : mithali raj aged years days smashed odi debut becoming youngest player score hundred across formats men women international cricket raj turns today also youngest double centurion women test cricket achieving feat aged years days \n실제 요약 : mithali raj is the youngest centurion in international cricket\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n예측 요약 :  year old indian cricketer to hit ipl in ipl\n\n\n원문 : china banned us film television production company hbo website following uk comedian john oliver chinese president xi jinping show earlier chinese social media platform weibo blocked mentions oliver oliver compared chinese president cartoon character winnie \n실제 요약 : china bans hbo after uk comedian criticises president xi\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n예측 요약 :  china releases game of thrones to sign obama\n\n\n원문 : woman said actor rishi kapoor sent abusive message twitter wrote ch posted meme involving actor earlier month sharing screenshot abusive message wrote rishi kapoor keep talking manners manners man \n실제 요약 : rishi wrote ck you to me over my meme says woman\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n예측 요약 :  woman trolled for saying woman rishi kapoor\n\n\n원문 : kings xi punjab mentor cum director cricket virender sehwag revealed team bought chris gayle back opener simply side means lot opening batsman gayle prove danger opposition added notably gayle bought kxip crore went unsold twice \n실제 요약 : bought chris gayle as back up for kings xi punjab sehwag\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n예측 요약 :  sehwag has not sell ipl xi of ipl zinta\n\n\n원문 : mumbai doctors occasion world suicide prevention day sunday launched emotional support helpline directory free mobile app prevent suicides app displays suicide prevention helpline numbers directs users nearest help centres bombay psychiatric society president called great step adding significant intervention prevent suicide \n실제 요약 : mumbai doctors launch free app to prevent suicides\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n예측 요약 :  mumbai mumbai body to get mobile mobile app\n\n\n원문 : hyderabad based customer ordered dal online retailer big basket found dead rat inside dal packet packaged website brand name took photos videos packet shared twitter following incident company apologised customer adding necessary action taken \n실제 요약 : customer finds dead rat in big dal\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n예측 요약 :  hyd hospital gets death after death for dead\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_dataset:\n    print(i)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:43:04.028042Z","iopub.execute_input":"2024-08-14T05:43:04.028467Z","iopub.status.idle":"2024-08-14T05:43:04.337002Z","shell.execute_reply.started":"2024-08-14T05:43:04.028438Z","shell.execute_reply":"2024-08-14T05:43:04.335884Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"({'encoder_inputs': <tf.Tensor: shape=(256, 43), dtype=int32, numpy=\narray([[  11, 1059, 1351, ...,    0,    0,    0],\n       [  37, 2700,   53, ...,    0,    0,    0],\n       [ 433, 3986, 6811, ...,    0,    0,    0],\n       ...,\n       [ 583,  349,   16, ...,    0,    0,    0],\n       [ 209,  495,  126, ...,    0,    0,    0],\n       [   5,   33,  101, ...,    0,    0,    0]], dtype=int32)>, 'decoder_inputs': <tf.Tensor: shape=(256, 12), dtype=int32, numpy=\narray([[   1,  559, 1223, ...,    0,    0,    0],\n       [   1,   20,  380, ..., 4320,  311, 1019],\n       [   1,  402,   53, ...,  282,  153,    0],\n       ...,\n       [   1,  574,  522, ...,    0,    0,    0],\n       [   1,    8,    3, ...,    0,    0,    0],\n       [   1,   75,  267, ...,    0,    0,    0]], dtype=int32)>}, <tf.Tensor: shape=(256, 12), dtype=int32, numpy=\narray([[ 559, 1223, 5927, ...,    0,    0,    0],\n       [  20,  380,   41, ...,  311, 1019,    2],\n       [ 402,   53,    7, ...,  153,    2,    0],\n       ...,\n       [ 574,  522,    5, ...,    0,    0,    0],\n       [   8,    3,  960, ...,    0,    0,    0],\n       [  75,  267, 2945, ...,    0,    0,    0]], dtype=int32)>)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, AdditiveAttention\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\n# GPU 확인\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\n# 분산 전략 설정\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n\n# 패딩\nencoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\nencoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\ndecoder_input_train = pad_sequences(decoder_input_train, maxlen=headline_max_len, padding='post')\ndecoder_target_train = pad_sequences(decoder_target_train, maxlen=headline_max_len, padding='post')\ndecoder_input_test = pad_sequences(decoder_input_test, maxlen=headline_max_len, padding='post')\ndecoder_target_test = pad_sequences(decoder_target_test, maxlen=headline_max_len, padding='post')\n\n# 모델 파라미터\nembedding_dim = 256\nhidden_size = 512\ndropout_rate = 0.2\n\n# 배치 크기 설정 (GPU 메모리에 맞게 조정)\nBATCH_SIZE_PER_REPLICA = 64\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\nwith strategy.scope():\n    # 인코더\n    encoder_inputs = Input(shape=(text_max_len,))\n    enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n    encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout_rate)\n    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n    encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout_rate)\n    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n    encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout_rate)\n    encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n\n    # 디코더\n    decoder_inputs = Input(shape=(headline_max_len,))\n    dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n    dec_emb = dec_emb_layer(decoder_inputs)\n\n    # LSTM 레이어\n    decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout_rate)\n    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n\n    # 어텐션 레이어\n    attn_layer = AdditiveAttention()\n    attn_out = attn_layer([decoder_outputs, encoder_outputs])\n    decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attn_out])\n\n    # 출력 레이어\n    decoder_dense = TimeDistributed(Dense(tar_vocab, activation='softmax'))\n    decoder_outputs = decoder_dense(decoder_concat_input)\n\n    # 모델 정의\n    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n    # 모델 컴파일\n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# 콜백 정의\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001, verbose=1)\nmc = ModelCheckpoint('best_model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n\n# 데이터셋 준비\ntrain_dataset = tf.data.Dataset.from_tensor_slices(((encoder_input_train, decoder_input_train), decoder_target_train))\ntrain_dataset = train_dataset.batch(GLOBAL_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices(((encoder_input_test, decoder_input_test), decoder_target_test))\nval_dataset = val_dataset.batch(GLOBAL_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n\n# 모델 학습\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=50,\n    callbacks=[es, mc, reduce_lr]\n)\n\n# 모델 저장\nmodel.save('text_summarization_model.keras')\n\nprint(\"모델 학습 및 저장 완료!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:56:04.907399Z","iopub.execute_input":"2024-08-14T05:56:04.907790Z","iopub.status.idle":"2024-08-14T06:07:43.244030Z","shell.execute_reply.started":"2024-08-14T05:56:04.907760Z","shell.execute_reply":"2024-08-14T06:07:43.243011Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\nNumber of devices: 2\nEpoch 1/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2761 - loss: 5.9163\nEpoch 1: val_loss improved from inf to 5.13419, saving model to best_model.keras\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 115ms/step - accuracy: 0.2762 - loss: 5.9158 - val_accuracy: 0.3162 - val_loss: 5.1342 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3139 - loss: 5.0880\nEpoch 2: val_loss improved from 5.13419 to 4.71310, saving model to best_model.keras\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 113ms/step - accuracy: 0.3139 - loss: 5.0878 - val_accuracy: 0.3382 - val_loss: 4.7131 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3386 - loss: 4.5349\nEpoch 3: val_loss improved from 4.71310 to 4.41645, saving model to best_model.keras\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 113ms/step - accuracy: 0.3386 - loss: 4.5346 - val_accuracy: 0.3578 - val_loss: 4.4164 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.3640 - loss: 4.0453\nEpoch 4: val_loss improved from 4.41645 to 4.26488, saving model to best_model.keras\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 113ms/step - accuracy: 0.3640 - loss: 4.0449 - val_accuracy: 0.3710 - val_loss: 4.2649 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.3907 - loss: 3.6055\nEpoch 5: val_loss improved from 4.26488 to 4.21729, saving model to best_model.keras\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 113ms/step - accuracy: 0.3907 - loss: 3.6052 - val_accuracy: 0.3774 - val_loss: 4.2173 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.4216 - loss: 3.2072\nEpoch 6: val_loss did not improve from 4.21729\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 110ms/step - accuracy: 0.4216 - loss: 3.2069 - val_accuracy: 0.3786 - val_loss: 4.2278 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.4598 - loss: 2.8508\nEpoch 7: val_loss did not improve from 4.21729\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 110ms/step - accuracy: 0.4599 - loss: 2.8505 - val_accuracy: 0.3806 - val_loss: 4.2492 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5004 - loss: 2.5383\nEpoch 8: val_loss did not improve from 4.21729\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 110ms/step - accuracy: 0.5005 - loss: 2.5380 - val_accuracy: 0.3777 - val_loss: 4.2960 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5342 - loss: 2.3104\nEpoch 9: val_loss did not improve from 4.21729\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 110ms/step - accuracy: 0.5342 - loss: 2.3100 - val_accuracy: 0.3878 - val_loss: 4.2302 - learning_rate: 2.0000e-04\nEpoch 10/50\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5583 - loss: 2.1752\nEpoch 10: val_loss did not improve from 4.21729\n\u001b[1m608/608\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 111ms/step - accuracy: 0.5584 - loss: 2.1747 - val_accuracy: 0.3893 - val_loss: 4.2281 - learning_rate: 2.0000e-04\nEpoch 10: early stopping\n모델 학습 및 저장 완료!\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:22:33.981464Z","iopub.execute_input":"2024-08-14T06:22:33.981823Z","iopub.status.idle":"2024-08-14T06:22:34.015855Z","shell.execute_reply.started":"2024-08-14T06:22:33.981795Z","shell.execute_reply":"2024-08-14T06:22:34.015002Z"},"trusted":true},"execution_count":123,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_19\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_39        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,840,000\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_79 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,574,912\u001b[0m │ embedding_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_80 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_40        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,560,000\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_81 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_82 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,574,912\u001b[0m │ embedding_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ lstm_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ lstm_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ additive_attention… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ lstm_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_15 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │ \u001b[38;5;34m10,250,000\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_39        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_40        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ lstm_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ lstm_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ additive_attention… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ lstm_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_15 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250,000</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,996,210\u001b[0m (274.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,996,210</span> (274.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,998,736\u001b[0m (91.55 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,998,736</span> (91.55 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m47,997,474\u001b[0m (183.10 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,997,474</span> (183.10 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# 저장된 모델 불러오기\nmodel = load_model('/kaggle/working/model/best_model.keras')\n\nmodel.summary()\n\nhidden_size = 512  # 모델 학습 시 사용한 값으로 설정\ntext_max_len = 43  # 모델 학습 시 사용한 값으로 설정\n\n# 모델 구조에서 필요한 레이어 추출\nencoder_inputs = model.input[0]\ndecoder_inputs = model.input[1]\nencoder_outputs, state_h, state_c = model.get_layer('lstm_50').output\ndecoder_lstm = model.get_layer('lstm_51')\nattn_layer = model.get_layer('attention_layer')\ndecoder_dense = model.get_layer('time_distributed_9')\n\n# 인코더 모델\nencoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n\n# 디코더 모델을 위한 입력\ndecoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\ndecoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\ndecoder_hidden_state_input = tf.keras.Input(shape=(text_max_len, hidden_size))\n\n# 디코더 임베딩 레이어\ndec_emb_layer = model.get_layer('embedding_25')\ndec_emb2 = dec_emb_layer(decoder_inputs)\n\n# 디코더 LSTM\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\n# 어텐션 메커니즘\nattn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\ndecoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\n# 디코더 출력층\ndecoder_outputs2 = decoder_dense(decoder_inf_concat)\n\n# 디코더 모델 정의\ndecoder_model = tf.keras.Model(\n    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])\n\n\n\ndef decode_sequence(input_seq):\n    e_out, e_h, e_c = encoder_model.predict(input_seq, verbose=0)\n    \n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = tar_word_to_index['sostoken']\n    \n    stop_condition = False\n    decoded_sentence = ''\n    \n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq, e_out, e_h, e_c], verbose=0)\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = tar_index_to_word[sampled_token_index]\n        \n        if (sampled_token != 'eostoken'):\n            decoded_sentence += ' ' + sampled_token\n        \n        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (headline_max_len-1)):\n            stop_condition = True\n        \n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        \n        e_h, e_c = h, c\n    \n    return decoded_sentence\n\n\n\n# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\ndef seq2text(input_seq):\n    temp = ''\n    for i in input_seq:\n        if (i != 0):\n            temp = temp + src_index_to_word[i] + ' '\n    return temp\n\n# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\ndef seq2summary(input_seq):\n    result = []\n    for i in input_seq:\n        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n            result.append(tar_index_to_word[i])\n    return ' '.join(result)\n\nprint('추론 모델 생성 완료')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:55:44.666033Z","iopub.execute_input":"2024-08-14T06:55:44.666405Z","iopub.status.idle":"2024-08-14T06:55:45.130463Z","shell.execute_reply.started":"2024-08-14T06:55:44.666365Z","shell.execute_reply":"2024-08-14T06:55:45.129515Z"},"trusted":true},"execution_count":147,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,280,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_48 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m394,240\u001b[0m │ embedding_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_49 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m525,312\u001b[0m │ lstm_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,280,000\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_50 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m525,312\u001b[0m │ lstm_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_51 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ lstm_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lstm_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_9  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m5,130,000\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m10000\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ time_distributed_9  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,058,722\u001b[0m (72.70 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,058,722</span> (72.70 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,529,360\u001b[0m (36.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,529,360</span> (36.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,529,362\u001b[0m (36.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,529,362</span> (36.35 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"추론 모델 생성 완료\n","output_type":"stream"}]},{"cell_type":"code","source":"src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\ntar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\ntar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n\nprint('=3')\n\n# 인코더 설계\nencoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output, state_h, state_c])\n\n# 이전 시점의 상태들을 저장하는 텐서\ndecoder_state_input_h = Input(shape=(hidden_size,))\ndecoder_state_input_c = Input(shape=(hidden_size,))\n\ndec_emb2 = dec_emb_layer(decoder_inputs)\n\n# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\ndecoder_outputs, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\n# 어텐션 함수\ndecoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\nattn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\ndecoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\n# 디코더의 출력층\ndecoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n\n\n# 최종 디코더 모델\ndecoder_model = Model(\n    [decoder_inputss] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])\n\nprint('=3')\n\n\ndef decode_sequence(input_seq):\n    # 입력으로부터 인코더의 상태를 얻음\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n\n     # <SOS>에 해당하는 토큰 생성\n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = tar_word_to_index['sostoken']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = tar_index_to_word[sampled_token_index]\n\n        if (sampled_token!='eostoken'):\n            decoded_sentence += ' '+sampled_token\n\n        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headline_max_len-1)):\n            stop_condition = True\n\n        # 길이가 1인 타겟 시퀀스를 업데이트\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # 상태를 업데이트 합니다.\n        e_h, e_c = h, c\n\n    return decoded_sentence\nprint('=3')\n\n# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\ndef seq2text(input_seq):\n    temp=''\n    for i in input_seq:\n        if (i!=0):\n            temp = temp + src_index_to_word[i]+' '\n    return temp\n\n# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n# def seq2summary(input_seq):\n#     # [[YOUR CODE]]\n#     temp=''\n#     for i in input_seq:\n#         if (i!=0):\n#             temp = temp + src_index_to_word[i]+' '\n#     return temp\n# print('=3')\n\ndef seq2summary(input_seq):\n    result = []\n    for i in input_seq:\n        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n            result.append(tar_index_to_word[i])\n    return ' '.join(result)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:46:38.928045Z","iopub.execute_input":"2024-08-14T06:46:38.928662Z","iopub.status.idle":"2024-08-14T06:46:38.991192Z","shell.execute_reply.started":"2024-08-14T06:46:38.928631Z","shell.execute_reply":"2024-08-14T06:46:38.989903Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"=3\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[133], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 인코더 설계\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m encoder_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mencoder_inputs, outputs\u001b[38;5;241m=\u001b[39m[\u001b[43mencoder_output\u001b[49m, state_h, state_c])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 이전 시점의 상태들을 저장하는 텐서\u001b[39;00m\n\u001b[1;32m     11\u001b[0m decoder_state_input_h \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(hidden_size,))\n","\u001b[0;31mNameError\u001b[0m: name 'encoder_output' is not defined"],"ename":"NameError","evalue":"name 'encoder_output' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# 모델 파라미터\nhidden_size = 256\ntext_max_len = 100\nembedding_dim = 128\n\n# 인코더 모델\nencoder_inputs = model.input[0]\nencoder_outputs, state_h, state_c = model.get_layer('lstm_50').output\nencoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n\n# 디코더 모델을 위한 입력\ndecoder_inputs = Input(shape=(None,), name='decoder_inputs')\ndecoder_state_input_h = Input(shape=(hidden_size,), name='decoder_state_input_h')\ndecoder_state_input_c = Input(shape=(hidden_size,), name='decoder_state_input_c')\ndecoder_hidden_state_input = Input(shape=(text_max_len, hidden_size), name='decoder_hidden_state_input')\n\n# 디코더 레이어\ndec_emb_layer = model.get_layer('embedding_25')\ndec_emb = dec_emb_layer(decoder_inputs)\n\ndecoder_lstm = model.get_layer('lstm_51')\ndecoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\nattn_layer = model.get_layer('attention_layer')\nattn_out = attn_layer([decoder_outputs, decoder_hidden_state_input])\n\nconcat_layer = model.get_layer('concat_layer')\ndecoder_concat_input = concat_layer([decoder_outputs, attn_out])\n\ndecoder_dense = model.get_layer('time_distributed_9')\ndecoder_outputs = decoder_dense(decoder_concat_input)\n\n# 디코더 모델 정의\ndecoder_model = Model(\n    [decoder_inputs, decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs, state_h, state_c])\n\n# decode_sequence 함수 수정\ndef decode_sequence(input_seq):\n    e_out, e_h, e_c = encoder_model.predict(input_seq, verbose=0)\n    \n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = tar_word_to_index['sostoken']\n    \n    stop_condition = False\n    decoded_sentence = ''\n    \n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq, e_out, e_h, e_c], verbose=0)\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = tar_index_to_word[sampled_token_index]\n        \n        if (sampled_token != 'eostoken'):\n            decoded_sentence += ' ' + sampled_token\n        \n        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (headline_max_len-1)):\n            stop_condition = True\n        \n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        \n        e_h, e_c = h, c\n    \n    return decoded_sentence\n\n# 예측 실행\n# 예측 실행\npadded_input = pad_input(encoder_input_test[i], text_max_len)\nprint(\"예측 요약 :\", decode_sequence(padded_input.reshape(1, text_max_len)))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:00:20.657595Z","iopub.execute_input":"2024-08-14T07:00:20.658432Z","iopub.status.idle":"2024-08-14T07:00:22.160425Z","shell.execute_reply.started":"2024-08-14T07:00:20.658400Z","shell.execute_reply":"2024-08-14T07:00:22.159333Z"},"trusted":true},"execution_count":153,"outputs":[{"name":"stdout","text":"예측 요약 :  outfits outfits washes outfits washes outfits washes washes outfits washes outfits\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_input_test[1]","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:00:51.901704Z","iopub.execute_input":"2024-08-14T07:00:51.902352Z","iopub.status.idle":"2024-08-14T07:00:51.908805Z","shell.execute_reply.started":"2024-08-14T07:00:51.902322Z","shell.execute_reply":"2024-08-14T07:00:51.907792Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"array([  141,   351, 14743,   141,  2909,  2216, 14743,  1267,    11,\n        9514,   170, 14743,    65,  3140,   141,  5624,   141,  6334,\n          12,    12,   452,  3039,  6334,     6,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# text_max_len을 100으로 설정\ntext_max_len = 100\n\n# 입력 데이터 패딩\ndef pad_input(input_seq, maxlen):\n    return pad_sequences([input_seq], maxlen=maxlen, padding='post')[0]\n\n# decode_sequence \ndef decode_sequence(input_seq):\n    e_out, e_h, e_c = encoder_model.predict(input_seq, verbose=0)\n    \n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = tar_word_to_index['sostoken']\n    \n    stop_condition = False\n    decoded_sentence = ''\n    \n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq, e_out, e_h, e_c], verbose=0)\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = tar_index_to_word[sampled_token_index]\n        \n        if (sampled_token != 'eostoken'):\n            decoded_sentence += ' ' + sampled_token\n        \n        if (sampled_token == 'eostoken' or len(decoded_sentence.split()) >= (headline_max_len-1)):\n            stop_condition = True\n        \n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        \n        e_h, e_c = h, c\n    \n    return decoded_sentence\n\n# 예측 실행\npadded_input = pad_input(encoder_input_test[i], text_max_len)\nprint(\"예측 요약 :\", decode_sequence(padded_input.reshape(1, text_max_len)))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:57:51.058732Z","iopub.execute_input":"2024-08-14T06:57:51.059421Z","iopub.status.idle":"2024-08-14T06:57:52.671476Z","shell.execute_reply.started":"2024-08-14T06:57:51.059392Z","shell.execute_reply":"2024-08-14T06:57:52.670396Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"예측 요약 :  displayed court court court court outfits court outfits outfits sood takeoff\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(0, 10):\n    print(\"원문 :\", seq2text(encoder_input_test[i]))\n    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n    padded_input = pad_input(encoder_input_test[i], text_max_len)\n    print(\"예측 요약 :\", decode_sequence(padded_input.reshape(1, text_max_len)))\n#     print(\"예측 요약 :\", decode_sequence(padded_input[i].reshape(1, text_max_len)))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:58:52.443215Z","iopub.execute_input":"2024-08-14T06:58:52.443567Z","iopub.status.idle":"2024-08-14T06:59:01.807932Z","shell.execute_reply.started":"2024-08-14T06:58:52.443542Z","shell.execute_reply":"2024-08-14T06:59:01.806858Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"원문 : kaur chhattisgarh private channel read breaking news husband death road accident saturday got sense husband vehicle read bulletin came studio started calling relatives senior editor said incident \n실제 요약 : tv anchor reads out news of her husband death in accident\n예측 요약 :  court outfits outfits outfits washes sworn outfits outfits sworn sworn outfits\n\n\n원문 : number known hardy number cambridge professor hardy visited indian mathematician hospital hardy called taxi number smallest number sum two two different ways sum also \n실제 요약 : why is known as number\n예측 요약 :  outfits outfits court court outfits court outfits washes outfits outfits washes\n\n\n원문 : two durga puja kolkata selected demonetisation theme year mitra pandal announced plans depict suffering caused people due demonetisation feature tree banned currency leaves another pandal north district feature money atm machine \n실제 요약 : kolkata durga puja to be themed around note ban\n예측 요약 :  outfits washes outfits sworn outfits washes outfits sworn outfits washes takeoff\n\n\n원문 : us federal trade commission investigating startup named raised across two crowdfunding campaigns yet ship product product wifi enabled battery packed power gadgets provide local friends however reported receiving accessories like batteries cables \n실제 요약 : startup after raising cr faces probe\n예측 요약 :  outfits outfits court court outfits outfits washes outfits washes outfits washes\n\n\n원문 : shiv sena leader manisha saturday said pm narendra modi declare emergency instead ten central agencies intercept information stored computer added move absolutely fundamental rights citizens authorised agencies include cbi delhi police commissioner raw national investigation agency among others \n실제 요약 : pm should declare emergency shiv sena on surveillance order\n예측 요약 :  outfits court outfits outfits washes outfits outfits washes outfits washes outfits\n\n\n원문 : lakh fine mumbai raja mandal damaging roads ganesh chaturthi reportedly waived mandal said repaired road damaged setting pandal brihanmumbai municipal corporation instructed pay every pothole created fix \n실제 요약 : lakh fine on mumbai raja waived\n예측 요약 :  court court outfits outfits sworn outfits outfits outfits washes outfits washes\n\n\n원문 : death toll nipah virus reached kerala health minister kk shailaja teacher friday warned second possible outbreak virus came contact infected would particularly vulnerable people closely watched said asked people contact special cell \n실제 요약 : kerala health minister warns of another nipah virus outbreak\n예측 요약 :  outfits sworn outfits outfits outfits takeoff outfits outfits takeoff outfits outfits\n\n\n원문 : billionaire elon musk trolled amazon digital assistant alexa users said made laughing noises response commands musk also liked tweet referred random laughing noises alexa witch like amazon confirmed issue said deployed software update smart speaker fix problem \n실제 요약 : musk trolls amazon alexa over reports of random laugh noises\n예측 요약 :  court outfits takeoff outfits outfits outfits outfits washes sworn outfits sworn\n\n\n원문 : actress turned producer pooja bhatt said pr machinery handles social media accounts point twitter account pr person putting tweets every every mark claim added pooja said prefers instagram platforms \n실제 요약 : do not have pr handle my accounts myself pooja\n예측 요약 :  outfits displayed court outfits court outfits takeoff takeoff takeoff outfits takeoff\n\n\n원문 : contest held facebook live participants kiss car longest time attempt win contest started participants monday people stopped kissing car eliminated case one contestant left end hours lucky draw decide winner \n실제 요약 : people compete to kiss car for longest time to win it\n예측 요약 :  outfits court court court outfits outfits outfits sworn takeoff outfits outfits\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(encoder_model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-08-14T06:21:56.782516Z","iopub.execute_input":"2024-08-14T06:21:56.783178Z","iopub.status.idle":"2024-08-14T06:21:56.809157Z","shell.execute_reply.started":"2024-08-14T06:21:56.783146Z","shell.execute_reply":"2024-08-14T06:21:56.808253Z"},"trusted":true},"execution_count":121,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_23\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_31        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_63 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_64 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_65 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ lstm_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_31        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,364,864\u001b[0m (12.84 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,364,864</span> (12.84 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,364,864\u001b[0m (12.84 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,364,864</span> (12.84 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(0, 10):\n    print(\"원문 :\", seq2text(encoder_input_test[i]))\n    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:01:16.860431Z","iopub.execute_input":"2024-08-14T07:01:16.860881Z","iopub.status.idle":"2024-08-14T07:01:16.907352Z","shell.execute_reply.started":"2024-08-14T07:01:16.860845Z","shell.execute_reply":"2024-08-14T07:01:16.905673Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"원문 : kaur chhattisgarh private channel read breaking news husband death road accident saturday got sense husband vehicle read bulletin came studio started calling relatives senior editor said incident \n실제 요약 : tv anchor reads out news of her husband death in accident\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[156], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m원문 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, seq2text(encoder_input_test[i]))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m실제 요약 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, seq2summary(decoder_input_test[i]))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m예측 요약 :\u001b[39m\u001b[38;5;124m\"\u001b[39m, decode_sequence(\u001b[43mencoder_input_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_max_len\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 43 into shape (1,100)"],"ename":"ValueError","evalue":"cannot reshape array of size 43 into shape (1,100)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFT5ForConditionalGeneration, T5Tokenizer\n\nmodel = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\")\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:08:19.242160Z","iopub.execute_input":"2024-08-14T07:08:19.242674Z","iopub.status.idle":"2024-08-14T07:08:29.194467Z","shell.execute_reply.started":"2024-08-14T07:08:19.242643Z","shell.execute_reply":"2024-08-14T07:08:29.193469Z"},"trusted":true},"execution_count":157,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccede9008184eed83fd61664ac31261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e252e1780a4d078eac2a3e5752df8f"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081512267cb74bdda6f2598c3860e55a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ebf2a98da14ef78a15d172c46230cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dbc3c4648154f74aa7ac44892ca247e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def t5model(article):\n    input_text = \"summarize: \" +  article\n    input_ids = tokenizer.encode(input_text, return_tensors=\"tf\", max_length=512, truncation=True)\n\n    summary_ids = model.generate(input_ids, max_length=12, min_length=4, length_penalty=2.0, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:12:40.898480Z","iopub.execute_input":"2024-08-14T07:12:40.898825Z","iopub.status.idle":"2024-08-14T07:12:40.904974Z","shell.execute_reply.started":"2024-08-14T07:12:40.898801Z","shell.execute_reply":"2024-08-14T07:12:40.903940Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"t5model(seq2text(encoder_input_test[0]))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:14:42.660750Z","iopub.execute_input":"2024-08-14T07:14:42.661417Z","iopub.status.idle":"2024-08-14T07:14:44.718237Z","shell.execute_reply.started":"2024-08-14T07:14:42.661385Z","shell.execute_reply":"2024-08-14T07:14:44.717240Z"},"trusted":true},"execution_count":168,"outputs":[{"execution_count":168,"output_type":"execute_result","data":{"text/plain":"'kaur chhattisgarh private channel'"},"metadata":{}}]},{"cell_type":"code","source":"summary","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:10:37.275158Z","iopub.execute_input":"2024-08-14T07:10:37.275555Z","iopub.status.idle":"2024-08-14T07:10:37.281620Z","shell.execute_reply.started":"2024-08-14T07:10:37.275527Z","shell.execute_reply":"2024-08-14T07:10:37.280643Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"'number known hardy number cambridge professor hardy visited'"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(100, 150):\n    print(\"원문 :\", seq2text(encoder_input_test[i]))\n    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n    print(\"예측 요약 :\", t5model(seq2text(encoder_input_test[i])))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:32:56.054200Z","iopub.execute_input":"2024-08-14T07:32:56.054977Z","iopub.status.idle":"2024-08-14T07:34:38.028648Z","shell.execute_reply.started":"2024-08-14T07:32:56.054946Z","shell.execute_reply":"2024-08-14T07:34:38.027417Z"},"trusted":true},"execution_count":171,"outputs":[{"name":"stdout","text":"원문 : congress president rahul gandhi accused pm narendra modi insulting guru lk advani bjp spokesperson anil said congress president practising lowest form politics stating country saw congress treated former president pranab mukherjee added country watching president oldest political party behaving \n실제 요약 : lowest form of politics bjp as rahul says pm insults advani\n예측 요약 : congress president rahul gandh\n\n\n원문 : ankita raina kaur india top two women tennis players first doubles title together lifted open trophy sunday also first title singles doubles indian players indian pair opponents forced retire final \n실제 요약 : ankita win their maiden title in\n예측 요약 : ankita raina kaur india top two women\n\n\n원문 : netflix facing criticism taking episode comedian hasan show act saudi arabia due criticism country rulers us based ngo human rights watch accused streaming website undermining artistic freedom content netflix pulled episode following complaint country communications information technology commission \n실제 요약 : netflix criticised for pulling comedy show episode in saudi\n예측 요약 : netflix facing criticism taking episode comedian hasan show\n\n\n원문 : vijayawada mumbai air india express flight runway mumbai airport today airline spokesperson said aircraft touched correctly used maximum braking due conditions caused heavy rain aircraft could stop damage aircraft passengers reported safe \n실제 요약 : aircraft runway amid heavy rains in mumbai\n예측 요약 : vijayawada mumbai air india express\n\n\n원문 : khan assaulted around people alwar highway suspicion cow smuggling rajasthan died hospital monday said police khan among people transporting cows six vehicles registered case murder six persons unknown people said sho alwar \n실제 요약 : man attacked by cow vigilantes in rajasthan dies\n예측 요약 : khan assaulted around people alwar highway\n\n\n원문 : three men found guilty murder friday causing explosion shop february leicester uk killed five people including three members indian origin family convicts caused explosion destroy shop order claim insurance indian origin family moved uk mauritius \n실제 요약 : men convicted of murder of indian origin family in uk\n예측 요약 : three men found guilty of murder friday causing explosion\n\n\n원문 : national green tribunal friday directed delhi development authority submit action plan restoration yamuna comes expert committee appointed ngt claimed acres adversely affected world culture festival organised art living \n실제 요약 : to submit action plan for yamuna\n예측 요약 : delhi development authority submit action plan restoration\n\n\n원문 : radio address mann ki baat prime minister narendra modi said edition commonwealth games special majority indian females squash boxing weightlifting shooting female players pm modi added pointed lot achieved indian athletes gold coast \n실제 요약 : indian female athletes success made cwg special pm modi\n예측 요약 : mann ki baat prime minister nar\n\n\n원문 : pakistan cut size biggest china pakistan economic corridor project country billion citing concerns debt levels project kilometre rail line connecting karachi peshawar initially priced billion part china belt road initiative \n실제 요약 : pakistan cuts biggest cpec project by billion\n예측 요약 : pakistan cut size biggest china pakist\n\n\n원문 : total lakh students kerala would get free school uniforms made materials current academic year state government earlier decided distribute materials school uniforms revive traditional sector inauguration programme would done cm pinarayi vijayan may \n실제 요약 : lakh students to get free school uniforms in kerala\n예측 요약 : total lakh students kerala would get free school\n\n\n원문 : delhi indira gandhi international airport launch first phase expansion drive appointing design consultant expansion terminal terminal construction new runway delhi international airport limited expects expansion completed followed construction new terminal \n실제 요약 : delhi airport to get bigger and new runway by\n예측 요약 : delhi indira gandh\n\n\n원문 : fugitive businessman vijay mallya reportedly kept mumbai arthur road jail number extradition uk cell facilities like tv personal toilet washing area also provided clean blankets cell east facing gets natural light \n실제 요약 : which jail will house vijay mallya after his extradition to india\n예측 요약 : vijay mallya reportedly kept mumbai\n\n\n원문 : year old woman riding pillion nephew scooter died lorry ran neck fell two wheeler bengaluru mysore road nephew applied sudden brakes avoid pothole road lost scooter balance victim lorry \n실제 요약 : luru woman riding dies in accident due to pothole\n예측 요약 : lorry ran neck fell two wheeler ben\n\n\n원문 : senior lawyer ram jethmalani quit delhi cm arvind kejriwal counsel defamation cases filed finance minister arun jaitley asking kejriwal settle dues crore came kejriwal denied instructed jethmalani use objectionable remarks jaitley court proceedings may jethmalani said kejriwal used offensive language jaitley \n실제 요약 : quits as kejriwal seeks crore dues\n예측 요약 : ram jethmalani quit delhi\n\n\n원문 : pakistan supreme court thursday barred former president pervez musharraf contesting upcoming general elections ruling came musharraf failed appear court treason case linked disqualification high court musharraf accused treason imposing emergency country \n실제 요약 : pakistan sc bars ex prez musharraf from contesting polls\n예측 요약 : pakistan supreme court barred former president\n\n\n원문 : bihar chief minister nitish kumar tuesday undertook seven kilometre walk village mahatma gandhi hundred years ago part celebrations champaran satyagraha man dressed mahatma gandhi police custody also took part march remind people \n실제 요약 : nitish walks km to recreate gandhiji yatra in\n예측 요약 : bihar chief minister nitish kumar\n\n\n원문 : first us based researchers printed plastic objects sensors communicate wifi connected devices technology named printed wifi uses mechanical motion reflect radio signals multiple applications example sensing quantity left bottle based flow rate automatically order \n실제 요약 : new printed connect to wifi without electronics\n예측 요약 : first us based researchers printed plastic objects sensors communicate wifi\n\n\n원문 : choreographer director praising actor rajinikanth said want work added everybody loves sir everybody want see first day first show said films rajinikanth seen one film really loves film \n실제 요약 : who does not want to work with rajinikanth\n예측 요약 : choreographer director praising actor rajini\n\n\n원문 : family netaji subhas chandra bose presented cap worn leader prime minister narendra modi pm modi inaugurated subhas chandra bose museum red fort mark leader nd birth anniversary said cap displayed mandir hope youngsters get inspired netaji bose life pm tweeted \n실제 요약 : family gifts cap by bose to pm narendra modi\n예측 요약 : family netaji subhas chandra bose\n\n\n원문 : supreme court friday stayed crore penalty imposed cement companies competition commission india allegations court asked companies deposit amount competition regulator imposed highest penalty crore aditya birla group firm cement \n실제 요약 : supreme court stays cci cr penalty on cement firms\n예측 요약 : supreme court stayed crore penalty imposed cement companies\n\n\n원문 : lalit bhatia younger son bhatia family said mastermind behind suspected mass suicide burari bought mobile numbers adding day incident mobile shop owner claimed year old visited shop saturday around pm going different numbers find ones adding \n실제 요약 : burari deaths mastermind bought cell adding to\n예측 요약 : mastermind behind suspected mass suicide burari bought mobile numbers\n\n\n원문 : indian shuttler saina nehwal beat thailand reach final indonesia masters super tournament saturday year old earlier beaten compatriot pv sindhu reach semifinal face either tai tzu ying chinese china sixth final jakarta tomorrow \n실제 요약 : saina nehwal reaches indonesia masters final\n예측 요약 : indian shuttler saina n\n\n\n원문 : israeli prime minister benjamin netanyahu vowed close jerusalem office al jazeera accusing news network inciting violence amid protests country heightened security measures outside al mosque netanyahu said would enact required legislation expel al jazeera israel law enforcement agencies failed close \n실제 요약 : israel pm netanyahu vows to expel al jazeera from israel\n예측 요약 : benjamin netanyahu vows close\n\n\n원문 : reacting former pakistani skipper shahid afridi ball ton user tweeted simply hitting afridi afridi boom boom mood another tweet read hold players field tonight born afridi already playing international cricket \n실제 요약 : be afridi be very afridi tweets user on afridi ton\n예측 요약 : shahid afridi ball ton\n\n\n원문 : indian diplomats pakistan reportedly humiliated barred entering gurdwara sahib wednesday night gurdwara sauda thursday administration allow officials inside saying indian government hurt sentiments sikhs allowing screening film nanak shah punjab province pakistan \n실제 요약 : indian officials barred from entering in pakistan\n예측 요약 : indian diplomats pakistan reportedly humiliat\n\n\n원문 : astronomers discovered planet times mass earth orbiting one closest stars sun star potentially rocky planet known star orbits around host star every days planet surface temperature estimated around making impossible life exist \n실제 요약 : planet times the mass of earth found orbiting nearby star\n예측 요약 : planet times mass earth orbits one closest stars sun star\n\n\n원문 : taking jibe congress oil minister dharmendra pradhan said opposed previous present government worked hard earn stake uae oil minister earlier team done good work pradhan added ongc led consortium agreed pay million stake \n실제 요약 : worked hard to earn stake in uae oil minister\n예측 요약 : taking jibe congress oil minister dharm\n\n\n원문 : prime minister narendra modi called imran khan congratulate party tehreek insaf emerging largest political party national assembly pakistan recent elections pm modi expressed hope democracy take deeper roots pakistan vision peace development entire neighbourhood \n실제 요약 : pm modi calls to congratulate pakistan imran khan\n예측 요약 : prime minister narendra modi called imran\n\n\n원문 : pm narendra modi president ram nath kovind congratulated team india winning world cup record fourth time pm modi said absolutely thrilled achievement young cricketers congratulations winning proud captain shaw prithvi mates well coach rahul dravid part president kovind tweet read \n실제 요약 : pm modi president congratulate india on wc\n예측 요약 : pm narendra modi president ram\n\n\n원문 : president ram nath kovind approved elevation chief justice karnataka high court dinesh justice sanjiv khanna delhi high court supreme court appointments take total strength apex court sanctioned strength chief justices delhi rajasthan high courts recommended elevation earlier \n실제 요약 : judges sanjiv khanna dinesh to supreme court\n예측 요약 : president ram nath kovind\n\n\n원문 : year old man german town called police mistaking nearly inch world war two bomb police said kilogram really look like bomb may thrown hedge man garden police man disposed \n실제 요약 : german mistakes large for wwii bomb calls police\n예측 요약 : year old man german town called police mistaking nearly inch\n\n\n원문 : police raipur sunday arrested upsc aspirant wife seized fake currency notes face value crore besides printing fake notes also allegedly offered help companies get income tax benefits accepting donations corporate social responsibility scheme couple arrested based tip \n실제 요약 : upsc aspirant wife held in raipur with cr in fake notes\n예측 요약 : upsc aspirant wife seized fake currency\n\n\n원문 : bsp chief mayawati saturday attacked bjp ram temple issue saying divert attention failures intentions good need waited four years said mayawati statement comes ahead mass organised various groups ayodhya construction ram temple \n실제 요약 : bjp raised ram temple issue to hide their failures mayawati\n예측 요약 : bsp chief mayawati attacks\n\n\n원문 : indian pacer jasprit bumrah posted video instagram shows cricketer working stated wished possess swedish footballer zlatan ibrahimovic lions compare humans zlatan ibrahimovic classic zlatan quote wish fitness read post caption \n실제 요약 : wish had zlatan jasprit bumrah\n예측 요약 : indian pacer jasprit bumr\n\n\n원문 : china tencent unveiled artificial intelligence based tool remove images using large scale de also trained ai called face editor adds facial features person image face editor uses system could allow function cameras apps \n실제 요약 : china tencent trains ai to de face photos\n예측 요약 : china tencent unveiled artificial intelligence based tool\n\n\n원문 : six years higgs boson discovery god particle observed fundamental particles known bottom seen two detectors cern switzerland geneva houses world largest particle accelerator physicist peter higgs predicted higgs boson physics nobel cern confirmed \n실제 요약 : found to yrs after nobel winning discovery\n예측 요약 : higgs boson discovery god particle observed fundamental particles\n\n\n원문 : bengaluru police arrested seven oxford college students allegedly two joined college days ago allegedly taken rented house forced sing dance household accused arrested college hostel warden lodged complaint behalf \n실제 요약 : college students arrested for ragging in bengaluru\n예측 요약 : bengaluru police arrest seven ox\n\n\n원문 : sunrisers hyderabad player ben cutting ran rcb jadhav full toss direct throw boundary opening match ipl wednesday jadhav went low delivery play sweep shot towards long leg cutting collected ball hit striker end knocking stumps deep \n실제 요약 : cutting runs out jadhav with full toss direct boundary throw\n예측 요약 : sunrisers hyderabad player be\n\n\n원문 : lipstick burkha director shrivastava said problem female point view adding comfortable something questions status quo also said male perspective popular culture led discrimination women makes stalking seem like love makes harassment abuse women okay \n실제 요약 : censors have issue with female lipstick director\n예측 요약 : lipstick burkha director shrivastava said problem female\n\n\n원문 : rising pune supergiant ben stokes called ms dhoni bollywood hero australian captain steve smith villain part well know super giants activity stokes required name one player hero another villain gave titles ajinkya rahane ms dhoni also participated activity \n실제 요약 : ms dhoni bollywood hero steve smith villain ben stokes\n예측 요약 : ben stokes called ms\n\n\n원문 : iranian director whose film best foreign language film oscars year accepted trophy nearly three months ceremony cannes film festival boycotted oscars ceremony following us president donald trump ban muslim visitors praised cannes place cultures speak one another \n실제 요약 : post ceremony boycott iran accepts oscar at cannes\n예측 요약 : iranian director whose film best foreign\n\n\n원문 : melbourne renegades afghan rounder mohammad nabi failed recognise australian teammate dan christian interview minutes recording run match winning partnership reporter asked nabi christian hospital ahead bbl match replied know sorry god give good health well added \n실제 요약 : player fails to recognise teammate minutes after batting with him\n예측 요약 : mohammad nabi failed recognise australian team\n\n\n원문 : central board employees provident fund organisation saturday unanimously dismissed proposal reduce employees employers contribution members also criticised labour ministry proposal reduce employers contributions mandatory people earning basic salary \n실제 요약 : proposal to cut employee contribution to dismissed\n예측 요약 : central board employees provident fund organisation dismiss proposal reduce\n\n\n원문 : karan johar said taken seriously sanjay leela bhansali rajkumar hirani intense filmmakers work nothing else added victim perception johar said wear gucci high heel shoes grabbing headlines twitter take seriously \n실제 요약 : am not taken as seriously as bhansali or hirani johar\n예측 요약 : sanjay leela bhan\n\n\n원문 : trailer danny starrer released film adaptation short story rabindranath tagore release date film recently changed february may birth anniversary month tagore directed deb scheduled release may \n실제 요약 : trailer of danny starrer released\n예측 요약 : trailer danny starrer released film adaptation short story\n\n\n원문 : taking dig gandhi family wednesday lok sabha finance minister arun jaitley quoted james bond movie said twice coincidence thrice conspiracy fingers point agustawestland national herald bofors bit much added \n실제 요약 : arun jaitley quotes james bond movie against gandhi family in ls\n예측 요약 : lok sabha finance minister\n\n\n원문 : pm narendra modi sunday inaugurated km long elevated section delhi metro green line link capital also known gateway haryana third place haryana brought delhi metro network gurugram faridabad trains service section seven stations \n실제 요약 : pm modi opens metro linking delhi to gateway to haryana\n예측 요약 : pm narendra modi inaugurates km long\n\n\n원문 : slamming ipl auction new zealand cricket players association said players paraded like cattle world see event think whole system deeply players chief executive mills said stated players act mere commodities franchises \n실제 요약 : players paraded like cattle in ipl auction nz cricketers\n예측 요약 : players paraded like cattle world see event think whole system\n\n\n원문 : jammu kashmir cm mehbooba mufti said government planning construct border bhavan provide shelter civilians ceasefire violations pakistan government offer employment family members killed firing added thought month ramzan pakistan would indulge ceasefire violations said \n실제 요약 : will make border bhavan for shelter from pak firing cm\n예측 요약 : ramzan pakistan would indulge ceasefire\n\n\n원문 : uber tapped stories riders drivers extend brand narrative tells story single mother enables year old pursue dream black belt campaign uber stories indians constantly moving towards aspirations one ride time \n실제 요약 : uber new ad film is inspired by real riders and their lives\n예측 요약 : story single mother enables year old pursue dream black belt\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# 인코더 설계 시작\nembedding_dim = 128\nhidden_size = 512\n\n# 배치 크기 설정 (GPU 메모리에 맞게 조정)\nBATCH_SIZE_PER_REPLICA = 64\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\nwith strategy.scope():\n\n    # 인코더\n    encoder_inputs = Input(shape=(text_max_len,))\n\n    # 인코더의 임베딩 층\n    enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n\n    # 인코더의 LSTM 1\n    # encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n    encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True)\n    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n\n    # 인코더의 LSTM 2\n    # [[YOUR CODE]]\n    encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True)\n    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n\n    # 인코더의 LSTM 3\n    # [[YOUR CODE]]\n    encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True)\n    encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n\n    # 디코더 설계\n    decoder_inputs = Input(shape=(None,))\n\n    # 디코더의 임베딩 층\n    dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n    dec_emb = dec_emb_layer(decoder_inputs)\n\n    # 디코더의 LSTM\n    # decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n    decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])\n\n    # 디코더의 출력층\n    decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n    decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n\n# 모델 정의\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\nmodel.summary()\n\nfrom tensorflow.keras.layers import AdditiveAttention\n\n# 어텐션 층(어텐션 함수)\nattn_layer = AdditiveAttention(name='attention_layer')\n\n# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\nattn_out = attn_layer([decoder_outputs, encoder_output3])\n\n\n# 어텐션의 결과와 디코더의 hidden state들을 연결\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n\n# 디코더의 출력층\ndecoder_softmax_layer = Dense(tar_vocab, activation='softmax')\ndecoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n\n# 모델 정의\nmodel = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n\nhistory = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n          batch_size=256, callbacks=[es], epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:54:13.519474Z","iopub.execute_input":"2024-08-14T07:54:13.519786Z","iopub.status.idle":"2024-08-14T07:54:15.611262Z","shell.execute_reply.started":"2024-08-14T07:54:13.519759Z","shell.execute_reply":"2024-08-14T07:54:15.609846Z"},"trusted":true},"execution_count":210,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_47\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_47\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_51      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_45        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ input_layer_51[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_91 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_52      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_92 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_46        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_93 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_94 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m5,130,000\u001b[0m │ lstm_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ \u001b[38;5;34m10000\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_51      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_45        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ input_layer_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_52      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_46        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ lstm_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,153,936\u001b[0m (57.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,153,936</span> (57.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,153,936\u001b[0m (57.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,153,936</span> (57.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_48\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_48\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_51      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_45        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ input_layer_51[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_91 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_52      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_92 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_46        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_93 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_94 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ lstm_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lstm_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_29 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m10,250,000\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m10000\u001b[0m)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_51      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_45        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ input_layer_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_52      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_46        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ lstm_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250,000</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)            │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,274,448\u001b[0m (77.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,274,448</span> (77.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,274,448\u001b[0m (77.34 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,274,448</span> (77.34 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[210], line 81\u001b[0m\n\u001b[1;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     79\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:71\u001b[0m, in \u001b[0;36mTFOptimizer.assign_sub\u001b[0;34m(self, variable, value)\u001b[0m\n\u001b[1;32m     69\u001b[0m value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(value, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, tf\u001b[38;5;241m.\u001b[39mIndexedSlices):\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     variable\u001b[38;5;241m.\u001b[39massign_sub(value)\n","\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not MirroredVariable"],"ename":"TypeError","evalue":"tuple indices must be integers or slices, not MirroredVariable","output_type":"error"}]},{"cell_type":"markdown","source":"T5","metadata":{}}]}